üîù Retour au [Sommaire](/SOMMAIRE.md)

# 3.6 RedisTimeSeries : Gestion de donn√©es temporelles (IoT, monitoring)

## Introduction

Les **s√©ries temporelles** (time-series) sont des donn√©es index√©es chronologiquement : m√©triques syst√®me, capteurs IoT, prix financiers, logs applicatifs, etc. Ces donn√©es ont des caract√©ristiques sp√©cifiques :

- üìà **Insertions s√©quentielles** : Donn√©es toujours ajout√©es dans l'ordre chronologique
- üîç **Requ√™tes par plage** : "Temp√©rature entre 10h et 12h"
- üìä **Agr√©gations** : Moyennes, min/max, sommes sur des intervalles
- üóúÔ∏è **Compaction** : R√©duire la granularit√© des donn√©es anciennes
- üìâ **R√©tention** : Supprimer automatiquement les donn√©es trop anciennes

**RedisTimeSeries** est un module Redis optimis√© pour g√©rer ces donn√©es avec :
- ‚úÖ **Ingestion ultra-rapide** : 100K+ writes/sec par s√©rie
- ‚úÖ **Agr√©gations automatiques** : Downsampling en temps r√©el
- ‚úÖ **Requ√™tes efficaces** : Latence < 1ms pour les requ√™tes
- ‚úÖ **Compression** : R√©duction de 90% de la m√©moire vs stockage na√Øf
- ‚úÖ **Labels** : M√©tadonn√©es pour filtrer et grouper les s√©ries

---

## Pourquoi RedisTimeSeries ?

### Le probl√®me avec Redis Core

**Avec Sorted Sets** (approche classique) :

```bash
# Stocker des mesures de temp√©rature avec Sorted Sets
ZADD temp:sensor1 1702123200 "22.5"
ZADD temp:sensor1 1702123260 "23.1"
ZADD temp:sensor1 1702123320 "22.8"

# Probl√®mes :
# ‚ùå Pas d'agr√©gations natives (moyenne, min, max)
# ‚ùå Pas de compaction automatique
# ‚ùå Pas de gestion de r√©tention
# ‚ùå Stockage inefficace (pas de compression)
# ‚ùå Requ√™tes complexes n√©cessitent du code applicatif
```

**Avec RedisTimeSeries** :

```bash
# Cr√©er une s√©rie temporelle
TS.CREATE temp:sensor1 RETENTION 86400000 LABELS sensor_id 1 type temperature

# Ajouter des mesures
TS.ADD temp:sensor1 * 22.5
TS.ADD temp:sensor1 * 23.1
TS.ADD temp:sensor1 * 22.8

# Requ√™te avec agr√©gation automatique
TS.RANGE temp:sensor1 1702123200000 1702209600000 AGGREGATION avg 60000
# Moyenne par minute sur 24h

# Avantages :
# ‚úÖ Agr√©gations natives
# ‚úÖ Compaction automatique
# ‚úÖ R√©tention automatique
# ‚úÖ Compression optimis√©e (~90% de r√©duction)
# ‚úÖ API simple et intuitive
```

---

## Installation et v√©rification

### V√©rifier que RedisTimeSeries est disponible

```bash
# V√©rifier les modules charg√©s
redis-cli MODULE LIST

# Devrait contenir :
# 1) 1) "name"
#    2) "timeseries"
#    3) "ver"
#    4) 10812  # Version 1.8.12
```

### Avec Docker (Redis Stack)

```bash
# D√©marrer Redis Stack avec RedisTimeSeries
docker run -d --name redis-stack -p 6379:6379 redis/redis-stack:latest

# Tester RedisTimeSeries
redis-cli TS.CREATE test RETENTION 60000
redis-cli TS.ADD test * 42
redis-cli TS.RANGE test - +
# OK : RedisTimeSeries fonctionne
```

---

## Concepts fondamentaux

### Timestamps

Les timestamps sont en **millisecondes** depuis l'epoch Unix.

```bash
# Timestamp explicite (millisecondes)
TS.ADD sensor:1 1702123200000 25.5

# Timestamp automatique (timestamp actuel)
TS.ADD sensor:1 * 25.5
```

**Conversion** :

```python
import time

# Obtenir le timestamp actuel en millisecondes
timestamp_ms = int(time.time() * 1000)

# Convertir une date en timestamp
from datetime import datetime
dt = datetime(2024, 12, 9, 10, 0, 0)
timestamp_ms = int(dt.timestamp() * 1000)
```

---

### Labels (m√©tadonn√©es)

Les labels permettent de filtrer et grouper les s√©ries.

```bash
# Cr√©er des s√©ries avec labels
TS.CREATE temp:sensor1 LABELS sensor_id 1 location datacenter-a type temperature
TS.CREATE temp:sensor2 LABELS sensor_id 2 location datacenter-a type temperature
TS.CREATE temp:sensor3 LABELS sensor_id 3 location datacenter-b type temperature

# Requ√™te multi-s√©ries par labels
TS.MRANGE - + FILTER location=datacenter-a
# Retourne temp:sensor1 et temp:sensor2

TS.MRANGE - + FILTER type=temperature location=datacenter-b
# Retourne temp:sensor3
```

---

### R√©tention (RETENTION)

D√©finit combien de temps conserver les donn√©es (en millisecondes).

```bash
# R√©tention de 24 heures
TS.CREATE sensor:1 RETENTION 86400000

# R√©tention de 7 jours
TS.CREATE sensor:2 RETENTION 604800000

# R√©tention infinie (0 ou omis)
TS.CREATE sensor:3
```

**Suppression automatique** : Les donn√©es plus anciennes que la r√©tention sont supprim√©es automatiquement.

---

### Politique de duplication (DUPLICATE_POLICY)

Que faire si on ins√®re deux fois la m√™me valeur au m√™me timestamp ?

```bash
# BLOCK : Erreur (d√©faut)
TS.CREATE sensor:1 DUPLICATE_POLICY BLOCK

# LAST : Garder la derni√®re valeur
TS.CREATE sensor:2 DUPLICATE_POLICY LAST

# FIRST : Garder la premi√®re valeur
TS.CREATE sensor:3 DUPLICATE_POLICY FIRST

# MIN : Garder la valeur minimale
TS.CREATE sensor:4 DUPLICATE_POLICY MIN

# MAX : Garder la valeur maximale
TS.CREATE sensor:5 DUPLICATE_POLICY MAX

# SUM : Additionner les valeurs
TS.CREATE sensor:6 DUPLICATE_POLICY SUM
```

**Cas d'usage** :
- `LAST` : Capteurs (garder la mesure la plus r√©cente)
- `SUM` : Compteurs (additionner les √©v√©nements)
- `MAX` : Pics de trafic (conserver le maximum)

---

## Commandes principales

### TS.CREATE : Cr√©er une s√©rie temporelle

```bash
# Syntaxe compl√®te
TS.CREATE key
  [RETENTION retention_ms]
  [ENCODING {COMPRESSED|UNCOMPRESSED}]
  [CHUNK_SIZE size]
  [DUPLICATE_POLICY {BLOCK|FIRST|LAST|MIN|MAX|SUM}]
  [LABELS label value...]
```

**Exemples** :

```bash
# S√©rie simple
TS.CREATE temperature

# Avec r√©tention et labels
TS.CREATE temp:cpu1
  RETENTION 3600000
  DUPLICATE_POLICY LAST
  LABELS server web-01 metric cpu_usage

# Avec compression et chunk size
TS.CREATE metrics:requests
  RETENTION 604800000
  ENCODING COMPRESSED
  CHUNK_SIZE 4096
  LABELS service api endpoint /users
```

---

### TS.ADD : Ajouter une mesure

```bash
# Avec timestamp automatique
TS.ADD temp:sensor1 * 25.5
# Retourne le timestamp utilis√© : (integer) 1702123456789

# Avec timestamp explicite
TS.ADD temp:sensor1 1702123200000 24.3

# Cr√©er la s√©rie √† la vol√©e (ON_DUPLICATE)
TS.ADD temp:sensor2 * 26.1 RETENTION 86400000 LABELS type temperature

# Avec politique de duplication
TS.ADD counter:requests * 1 ON_DUPLICATE SUM
```

---

### TS.MADD : Ajouter plusieurs mesures

```bash
# Ajouter √† plusieurs s√©ries en une seule commande
TS.MADD
  temp:sensor1 * 25.5
  temp:sensor2 * 26.1
  temp:sensor3 * 24.8

# Retourne les timestamps pour chaque s√©rie
# 1) (integer) 1702123456789
# 2) (integer) 1702123456790
# 3) (integer) 1702123456791
```

**Performance** : Plus efficace que plusieurs `TS.ADD` s√©par√©s.

---

### TS.INCRBY / TS.DECRBY : Incr√©menter/D√©cr√©menter

```bash
# Cr√©er un compteur
TS.CREATE counter:requests DUPLICATE_POLICY SUM

# Incr√©menter
TS.INCRBY counter:requests 1
TS.INCRBY counter:requests 5
TS.INCRBY counter:requests 3

# D√©cr√©menter
TS.DECRBY counter:requests 2

# Avec timestamp explicite
TS.INCRBY counter:requests 1 TIMESTAMP 1702123200000
```

---

### TS.RANGE : Requ√™te sur une s√©rie

```bash
# Syntaxe
TS.RANGE key from_timestamp to_timestamp
  [LATEST]
  [FILTER_BY_TS ts...]
  [FILTER_BY_VALUE min max]
  [COUNT count]
  [AGGREGATION aggregator bucket_duration]
  [ALIGN align]
  [BUCKETTIMESTAMP bt]
```

**Exemples** :

```bash
# Toutes les donn√©es
TS.RANGE temp:sensor1 - +

# Plage sp√©cifique (timestamps en millisecondes)
TS.RANGE temp:sensor1 1702123200000 1702209600000

# Avec agr√©gation (moyenne par heure)
TS.RANGE temp:sensor1 1702123200000 1702209600000
  AGGREGATION avg 3600000

# Limiter le nombre de r√©sultats
TS.RANGE temp:sensor1 - + COUNT 100

# Filtrer par valeur (temp√©ratures entre 20 et 30)
TS.RANGE temp:sensor1 - + FILTER_BY_VALUE 20 30
```

**R√©sultat** :

```
1) 1) (integer) 1702123200000
   2) "25.5"
2) 1) (integer) 1702126800000
   2) "26.1"
3) 1) (integer) 1702130400000
   2) "24.8"
```

---

### TS.REVRANGE : Requ√™te en ordre invers√©

```bash
# Les 10 derni√®res mesures
TS.REVRANGE temp:sensor1 - + COUNT 10
```

---

### TS.MRANGE : Requ√™te multi-s√©ries

```bash
# Toutes les s√©ries avec un label sp√©cifique
TS.MRANGE - + FILTER type=temperature

# Avec agr√©gation
TS.MRANGE 1702123200000 1702209600000
  AGGREGATION avg 3600000
  FILTER location=datacenter-a

# Grouper par label
TS.MRANGE - +
  FILTER type=temperature
  GROUPBY location
  REDUCE avg
```

**R√©sultat** :

```
1) 1) "temp:sensor1"
   2) 1) 1) "sensor_id"
         2) "1"
      2) 1) "location"
         2) "datacenter-a"
   3) 1) 1) (integer) 1702123200000
         2) "25.5"
      2) 1) (integer) 1702126800000
         2) "26.1"
2) 1) "temp:sensor2"
   2) 1) 1) "sensor_id"
         2) "2"
      2) 1) "location"
         2) "datacenter-a"
   3) 1) 1) (integer) 1702123200000
         2) "24.8"
```

---

### TS.GET : Derni√®re valeur

```bash
# Obtenir la derni√®re mesure
TS.GET temp:sensor1

# R√©sultat :
# 1) (integer) 1702123456789  # Timestamp
# 2) "25.5"                    # Valeur
```

---

### TS.MGET : Derni√®res valeurs de plusieurs s√©ries

```bash
# Derni√®re valeur de toutes les s√©ries de type temperature
TS.MGET LATEST FILTER type=temperature

# R√©sultat :
# 1) 1) "temp:sensor1"
#    2) 1) 1) "sensor_id"
#          2) "1"
#    3) 1) (integer) 1702123456789
#       2) "25.5"
# 2) 1) "temp:sensor2"
#    2) 1) 1) "sensor_id"
#          2) "2"
#    3) 1) (integer) 1702123456790
#       2) "26.1"
```

---

### TS.INFO : Informations sur une s√©rie

```bash
TS.INFO temp:sensor1

# R√©sultat :
# 1) "totalSamples"
# 2) (integer) 1440  # Nombre de samples
# 3) "memoryUsage"
# 4) (integer) 4184  # M√©moire utilis√©e (bytes)
# 5) "firstTimestamp"
# 6) (integer) 1702123200000
# 7) "lastTimestamp"
# 8) (integer) 1702209600000
# 9) "retentionTime"
# 10) (integer) 86400000
# 11) "chunkCount"
# 12) (integer) 1
# 13) "labels"
# 14) 1) 1) "sensor_id"
#        2) "1"
#     2) 1) "type"
#        2) "temperature"
```

---

## Agr√©gations automatiques : TS.CREATERULE

### Concept de downsampling

**Probl√®me** : Conserver des donn√©es haute r√©solution (1 seconde) sur 1 an = √©norme volume.

**Solution** : Cr√©er des agr√©gations automatiques :
- R√©solution 1s ‚Üí Conserver 24h
- R√©solution 1min (moyenne sur 1 min) ‚Üí Conserver 7 jours
- R√©solution 1h (moyenne sur 1h) ‚Üí Conserver 1 an

---

### Cr√©er une r√®gle d'agr√©gation

```bash
# S√©rie source (haute r√©solution)
TS.CREATE temp:sensor1:raw
  RETENTION 86400000
  LABELS sensor_id 1 resolution raw

# S√©rie agr√©g√©e (moyenne sur 1 minute)
TS.CREATE temp:sensor1:1min
  RETENTION 604800000
  LABELS sensor_id 1 resolution 1min

# Cr√©er la r√®gle d'agr√©gation
TS.CREATERULE temp:sensor1:raw temp:sensor1:1min
  AGGREGATION avg 60000

# S√©rie agr√©g√©e (moyenne sur 1 heure)
TS.CREATE temp:sensor1:1hour
  RETENTION 31536000000
  LABELS sensor_id 1 resolution 1hour

TS.CREATERULE temp:sensor1:raw temp:sensor1:1hour
  AGGREGATION avg 3600000
```

**Fonctionnement** :
- Chaque fois qu'une valeur est ajout√©e √† `temp:sensor1:raw`, RedisTimeSeries calcule automatiquement les agr√©gations
- Les s√©ries agr√©g√©es sont mises √† jour en temps r√©el
- Pas besoin de code applicatif pour g√©rer le downsampling

---

### Fonctions d'agr√©gation disponibles

```bash
# Moyenne
TS.CREATERULE source dest AGGREGATION avg 60000

# Somme
TS.CREATERULE source dest AGGREGATION sum 60000

# Min / Max
TS.CREATERULE source dest AGGREGATION min 60000
TS.CREATERULE source dest AGGREGATION max 60000

# Premier / Dernier
TS.CREATERULE source dest AGGREGATION first 60000
TS.CREATERULE source dest AGGREGATION last 60000

# Range (max - min)
TS.CREATERULE source dest AGGREGATION range 60000

# Comptage
TS.CREATERULE source dest AGGREGATION count 60000

# √âcart-type
TS.CREATERULE source dest AGGREGATION std.p 60000
TS.CREATERULE source dest AGGREGATION std.s 60000

# Variance
TS.CREATERULE source dest AGGREGATION var.p 60000
TS.CREATERULE source dest AGGREGATION var.s 60000
```

---

### Lister les r√®gles

```bash
# Lister les r√®gles d'agr√©gation d'une s√©rie
TS.INFO temp:sensor1:raw

# R√©sultat inclut :
# "rules"
# 1) 1) "temp:sensor1:1min"
#    2) (integer) 60000
#    3) "avg"
# 2) 1) "temp:sensor1:1hour"
#    2) (integer) 3600000
#    3) "avg"
```

---

### Supprimer une r√®gle

```bash
TS.DELETERULE temp:sensor1:raw temp:sensor1:1min
```

---

## Cas d'usage modernes

### 1Ô∏è‚É£ Monitoring syst√®me (CPU, RAM, disque)

**Contexte** : Surveiller les m√©triques syst√®me de plusieurs serveurs

```bash
# Cr√©er les s√©ries pour chaque serveur
TS.CREATE metrics:cpu:server01
  RETENTION 86400000
  DUPLICATE_POLICY LAST
  LABELS server server01 metric cpu_usage datacenter paris

TS.CREATE metrics:cpu:server02
  RETENTION 86400000
  DUPLICATE_POLICY LAST
  LABELS server server02 metric cpu_usage datacenter paris

TS.CREATE metrics:memory:server01
  RETENTION 86400000
  DUPLICATE_POLICY LAST
  LABELS server server01 metric memory_usage datacenter paris

# Cr√©er des agr√©gations (moyenne sur 5 minutes)
TS.CREATE metrics:cpu:server01:5min RETENTION 604800000
TS.CREATERULE metrics:cpu:server01 metrics:cpu:server01:5min AGGREGATION avg 300000

# Envoyer des m√©triques (toutes les 10 secondes)
TS.ADD metrics:cpu:server01 * 23.5
TS.ADD metrics:memory:server01 * 45.2

# Requ√™te : CPU moyen sur la derni√®re heure
TS.RANGE metrics:cpu:server01 1702120000000 1702123600000 AGGREGATION avg 60000

# Requ√™te multi-serveurs : CPU de tous les serveurs √† Paris
TS.MRANGE - + FILTER metric=cpu_usage datacenter=paris

# Dashboard : Derni√®re valeur de toutes les m√©triques
TS.MGET LATEST FILTER datacenter=paris
```

---

### 2Ô∏è‚É£ IoT : Capteurs de temp√©rature et humidit√©

**Contexte** : R√©seau de capteurs dans plusieurs b√¢timents

```bash
# Cr√©er les s√©ries pour chaque capteur
TS.CREATE sensor:temp:building_a:room_101
  RETENTION 2592000000  # 30 jours
  LABELS building building_a room room_101 type temperature

TS.CREATE sensor:humidity:building_a:room_101
  RETENTION 2592000000
  LABELS building building_a room room_101 type humidity

TS.CREATE sensor:temp:building_b:room_201
  RETENTION 2592000000
  LABELS building building_b room room_201 type temperature

# Agr√©gations : Moyenne par heure (conservation 1 an)
TS.CREATE sensor:temp:building_a:room_101:hourly RETENTION 31536000000
TS.CREATERULE sensor:temp:building_a:room_101 sensor:temp:building_a:room_101:hourly
  AGGREGATION avg 3600000

# Ingestion des mesures (toutes les minutes)
TS.ADD sensor:temp:building_a:room_101 * 22.5
TS.ADD sensor:humidity:building_a:room_101 * 65.2

# Analyse : Temp√©rature moyenne par b√¢timent
TS.MRANGE 1702123200000 1702209600000
  FILTER type=temperature
  GROUPBY building
  REDUCE avg

# Alerte : Temp√©ratures anormales (> 30¬∞C)
TS.MRANGE - +
  FILTER type=temperature
  FILTER_BY_VALUE 30 +inf
```

---

### 3Ô∏è‚É£ Application web : M√©triques de trafic

**Contexte** : Tracker les requ√™tes HTTP, latences, erreurs

```bash
# S√©ries pour les compteurs de requ√™tes
TS.CREATE metrics:requests:total
  RETENTION 604800000
  DUPLICATE_POLICY SUM
  LABELS service api endpoint all

TS.CREATE metrics:requests:endpoint_users
  RETENTION 604800000
  DUPLICATE_POLICY SUM
  LABELS service api endpoint /users

TS.CREATE metrics:requests:endpoint_orders
  RETENTION 604800000
  DUPLICATE_POLICY SUM
  LABELS service api endpoint /orders

# S√©ries pour les latences
TS.CREATE metrics:latency:p50
  RETENTION 604800000
  LABELS service api metric latency_p50

TS.CREATE metrics:latency:p99
  RETENTION 604800000
  LABELS service api metric latency_p99

# Agr√©gations : Requ√™tes par minute (conservation 30 jours)
TS.CREATE metrics:requests:total:1min RETENTION 2592000000
TS.CREATERULE metrics:requests:total metrics:requests:total:1min
  AGGREGATION sum 60000

# Ingestion (chaque requ√™te)
TS.INCRBY metrics:requests:total 1
TS.INCRBY metrics:requests:endpoint_users 1
TS.ADD metrics:latency:p50 * 45  # 45ms

# Dashboard : Requ√™tes par seconde (RPS)
TS.RANGE metrics:requests:total:1min - + AGGREGATION sum 1000

# Analyse : Quel endpoint a le plus de trafic ?
TS.MGET LATEST FILTER service=api
```

---

### 4Ô∏è‚É£ Finance : Prix des actifs

**Contexte** : Stocker les prix de cryptomonnaies / actions

```bash
# Cr√©er les s√©ries pour chaque actif
TS.CREATE price:btc:usd
  RETENTION 31536000000  # 1 an
  DUPLICATE_POLICY LAST
  LABELS asset BTC pair BTC/USD

TS.CREATE price:eth:usd
  RETENTION 31536000000
  DUPLICATE_POLICY LAST
  LABELS asset ETH pair ETH/USD

# Agr√©gations : OHLC (Open, High, Low, Close)
TS.CREATE price:btc:usd:1min:open RETENTION 2592000000
TS.CREATERULE price:btc:usd price:btc:usd:1min:open AGGREGATION first 60000

TS.CREATE price:btc:usd:1min:high RETENTION 2592000000
TS.CREATERULE price:btc:usd price:btc:usd:1min:high AGGREGATION max 60000

TS.CREATE price:btc:usd:1min:low RETENTION 2592000000
TS.CREATERULE price:btc:usd price:btc:usd:1min:low AGGREGATION min 60000

TS.CREATE price:btc:usd:1min:close RETENTION 2592000000
TS.CREATERULE price:btc:usd price:btc:usd:1min:close AGGREGATION last 60000

# Ingestion (tick par tick)
TS.ADD price:btc:usd * 42350.50
TS.ADD price:btc:usd * 42360.20
TS.ADD price:btc:usd * 42345.80

# Requ√™te : Prix BTC sur la derni√®re heure avec candlesticks (1 min)
# R√©cup√©rer OHLC
TS.MRANGE 1702120000000 1702123600000
  FILTER asset=BTC pair=BTC/USD

# Analyse : Volatilit√© (range = high - low)
TS.RANGE price:btc:usd 1702123200000 1702209600000 AGGREGATION range 60000
```

---

### 5Ô∏è‚É£ Gaming : Analytics de joueurs en temps r√©el

**Contexte** : Tracker les connexions, sessions, achats

```bash
# S√©ries pour les m√©triques de jeu
TS.CREATE game:players:online
  RETENTION 604800000
  DUPLICATE_POLICY LAST
  LABELS game mmorpg metric players_online

TS.CREATE game:revenue:daily
  RETENTION 31536000000
  DUPLICATE_POLICY SUM
  LABELS game mmorpg metric revenue

TS.CREATE game:sessions:started
  RETENTION 604800000
  DUPLICATE_POLICY SUM
  LABELS game mmorpg metric sessions_started

# Agr√©gations : Joueurs moyens par heure
TS.CREATE game:players:online:hourly RETENTION 2592000000
TS.CREATERULE game:players:online game:players:online:hourly AGGREGATION avg 3600000

# Ingestion
TS.ADD game:players:online * 15423  # 15,423 joueurs en ligne
TS.INCRBY game:revenue:daily 9.99   # Achat in-game
TS.INCRBY game:sessions:started 1   # Nouvelle session

# Dashboard : Joueurs en ligne (temps r√©el)
TS.GET game:players:online

# Analytics : Revenu total du mois
TS.RANGE game:revenue:daily 1704067200000 1706745600000 AGGREGATION sum 86400000

# Analyse : Peak d'utilisateurs (max par jour)
TS.RANGE game:players:online 1702123200000 1702209600000 AGGREGATION max 86400000
```

---

## Compression et optimisation

### Compression automatique

RedisTimeSeries utilise **Gorilla compression** (algorithme Facebook) optimis√© pour les time-series.

```bash
# Exemple de compression

# Sans compression (stockage na√Øf) :
# 1440 samples (1 par minute sur 24h)
# Taille : 1440 √ó 16 bytes = 23 KB

# Avec compression RedisTimeSeries :
# Taille : ~2-3 KB
# Ratio de compression : 90%
```

**Activation** :

```bash
# Compression activ√©e par d√©faut
TS.CREATE sensor:1 ENCODING COMPRESSED

# D√©sactiver la compression (plus rapide, mais plus de m√©moire)
TS.CREATE sensor:2 ENCODING UNCOMPRESSED
```

**Conseil** : Garder la compression activ√©e sauf si vous avez des contraintes de latence extr√™mes (< 100¬µs).

---

### Chunk Size

RedisTimeSeries stocke les donn√©es par chunks (blocs).

```bash
# Chunk size par d√©faut : 4096 bytes
TS.CREATE sensor:1

# Chunk size personnalis√©
TS.CREATE sensor:2 CHUNK_SIZE 8192

# Plus petit chunk : Moins de m√©moire, plus de chunks
TS.CREATE sensor:3 CHUNK_SIZE 2048

# Plus grand chunk : Plus de m√©moire, moins de chunks
TS.CREATE sensor:4 CHUNK_SIZE 16384
```

**Trade-off** :
- Petit chunk (2048) : Utilise moins de m√©moire, mais plus d'overhead
- Grand chunk (8192+) : Utilise plus de m√©moire, mais moins d'overhead

**Recommandation** : Garder le d√©faut (4096) sauf cas sp√©cifiques.

---

## Performance et benchmarks

### Ingestion

```bash
# Benchmark : Ingestion continue

# 1 s√©rie, 1 mesure/seconde
# Throughput : ~100K writes/sec
# Latence moyenne : < 0.1ms

# 1000 s√©ries, 1 mesure/seconde chacune
# Throughput total : ~100K writes/sec (limit√© par single-thread Redis)
# Latence moyenne : < 0.5ms
```

**Optimisation** : Utiliser `TS.MADD` pour ins√©rer dans plusieurs s√©ries en une commande.

```bash
# ‚úÖ Bon : TS.MADD (1 round-trip)
TS.MADD sensor:1 * 25.5 sensor:2 * 26.1 sensor:3 * 24.8

# ‚ùå Moins efficace : 3 TS.ADD (3 round-trips)
TS.ADD sensor:1 * 25.5
TS.ADD sensor:2 * 26.1
TS.ADD sensor:3 * 24.8
```

---

### Requ√™tes

```bash
# Benchmark : Requ√™tes

# TS.RANGE sur 1 s√©rie (1h de donn√©es, 1 sample/sec)
# Latence : < 1ms

# TS.RANGE avec agr√©gation (1 jour de donn√©es, avg par heure)
# Latence : 2-5ms

# TS.MRANGE sur 100 s√©ries (1h de donn√©es)
# Latence : 10-20ms

# TS.MGET sur 1000 s√©ries
# Latence : 5-10ms
```

---

### Impact m√©moire

```bash
# Exemple : 1 s√©rie, 86400 samples (1 par seconde sur 24h)

# Sans compression :
# 86400 √ó 16 bytes = 1.38 MB

# Avec compression RedisTimeSeries :
# ~150-200 KB (compression ~90%)

# Avec agr√©gations (1 raw + 2 agr√©g√©es) :
# Raw (24h, 1s) : 150 KB
# 1min (7 jours) : 168 KB
# 1h (1 an) : 140 KB
# Total : ~460 KB pour 1 an de donn√©es
```

---

## Comparaison : RedisTimeSeries vs alternatives

| Crit√®re | RedisTimeSeries | InfluxDB | TimescaleDB | Prometheus |
|---------|-----------------|----------|-------------|------------|
| **Latence √©criture** | < 0.1ms | 1-5ms | 5-20ms | 1-10ms |
| **Latence lecture** | < 1ms | 5-50ms | 10-100ms | 5-50ms |
| **Throughput** | 100K+ writes/sec | 50-100K/sec | 10-50K/sec | 50K/sec |
| **Compression** | 90% (Gorilla) | 80% | 70% | 85% |
| **Agr√©gations temps r√©el** | ‚úÖ Natives | ‚úÖ Continues | ‚ö†Ô∏è Manuelles | ‚úÖ Recording rules |
| **Stockage** | M√©moire (+ RDB/AOF) | Disque | Disque (PostgreSQL) | Disque |
| **Requ√™tes complexes** | Limit√©es | ‚úÖ InfluxQL | ‚úÖ SQL complet | ‚úÖ PromQL |
| **Cas d'usage** | M√©triques temps r√©el | TSDB g√©n√©raliste | Analytics complexes | Monitoring infra |

**Avantages RedisTimeSeries** :
- ‚úÖ Latence ultra-faible (< 1ms)
- ‚úÖ Throughput exceptionnel (100K+/sec)
- ‚úÖ Agr√©gations automatiques
- ‚úÖ Int√©gration Redis native (m√™me infrastructure)

**Quand choisir une alternative** :
- **InfluxDB** : Si vous avez besoin d'un TSDB d√©di√© avec InfluxQL
- **TimescaleDB** : Si vous avez besoin de requ√™tes SQL complexes
- **Prometheus** : Si vous faites du monitoring d'infrastructure avec scraping

---

## Bonnes pratiques

### ‚úÖ 1. Utiliser des labels pour filtrer et grouper

```bash
# ‚úÖ Bon : Labels riches
TS.CREATE metrics:cpu
  LABELS server web-01 datacenter paris rack 42 environment prod

# Requ√™te facile
TS.MRANGE - + FILTER datacenter=paris environment=prod

# ‚ùå Mauvais : Pas de labels
TS.CREATE metrics:cpu:web01:paris:rack42:prod
# Requ√™te difficile (KEYS + filtrage applicatif)
```

---

### ‚úÖ 2. Cr√©er des agr√©gations pour les donn√©es historiques

```bash
# ‚úÖ Bon : Strat√©gie de r√©tention multi-niveaux
# Raw : 1s ‚Üí 24h
TS.CREATE sensor:1:raw RETENTION 86400000

# 1 min : avg ‚Üí 7 jours
TS.CREATE sensor:1:1min RETENTION 604800000
TS.CREATERULE sensor:1:raw sensor:1:1min AGGREGATION avg 60000

# 1h : avg ‚Üí 1 an
TS.CREATE sensor:1:1hour RETENTION 31536000000
TS.CREATERULE sensor:1:raw sensor:1:1hour AGGREGATION avg 3600000

# ‚ùå Mauvais : Tout conserver en haute r√©solution
TS.CREATE sensor:1 RETENTION 31536000000  # 1 an √† 1s = √©norme
```

---

### ‚úÖ 3. Utiliser TS.MADD pour l'ingestion batch

```bash
# ‚úÖ Bon : 1 commande pour plusieurs s√©ries
TS.MADD
  sensor:1 * 25.5
  sensor:2 * 26.1
  sensor:3 * 24.8

# ‚ùå Moins efficace : Plusieurs commandes
TS.ADD sensor:1 * 25.5
TS.ADD sensor:2 * 26.1
TS.ADD sensor:3 * 24.8
```

---

### ‚úÖ 4. Choisir la bonne politique de duplication

```bash
# ‚úÖ Bon : LAST pour les capteurs (valeur la plus r√©cente)
TS.CREATE temp:sensor1 DUPLICATE_POLICY LAST

# ‚úÖ Bon : SUM pour les compteurs (additionner)
TS.CREATE counter:requests DUPLICATE_POLICY SUM

# ‚úÖ Bon : MAX pour les pics (conserver le maximum)
TS.CREATE metrics:peak_traffic DUPLICATE_POLICY MAX

# ‚ùå Mauvais : BLOCK (erreur si duplicate)
# Utiliser seulement si vous √™tes s√ªr qu'il n'y aura pas de duplicatas
```

---

### ‚úÖ 5. Monitorer l'usage m√©moire

```bash
# V√©rifier l'usage m√©moire d'une s√©rie
TS.INFO sensor:1

# R√©sultat :
# "memoryUsage"
# (integer) 4184  # bytes

# Calculer l'usage total (script Lua ou application)
```

---

### ‚úÖ 6. Utiliser des conventions de nommage

```bash
# ‚úÖ Bon : Convention hi√©rarchique
metrics:cpu:server01
metrics:memory:server01
metrics:disk:server01
sensor:temp:building_a:room_101
game:players:online

# Facilite les requ√™tes par pattern
TS.MRANGE - + FILTER server=server01  # Toutes les m√©triques de server01

# ‚ùå Mauvais : Pas de convention
cpu_server01
mem_srv1
disk_usage_server_01
```

---

## Int√©gration avec les langages

### Python (redis-py)

```python
import redis
import time

r = redis.Redis(host='localhost', port=6379, decode_responses=True)

# Cr√©er une s√©rie
r.ts().create('sensor:1', retention_msecs=86400000, labels={'type': 'temperature'})

# Ajouter des mesures
timestamp_ms = int(time.time() * 1000)
r.ts().add('sensor:1', timestamp_ms, 25.5)

# Avec timestamp automatique
r.ts().add('sensor:1', '*', 26.1)

# Requ√™te
result = r.ts().range('sensor:1', '-', '+')
for timestamp, value in result:
    print(f"{timestamp}: {value}")

# Avec agr√©gation
result = r.ts().range('sensor:1', '-', '+', aggregation_type='avg', bucket_size_msec=60000)
```

---

### Node.js (node-redis)

```javascript
import { createClient } from 'redis';

const client = await createClient().connect();

// Cr√©er une s√©rie
await client.ts.create('sensor:1', {
  RETENTION: 86400000,
  LABELS: { type: 'temperature' }
});

// Ajouter des mesures
await client.ts.add('sensor:1', '*', 25.5);

// Requ√™te
const result = await client.ts.range('sensor:1', '-', '+');
console.log(result);

// Avec agr√©gation
const aggregated = await client.ts.range('sensor:1', '-', '+', {
  AGGREGATION: {
    type: 'AVG',
    timeBucket: 60000  // 1 minute
  }
});
```

---

### Go (go-redis)

```go
package main

import (
    "context"
    "fmt"
    "time"
    "github.com/redis/go-redis/v9"
)

func main() {
    ctx := context.Background()
    rdb := redis.NewClient(&redis.Options{
        Addr: "localhost:6379",
    })

    // Cr√©er une s√©rie
    rdb.Do(ctx, "TS.CREATE", "sensor:1", "RETENTION", 86400000, "LABELS", "type", "temperature")

    // Ajouter une mesure
    timestamp := time.Now().UnixMilli()
    rdb.Do(ctx, "TS.ADD", "sensor:1", timestamp, 25.5)

    // Requ√™te
    result, _ := rdb.Do(ctx, "TS.RANGE", "sensor:1", "-", "+").Result()
    fmt.Println(result)
}
```

---

## Troubleshooting

### Erreur : "ERR TSDB: the key does not exist"

```bash
# ‚ùå Erreur
TS.ADD sensor:1 * 25.5
# (error) ERR TSDB: the key does not exist

# ‚úÖ Solution : Cr√©er la s√©rie d'abord
TS.CREATE sensor:1
TS.ADD sensor:1 * 25.5

# Ou cr√©er √† la vol√©e
TS.ADD sensor:1 * 25.5 RETENTION 86400000 LABELS type temperature
```

---

### Erreur : "ERR TSDB: timestamp must be higher than the last timestamp"

```bash
# ‚ùå Erreur : Timestamp dans le pass√©
TS.ADD sensor:1 1702123200000 25.5
TS.ADD sensor:1 1702123100000 24.3  # Plus ancien
# (error) ERR TSDB: timestamp must be higher than the last timestamp

# ‚úÖ Solution : Assurer que les timestamps sont croissants
# Ou utiliser DUPLICATE_POLICY pour g√©rer les doublons
TS.CREATE sensor:1 DUPLICATE_POLICY LAST
```

---

### Performance d√©grad√©e

```bash
# ‚úÖ Diagnostics :

# 1. V√©rifier le nombre de samples
TS.INFO sensor:1
# "totalSamples" trop √©lev√© ? ‚Üí R√©duire la RETENTION

# 2. V√©rifier la m√©moire utilis√©e
TS.INFO sensor:1
# "memoryUsage" √©lev√© ? ‚Üí Activer la compression

# 3. V√©rifier le nombre de s√©ries
DBSIZE
# Trop de s√©ries ? ‚Üí Consolider ou utiliser Redis Cluster

# 4. V√©rifier les agr√©gations
TS.INFO sensor:1:raw
# Trop de r√®gles d'agr√©gation ? ‚Üí Simplifier
```

---

## R√©sum√©

**RedisTimeSeries permet de** :
- ‚úÖ Ingestion ultra-rapide (100K+ writes/sec)
- ‚úÖ Requ√™tes low-latency (< 1ms)
- ‚úÖ Agr√©gations automatiques (downsampling)
- ‚úÖ Compression efficace (90% de r√©duction)
- ‚úÖ R√©tention automatique des donn√©es
- ‚úÖ Filtrage et groupement par labels

**Commandes principales** :
- `TS.CREATE` : Cr√©er une s√©rie
- `TS.ADD` / `TS.MADD` : Ins√©rer des mesures
- `TS.RANGE` / `TS.MRANGE` : Requ√™tes
- `TS.CREATERULE` : Agr√©gations automatiques
- `TS.GET` / `TS.MGET` : Derni√®res valeurs

**Cas d'usage id√©aux** :
- üìä Monitoring syst√®me (CPU, RAM, disque)
- üå°Ô∏è IoT (capteurs, t√©l√©m√©trie)
- üìà M√©triques applicatives (requ√™tes, latences)
- üíπ Finance (prix, trading)
- üéÆ Gaming analytics (joueurs, sessions)

**Performance** :
- Latence √©criture : < 0.1ms
- Latence lecture : < 1ms
- Compression : 90%
- Throughput : 100K+ writes/sec

---

**Pr√™t pour les filtres probabilistes ?** Passons √† la section suivante : [3.7 RedisBloom - Filtres de Bloom et Cuckoo](./07-redisbloom-filtres-bloom-cuckoo.md)

‚è≠Ô∏è [RedisBloom : Filtres de Bloom et Cuckoo](/03-structures-donnees-etendues/07-redisbloom-filtres-bloom-cuckoo.md)
