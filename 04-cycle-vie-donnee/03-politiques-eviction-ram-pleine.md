ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 4.3 Politiques d'Ã©viction : Que se passe-t-il quand la RAM est pleine ?

## Introduction

Redis est une base de donnÃ©es **en mÃ©moire**. Cette caractÃ©ristique fondamentale implique une contrainte incontournable : la RAM est **finie**. Lorsque cette limite est atteinte, Redis doit prendre une dÃ©cision critique : **que faire des nouvelles Ã©critures ?**

Les politiques d'Ã©viction (eviction policies) dÃ©finissent le comportement de Redis face Ã  la saturation mÃ©moire. C'est un mÃ©canisme sophistiquÃ© qui peut faire la diffÃ©rence entre une application rÃ©siliente et un systÃ¨me qui s'effondre en production.

## Le problÃ¨me de la saturation mÃ©moire

### ScÃ©nario typique

```
Application â†’ Redis (2GB maxmemory)
         â†“
   Ã‰crit progressivement
         â†“
   1.0 GB utilisÃ© âœ…
   1.5 GB utilisÃ© âœ…
   1.9 GB utilisÃ© âœ…
   2.0 GB utilisÃ© âš ï¸
         â†“
   Nouvelle Ã©criture ?
         â†“
    Que faire ?
```

### Options possibles

1. **Refuser l'Ã©criture** : Retourner une erreur OOM
2. **Supprimer des donnÃ©es** : LibÃ©rer de l'espace automatiquement
3. **Bloquer** : Attendre qu'un processus libÃ¨re de la mÃ©moire (âŒ jamais dans Redis)

## Configuration de la limite mÃ©moire

### maxmemory : La limite absolue

```conf
# redis.conf

# DÃ©finir une limite de mÃ©moire
maxmemory 2gb

# Ou en bytes
maxmemory 2147483648

# Ou avec suffixes
maxmemory 2000mb
maxmemory 2048000kb
```

**Sans maxmemory** :

```conf
# Pas de limite (comportement par dÃ©faut)
maxmemory 0

# âš ï¸ Dangereux en production !
# Redis peut consommer toute la RAM disponible
# â†’ OOM killer du systÃ¨me peut tuer Redis
```

**Calcul recommandÃ©** :

```
MÃ©moire systÃ¨me: 8 GB
â”œâ”€ SystÃ¨me + autres services: 2 GB
â”œâ”€ Buffer/cache kernel: 1 GB
â””â”€ Redis maxmemory: 5 GB (safe)

maxmemory = (RAM totale - 2GB) * 0.75
```

**VÃ©rification runtime** :

```bash
# Voir la limite actuelle
redis-cli CONFIG GET maxmemory
# 1) "maxmemory"
# 2) "2147483648"

# Modifier Ã  chaud (non persistant)
redis-cli CONFIG SET maxmemory 4gb

# Sauvegarder la config
redis-cli CONFIG REWRITE
```

### maxmemory-policy : Choisir le comportement

```conf
# redis.conf
maxmemory-policy noeviction  # DÃ©faut (refuse les Ã©critures)
```

## Les 8 politiques d'Ã©viction

### Vue d'ensemble

| Politique | Cible | Algorithme | Description |
|-----------|-------|------------|-------------|
| `noeviction` | - | - | Refuse les Ã©critures (erreur) |
| `allkeys-lru` | Toutes | LRU | Ã‰victe les moins rÃ©cemment utilisÃ©es |
| `allkeys-lfu` | Toutes | LFU | Ã‰victe les moins frÃ©quemment utilisÃ©es |
| `allkeys-random` | Toutes | Random | Ã‰victe alÃ©atoirement |
| `volatile-lru` | Avec TTL | LRU | Ã‰victe parmi clÃ©s avec TTL (LRU) |
| `volatile-lfu` | Avec TTL | LFU | Ã‰victe parmi clÃ©s avec TTL (LFU) |
| `volatile-random` | Avec TTL | Random | Ã‰victe parmi clÃ©s avec TTL (alÃ©atoire) |
| `volatile-ttl` | Avec TTL | TTL court | Ã‰victe clÃ©s avec TTL le plus court |

### 1. noeviction (dÃ©faut)

**Comportement** : Redis **refuse** toute Ã©criture qui nÃ©cessiterait plus de mÃ©moire.

**MÃ©canisme** :

```
Client â†’ SET newkey "value"
         â†“
Memory usage > maxmemory ?
         â†“
       OUI
         â†“
    Retourne erreur OOM
    "OOM command not allowed when used memory > 'maxmemory'."
         â†“
    Pas d'Ã©criture
```

**Configuration** :

```conf
maxmemory 2gb
maxmemory-policy noeviction
```

**Test** :

```bash
# Remplir Redis jusqu'Ã  la limite
redis-cli CONFIG SET maxmemory 10mb
for i in {1..10000}; do
    redis-cli SET key:$i "$(head -c 1000 /dev/urandom | base64)"
done

# Tentative d'Ã©criture supplÃ©mentaire
redis-cli SET overflow "data"
# (error) OOM command not allowed when used memory > 'maxmemory'.

# Les lectures continuent de fonctionner
redis-cli GET key:1
# "..." - OK

# INCR, APPEND peuvent encore fonctionner si pas d'allocation nouvelle
redis-cli SET counter 0
redis-cli INCR counter
# (integer) 1 - OK (pas d'allocation nouvelle, reuse du buffer)
```

**Avantages** :
- âœ… Aucune perte de donnÃ©es
- âœ… Comportement prÃ©visible
- âœ… Application contrÃ´le les erreurs

**InconvÃ©nients** :
- âŒ Application doit gÃ©rer l'erreur OOM
- âŒ Redis devient read-only
- âŒ Peut bloquer des fonctionnalitÃ©s critiques

**Use cases** :
- Cache critique oÃ¹ aucune donnÃ©e ne doit Ãªtre perdue
- Bases de donnÃ©es oÃ¹ l'intÃ©gritÃ© prime
- Environnements oÃ¹ l'application gÃ¨re elle-mÃªme le nettoyage

### 2. allkeys-lru (Least Recently Used)

**Comportement** : Ã‰victe les clÃ©s les **moins rÃ©cemment utilisÃ©es** parmi TOUTES les clÃ©s.

**MÃ©canisme** :

```
Client â†’ SET newkey "value"
         â†“
Memory usage > maxmemory ?
         â†“
       OUI
         â†“
    Ã‰chantillonne N clÃ©s (maxmemory-samples)
         â†“
    Calcule score LRU pour chaque clÃ©
         â†“
    SÃ©lectionne clÃ© avec plus vieux LRU
         â†“
    Supprime la clÃ© (UNLINK)
         â†“
    RÃ©pÃ¨te jusqu'Ã  memory < maxmemory
         â†“
    Continue l'Ã©criture
```

**Algorithme LRU simplifiÃ©** :

```c
// Structure RedisObject (simplifiÃ©)
typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:24;  // LRU clock: secondes / rÃ©solution
    int refcount;
    void *ptr;
} robj;

// Calcul du score LRU
long long estimateObjectIdleTime(robj *o) {
    unsigned long long lruclock = LRU_CLOCK();
    if (lruclock >= o->lru) {
        return (lruclock - o->lru) * LRU_CLOCK_RESOLUTION;
    } else {
        // Wrap around
        return (LRU_CLOCK_MAX - o->lru + lruclock) * LRU_CLOCK_RESOLUTION;
    }
}

// LRU_CLOCK_RESOLUTION = 1000 ms (1 seconde)
// LRU_CLOCK_MAX = 2^24 - 1 = 16777215
// Range: ~194 jours
```

**Configuration** :

```conf
maxmemory 2gb
maxmemory-policy allkeys-lru
maxmemory-samples 5  # Nombre de clÃ©s Ã©chantillonnÃ©es
```

**Exemple de fonctionnement** :

```bash
# Configuration
redis-cli CONFIG SET maxmemory 10mb
redis-cli CONFIG SET maxmemory-policy allkeys-lru

# Remplir avec des clÃ©s
redis-cli SET key:1 "value"
redis-cli SET key:2 "value"
redis-cli SET key:3 "value"

# AccÃ©der Ã  certaines clÃ©s
redis-cli GET key:1  # Met Ã  jour LRU de key:1
sleep 2
redis-cli GET key:2  # Met Ã  jour LRU de key:2

# Observer les idle times
redis-cli OBJECT IDLETIME key:1  # ~2 secondes
redis-cli OBJECT IDLETIME key:2  # ~0 secondes
redis-cli OBJECT IDLETIME key:3  # ~5 secondes

# Quand maxmemory est atteinte, key:3 sera Ã©victÃ©e en premier
```

**Avantages** :
- âœ… Garde les donnÃ©es frÃ©quemment accÃ©dÃ©es
- âœ… Bon compromis performance/simplicitÃ©
- âœ… Fonctionne bien pour la plupart des caches

**InconvÃ©nients** :
- âŒ Approximation (Ã©chantillonnage, pas vrai LRU)
- âŒ Les "scans" peuvent invalider le cache
- âŒ Peut Ã©vacuer des donnÃ©es sans TTL

**Use cases** :
- Cache gÃ©nÃ©ral
- Sessions utilisateur
- DonnÃ©es frÃ©quemment accÃ©dÃ©es

### 3. allkeys-lfu (Least Frequently Used)

**Comportement** : Ã‰victe les clÃ©s les **moins frÃ©quemment utilisÃ©es** parmi TOUTES les clÃ©s.

**MÃ©canisme LFU** :

Redis implÃ©mente un LFU probabiliste avec decay :

```c
// Structure du champ LRU en mode LFU (24 bits)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 16 bits        â”‚ 8 bits     â”‚
â”‚ Compteur accÃ¨s â”‚ Decay time â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

// Compteur : 0-255 (logarithmique)
// Decay : Timestamp du dernier accÃ¨s
```

**Algorithme de comptage** :

```c
// IncrÃ©mentation du compteur (probabiliste)
uint8_t LFULogIncr(uint8_t counter) {
    if (counter == 255) return 255;

    double r = (double)rand() / RAND_MAX;
    double baseval = counter - LFU_INIT_VAL;
    if (baseval < 0) baseval = 0;

    double p = 1.0 / (baseval * server.lfu_log_factor + 1);

    if (r < p) counter++;
    return counter;
}

// Avec lfu_log_factor=10:
// 1 hit  â†’ counter=1 (probabilitÃ© 100%)
// 10 hits â†’ counter=5 (probabilitÃ© ~50% au 10e hit)
// 100 hits â†’ counter=10
// 1000 hits â†’ counter=15
```

**Decay du compteur** :

```c
// RÃ©duction du compteur dans le temps
unsigned long LFUDecrAndReturn(robj *o) {
    unsigned long ldt = o->lru >> 8;  // Last decrement time
    unsigned long counter = o->lru & 255;

    if (LFUTimeElapsed(ldt) >= server.lfu_decay_time) {
        if (counter > 0) {
            counter--;
        }
    }

    return counter;
}
```

**Configuration** :

```conf
maxmemory 2gb
maxmemory-policy allkeys-lfu

# Facteur logarithmique (0-255)
lfu-log-factor 10   # DÃ©faut
# Plus Ã©levÃ© = compteur augmente plus lentement
# Plus bas = compteur augmente plus rapidement

# Temps de decay en minutes
lfu-decay-time 1    # DÃ©faut: 1 minute
# Temps avant que le compteur dÃ©croisse
```

**Impact de lfu-log-factor** :

```
lfu-log-factor=1:
100 hits â†’ counter â‰ˆ 50
1000 hits â†’ counter â‰ˆ 100

lfu-log-factor=10 (dÃ©faut):
100 hits â†’ counter â‰ˆ 10
1000 hits â†’ counter â‰ˆ 15

lfu-log-factor=100:
100 hits â†’ counter â‰ˆ 3
1000 hits â†’ counter â‰ˆ 5
```

**Exemple** :

```bash
redis-cli CONFIG SET maxmemory-policy allkeys-lfu
redis-cli CONFIG SET lfu-log-factor 10
redis-cli CONFIG SET lfu-decay-time 1

# CrÃ©er des clÃ©s avec diffÃ©rentes frÃ©quences
for i in {1..100}; do redis-cli GET key:hot; done      # 100 accÃ¨s
for i in {1..10}; do redis-cli GET key:warm; done      # 10 accÃ¨s
redis-cli GET key:cold                                 # 1 accÃ¨s

# Observer les frÃ©quences
redis-cli OBJECT FREQ key:hot   # ~15
redis-cli OBJECT FREQ key:warm  # ~5
redis-cli OBJECT FREQ key:cold  # ~1

# key:cold sera Ã©victÃ©e en premier
```

**Avantages** :
- âœ… Meilleur que LRU pour patterns d'accÃ¨s rÃ©pÃ©titifs
- âœ… Garde les donnÃ©es vraiment populaires
- âœ… RÃ©siste aux scans qui invalident le LRU

**InconvÃ©nients** :
- âŒ Plus complexe Ã  comprendre
- âŒ NÃ©cessite tuning (log_factor, decay_time)
- âŒ Peut favoriser les vieilles donnÃ©es populaires

**Use cases** :
- Cache avec accÃ¨s trÃ¨s rÃ©pÃ©titifs
- DonnÃ©es avec popularitÃ© stable
- Protection contre cache pollution

### 4. allkeys-random

**Comportement** : Ã‰victe des clÃ©s **alÃ©atoirement** parmi TOUTES les clÃ©s.

**MÃ©canisme** :

```
Client â†’ SET newkey "value"
         â†“
Memory usage > maxmemory ?
         â†“
       OUI
         â†“
    SÃ©lectionne une clÃ© alÃ©atoire
         â†“
    Supprime la clÃ©
         â†“
    RÃ©pÃ¨te jusqu'Ã  memory < maxmemory
         â†“
    Continue l'Ã©criture
```

**Configuration** :

```conf
maxmemory 2gb
maxmemory-policy allkeys-random
```

**Avantages** :
- âœ… TrÃ¨s rapide (pas de calcul de score)
- âœ… PrÃ©visible en performance
- âœ… Simple Ã  comprendre

**InconvÃ©nients** :
- âŒ Aucune intelligence
- âŒ Peut Ã©vacuer des donnÃ©es importantes
- âŒ ImprÃ©visible en rÃ©sultat

**Use cases** :
- Tests/dÃ©veloppement
- Cas oÃ¹ toutes les donnÃ©es ont la mÃªme importance
- Performance absolue requise

### 5. volatile-lru

**Comportement** : Ã‰victe parmi les clÃ©s **avec TTL**, selon l'algorithme LRU.

**MÃ©canisme** :

```
Client â†’ SET newkey "value"
         â†“
Memory usage > maxmemory ?
         â†“
       OUI
         â†“
    Ã‰chantillonne N clÃ©s AVEC TTL
         â†“
    Si aucune clÃ© avec TTL trouvÃ©e
         â†“
    Retourne erreur OOM
         â†“
    Sinon, calcule score LRU
         â†“
    Ã‰victe clÃ© avec plus vieux LRU
         â†“
    Continue l'Ã©criture
```

**Configuration** :

```conf
maxmemory 2gb
maxmemory-policy volatile-lru
maxmemory-samples 5
```

**Exemple** :

```bash
redis-cli CONFIG SET maxmemory 10mb
redis-cli CONFIG SET maxmemory-policy volatile-lru

# ClÃ©s sans TTL (ne seront PAS Ã©victÃ©es)
redis-cli SET important:1 "critical data"
redis-cli SET important:2 "critical data"

# ClÃ©s avec TTL (candidates Ã  l'Ã©viction)
redis-cli SET cache:1 "data" EX 3600
redis-cli SET cache:2 "data" EX 3600
redis-cli SET cache:3 "data" EX 3600

# AccÃ¨s Ã  cache:1 et cache:2
redis-cli GET cache:1
redis-cli GET cache:2

# Quand maxmemory atteinte, cache:3 sera Ã©victÃ©e (LRU le plus vieux)
# important:1 et important:2 ne seront JAMAIS Ã©victÃ©es
```

**Avantages** :
- âœ… ProtÃ¨ge les donnÃ©es sans TTL
- âœ… Bon contrÃ´le sur ce qui est Ã©victable
- âœ… Combine Ã©viction et expiration

**InconvÃ©nients** :
- âŒ Erreur OOM si aucune clÃ© avec TTL
- âŒ NÃ©cessite discipline de mettre TTL sur cache
- âŒ Performance dÃ©pend du ratio clÃ©s avec/sans TTL

**Use cases** :
- Mix de donnÃ©es permanentes et cache
- Applications critiques avec cache secondaire
- ContrÃ´le fin de l'Ã©viction

### 6. volatile-lfu

**Comportement** : Ã‰victe parmi les clÃ©s **avec TTL**, selon l'algorithme LFU.

**Configuration** :

```conf
maxmemory 2gb
maxmemory-policy volatile-lfu
lfu-log-factor 10
lfu-decay-time 1
```

**Avantages/InconvÃ©nients** : Identiques Ã  volatile-lru, mais avec LFU.

### 7. volatile-random

**Comportement** : Ã‰victe **alÃ©atoirement** parmi les clÃ©s avec TTL.

**Configuration** :

```conf
maxmemory 2gb
maxmemory-policy volatile-random
```

**Use cases** :
- Performance maximale avec protection des donnÃ©es sans TTL
- Ã‰viction Ã©quitable parmi le cache

### 8. volatile-ttl

**Comportement** : Ã‰victe les clÃ©s avec le **TTL le plus court** parmi les clÃ©s avec TTL.

**MÃ©canisme** :

```
Client â†’ SET newkey "value"
         â†“
Memory usage > maxmemory ?
         â†“
       OUI
         â†“
    Ã‰chantillonne N clÃ©s AVEC TTL
         â†“
    Pour chaque clÃ©, lit TTL dans expires dict
         â†“
    SÃ©lectionne clÃ© avec TTL le plus court
         â†“
    Supprime la clÃ©
         â†“
    Continue l'Ã©criture
```

**Configuration** :

```conf
maxmemory 2gb
maxmemory-policy volatile-ttl
```

**Exemple** :

```bash
redis-cli CONFIG SET maxmemory-policy volatile-ttl

# ClÃ©s avec diffÃ©rents TTL
redis-cli SET temp:1 "data" EX 60      # 1 minute
redis-cli SET temp:2 "data" EX 300     # 5 minutes
redis-cli SET temp:3 "data" EX 3600    # 1 heure

# Quand maxmemory atteinte, temp:1 sera Ã©victÃ©e en premier
```

**Avantages** :
- âœ… Logique intuitive (Ã©vacue ce qui expire bientÃ´t)
- âœ… ComplÃ©mentaire Ã  l'expiration automatique
- âœ… Prioritise les donnÃ©es Ã  durÃ©e de vie longue

**InconvÃ©nients** :
- âŒ Peut Ã©vacuer des donnÃ©es frÃ©quemment accÃ©dÃ©es
- âŒ Ignore la popularitÃ©
- âŒ Erreur OOM si aucune clÃ© avec TTL

**Use cases** :
- Cache avec diffÃ©rentes prioritÃ©s via TTL
- DonnÃ©es temporaires avec urgence variable

## L'Ã©chantillonnage : maxmemory-samples

### Le problÃ¨me de performance

Calculer le score LRU/LFU de **toutes** les clÃ©s serait trop coÃ»teux :

```
1 million de clÃ©s:
â”œâ”€ LRU parfait : Parcourir 1M clÃ©s â†’ ~100ms
â””â”€ Ã‰chantillonnage : Parcourir 5 clÃ©s â†’ <0.1ms
```

### L'Ã©chantillonnage probabiliste

Redis utilise un Ã©chantillonnage alÃ©atoire :

```python
# Pseudo-code de l'Ã©viction
def evict_key():
    best_key = None
    best_score = 0

    # Ã‰chantillonne N clÃ©s alÃ©atoires
    for _ in range(maxmemory_samples):
        key = random_key()
        score = calculate_score(key)  # LRU, LFU, TTL, etc.

        if score > best_score:
            best_score = score
            best_key = key

    delete(best_key)
```

### Configuration

```conf
# redis.conf
maxmemory-samples 5  # DÃ©faut

# Plus de samples = meilleure prÃ©cision, plus de CPU
maxmemory-samples 3   # Rapide, moins prÃ©cis
maxmemory-samples 10  # Lent, plus prÃ©cis
maxmemory-samples 20  # TrÃ¨s lent, trÃ¨s prÃ©cis
```

### Impact sur la prÃ©cision

**Test de prÃ©cision LRU** (source: Redis doc) :

```
Ã‰chantillonnage vs LRU parfait:

maxmemory-samples 3:  ~70% de prÃ©cision
maxmemory-samples 5:  ~85% de prÃ©cision (dÃ©faut)
maxmemory-samples 10: ~95% de prÃ©cision
maxmemory-samples 20: ~99% de prÃ©cision

CoÃ»t CPU:
samples=3  â†’ 1x
samples=5  â†’ 1.5x
samples=10 â†’ 3x
samples=20 â†’ 6x
```

**Visualisation** :

```
LRU parfait (thÃ©orique):
ClÃ©s Ã©victÃ©es: [oldest] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [newest]

samples=3:
ClÃ©s Ã©victÃ©es: [oldest] â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–ˆâ–ˆâ–‘â–‘â–‘â–ˆ [newest]
                           â†‘ Quelques "jeunes" clÃ©s Ã©victÃ©es par erreur

samples=10:
ClÃ©s Ã©victÃ©es: [oldest] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ [newest]
                                     â†‘ TrÃ¨s proche du LRU parfait
```

### Recommandations

```conf
# Environnement de dÃ©veloppement
maxmemory-samples 3  # Vitesse > prÃ©cision

# Production standard
maxmemory-samples 5  # Bon Ã©quilibre (dÃ©faut)

# Production critique
maxmemory-samples 10  # PrÃ©cision importante

# Haute charge, CPU limitÃ©
maxmemory-samples 3

# Faible charge, prÃ©cision maximale
maxmemory-samples 20
```

## Le processus d'Ã©viction en dÃ©tail

### Flow d'exÃ©cution complet

```
Client â†’ SET key "value"
    â†“
1. Parse command
    â†“
2. VÃ©rifie type de commande (write ?)
    â†“
3. VÃ©rifie mÃ©moire AVANT exÃ©cution
    â†“
used_memory + estimated_size > maxmemory ?
    â†“
  OUI â”€â”€â”€â†’ 4. Applique Ã©viction
    â”‚           â†“
    â”‚       Policy = noeviction ?
    â”‚           â†“
    â”‚         OUI â”€â”€â”€â†’ Retourne erreur OOM
    â”‚           â”‚
    â”‚         NON
    â”‚           â†“
    â”‚       5. Pool d'Ã©viction
    â”‚           â†“
    â”‚       Ã‰chantillonne maxmemory_samples clÃ©s
    â”‚           â†“
    â”‚       Filtre selon policy (all vs volatile)
    â”‚           â†“
    â”‚       Calcule score (LRU/LFU/TTL/Random)
    â”‚           â†“
    â”‚       Trie par score
    â”‚           â†“
    â”‚       6. Supprime clÃ©(s)
    â”‚           â†“
    â”‚       UNLINK (async) ou DEL (sync)
    â”‚           â†“
    â”‚       RÃ©pÃ¨te si encore > maxmemory
    â”‚           â†“
    â”‚  NON  7. ExÃ©cute commande
    â””â”€â”€â”€â”€â”€â”€â”€â”€â†’
```

### Estimation de la taille

Redis estime la taille de la nouvelle allocation avant d'exÃ©cuter la commande :

```c
// Estimation simplifiÃ©e
size_t estimated_size = 0;

switch (command) {
    case SET:
        estimated_size = sizeof(robj) + strlen(key) + strlen(value);
        break;
    case LPUSH:
        estimated_size = sizeof(listNode) + strlen(value);
        break;
    case SADD:
        estimated_size = sizeof(dictEntry) + strlen(member);
        break;
    // ...
}

if (used_memory + estimated_size > maxmemory) {
    evict();
}
```

### Pool d'Ã©viction

Redis 3.0+ utilise un **pool** pour amÃ©liorer la qualitÃ© de l'Ã©viction :

```c
#define EVPOOL_SIZE 16

struct evictionPoolEntry {
    unsigned long long idle;  // Score (idle time, freq, ttl)
    sds key;                  // ClÃ© candidate
    sds cached;               // SDS cached pour performance
    int dbid;                 // Database ID
};

static struct evictionPoolEntry EvictionPoolLRU[EVPOOL_SIZE];
```

**MÃ©canisme** :

```
1. Pool initialement vide (16 slots)
2. Ã‰chantillonne maxmemory_samples clÃ©s
3. Calcule score pour chaque clÃ©
4. InsÃ¨re dans le pool si score > min(pool)
5. RÃ©pÃ¨te jusqu'Ã  pool plein
6. Ã‰victe clÃ© avec plus haut score du pool
7. Continue si nÃ©cessaire
```

**Avantage** : AmÃ©liore la qualitÃ© sans augmenter maxmemory-samples.

## Comparaison des politiques

### Tableau dÃ©cisionnel

| CritÃ¨re | noeviction | allkeys-lru | allkeys-lfu | volatile-lru | volatile-ttl |
|---------|-----------|-------------|-------------|--------------|--------------|
| **Perte de donnÃ©es** | âŒ Jamais | âœ… Cache | âœ… Cache | âš ï¸ Cache | âš ï¸ Cache |
| **Erreur OOM** | âœ… Oui | âŒ Jamais | âŒ Jamais | âš ï¸ Si pas TTL | âš ï¸ Si pas TTL |
| **CPU** | Minimal | Faible | Moyen | Faible | Faible |
| **PrÃ©cision** | N/A | Bonne | Meilleure | Bonne | Moyenne |
| **ComplexitÃ©** | Simple | Simple | Moyenne | Moyenne | Simple |

### Matrice de dÃ©cision

```
Votre cas d'usage:

1. "J'ai uniquement du cache" ?
   â””â”€> allkeys-lru (ou allkeys-lfu si accÃ¨s rÃ©pÃ©titifs)

2. "J'ai donnÃ©es permanentes + cache" ?
   â””â”€> volatile-lru (avec TTL sur cache)

3. "Toutes mes donnÃ©es ont la mÃªme importance" ?
   â””â”€> allkeys-random

4. "Mes donnÃ©es sont critiques" ?
   â””â”€> noeviction (+ monitoring + alerting)

5. "Mon cache a diffÃ©rentes prioritÃ©s" ?
   â””â”€> volatile-ttl (TTL court = basse prioritÃ©)

6. "J'ai beaucoup de scans/parcours" ?
   â””â”€> allkeys-lfu (rÃ©siste mieux)

7. "Je veux la performance maximale" ?
   â””â”€> allkeys-random
```

### Benchmarks comparatifs

**Hit ratio avec workload rÃ©el** :

```
Workload: 80/20 (80% accÃ¨s sur 20% des donnÃ©es)

allkeys-lru:    ~82% hit ratio
allkeys-lfu:    ~87% hit ratio  â† Meilleur
allkeys-random: ~60% hit ratio
volatile-lru:   ~80% hit ratio (avec 50% des clÃ©s avec TTL)
```

**CPU overhead** :

```
Baseline (noeviction): 1.0x

allkeys-random:  1.02x
allkeys-lru:     1.15x
allkeys-lfu:     1.25x
volatile-lru:    1.18x
volatile-ttl:    1.20x
```

## Configuration par cas d'usage

### 1. Cache pur (type Memcached)

```conf
# Configuration recommandÃ©e
maxmemory 8gb
maxmemory-policy allkeys-lru
maxmemory-samples 10

# Ou si accÃ¨s trÃ¨s rÃ©pÃ©titifs
maxmemory-policy allkeys-lfu
lfu-log-factor 10
lfu-decay-time 1
```

**Justification** :
- Toutes les donnÃ©es sont du cache â†’ `allkeys-*`
- LRU fonctionne bien pour la plupart des patterns
- LFU si vous avez des "hits" trÃ¨s concentrÃ©s

### 2. Session store

```conf
maxmemory 4gb
maxmemory-policy volatile-lru
maxmemory-samples 5

# Sessions avec TTL
# SET session:abc123 {data} EX 1800  # 30 minutes
```

**Justification** :
- Sessions ont toutes un TTL â†’ `volatile-*`
- LRU Ã©vacue les sessions inactives
- Protection contre OOM si TTL oubliÃ©s

### 3. Mix donnÃ©es permanentes + cache

```conf
maxmemory 16gb
maxmemory-policy volatile-lru
maxmemory-samples 10

# DonnÃ©es permanentes: PAS de TTL
# SET user:123:profile {data}

# Cache: AVEC TTL
# SET cache:api:result {data} EX 3600
```

**Justification** :
- SÃ©pare clairement permanent vs cache via TTL
- Aucun risque d'Ã©viction de donnÃ©es importantes
- Flexible et sÃ©curisÃ©

### 4. Application critique (pas de perte)

```conf
maxmemory 8gb
maxmemory-policy noeviction

# Monitoring et alerting obligatoires
# Alert si used_memory > 80% maxmemory
```

**Justification** :
- Aucune perte de donnÃ©es acceptable
- Application gÃ¨re l'erreur OOM
- Nettoyage manuel ou automatique via application

### 5. Cache de rÃ©sultats coÃ»teux

```conf
maxmemory 32gb
maxmemory-policy allkeys-lfu
lfu-log-factor 10
lfu-decay-time 5

maxmemory-samples 10
```

**Justification** :
- Calculs coÃ»teux â†’ maximiser rÃ©utilisation
- LFU garde les rÃ©sultats vraiment populaires
- decay-time plus long pour favoriser stabilitÃ©

### 6. Multi-tenant avec prioritÃ©s

```conf
maxmemory 64gb
maxmemory-policy volatile-ttl
maxmemory-samples 10

# Tenant premium: TTL long
# SET tenant:premium:123 {data} EX 86400  # 24h

# Tenant standard: TTL court
# SET tenant:std:456 {data} EX 3600  # 1h
```

**Justification** :
- TTL comme mÃ©canisme de prioritÃ©
- Ã‰vacue d'abord les donnÃ©es moins prioritaires
- QoS naturel via TTL

## Monitoring de l'Ã©viction

### MÃ©triques clÃ©s

```bash
# Nombre total d'Ã©victions
redis-cli INFO stats | grep evicted_keys
# evicted_keys:12543

# Taux d'Ã©viction (calculÃ©)
# evictions_per_sec = delta(evicted_keys) / delta(time)

# MÃ©moire utilisÃ©e
redis-cli INFO memory | grep used_memory:
# used_memory:2147483648

# Ratio mÃ©moire utilisÃ©e
redis-cli INFO memory | grep used_memory_peak:
# used_memory_peak:2200000000

# Hit ratio
redis-cli INFO stats | grep keyspace
# keyspace_hits:1000000
# keyspace_misses:100000
# Hit ratio = hits / (hits + misses) = 90.9%
```

### Commandes de diagnostic

```bash
# VÃ©rifier la politique actuelle
redis-cli CONFIG GET maxmemory-policy
# 1) "maxmemory-policy"
# 2) "allkeys-lru"

# Observer les clÃ©s candidates Ã  l'Ã©viction
redis-cli --bigkeys
# Identifie les plus grosses clÃ©s

# Analyser la distribution des idle times
redis-cli --scan --pattern 'cache:*' | head -100 | while read key; do
    idle=$(redis-cli OBJECT IDLETIME "$key")
    echo "$key: $idle seconds"
done | sort -t: -k2 -n

# Observer en temps rÃ©el
redis-cli --stat
# Shows ops/sec, hit%, eviction%, etc.
```

### Script de monitoring avancÃ©

```python
import redis
import time

def monitor_eviction(r, interval=60):
    stats_before = r.info('stats')
    mem_before = r.info('memory')

    time.sleep(interval)

    stats_after = r.info('stats')
    mem_after = r.info('memory')

    # Calculs
    evictions = stats_after['evicted_keys'] - stats_before['evicted_keys']
    eviction_rate = evictions / interval

    used_mem = mem_after['used_memory']
    max_mem = r.config_get('maxmemory')['maxmemory']
    mem_ratio = (used_mem / int(max_mem)) * 100 if max_mem != '0' else 0

    hits = stats_after['keyspace_hits'] - stats_before['keyspace_hits']
    misses = stats_after['keyspace_misses'] - stats_before['keyspace_misses']
    hit_ratio = (hits / (hits + misses) * 100) if (hits + misses) > 0 else 0

    print(f"""
Ã‰victions: {evictions} ({eviction_rate:.2f}/sec)
MÃ©moire: {used_mem / 1024 / 1024:.2f} MB / {int(max_mem) / 1024 / 1024:.2f} MB ({mem_ratio:.1f}%)
Hit ratio: {hit_ratio:.1f}%
    """)

    # Alerting
    if mem_ratio > 90:
        alert("CRITICAL: Memory usage > 90%")
    if eviction_rate > 100:
        alert("WARNING: High eviction rate")
    if hit_ratio < 70:
        alert("WARNING: Low hit ratio")
```

### Alertes Prometheus

```yaml
# prometheus/alerts.yml
groups:
  - name: redis_eviction
    rules:
      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_config_maxmemory * 100 > 90
        for: 5m
        annotations:
          summary: "Redis memory usage > 90%"

      - alert: RedisHighEvictionRate
        expr: rate(redis_evicted_keys_total[5m]) > 100
        for: 5m
        annotations:
          summary: "High eviction rate (>100/sec)"

      - alert: RedisLowHitRatio
        expr: redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total) < 0.7
        for: 10m
        annotations:
          summary: "Hit ratio < 70%"
```

## Impact sur la performance

### Latence d'Ã©viction

**Mesure** :

```bash
redis-cli CONFIG SET latency-monitor-threshold 100

# Remplir jusqu'Ã  maxmemory
# ... attendre les Ã©victions

redis-cli LATENCY LATEST
# 1) 1) "eviction-cycle"
#    2) (integer) 1733847600
#    3) (integer) 15
#    4) (integer) 50
# 15ms de latency max, 50ms au 99e percentile
```

**Impact selon la politique** :

```
allkeys-random:  0.1-0.5 ms   (trÃ¨s rapide)
allkeys-lru:     0.5-2 ms     (rapide)
allkeys-lfu:     1-5 ms       (moyen)
volatile-lru:    0.5-3 ms     (rapide, dÃ©pend du ratio)
volatile-ttl:    0.5-3 ms     (rapide)
```

### Throughput

**Impact sur le dÃ©bit** :

```
Baseline (pas d'Ã©viction): 100k ops/sec

Avec Ã©viction active:
- allkeys-random:  95k ops/sec (-5%)
- allkeys-lru:     90k ops/sec (-10%)
- allkeys-lfu:     85k ops/sec (-15%)
- volatile-lru:    92k ops/sec (-8%)
```

## PiÃ¨ges et considÃ©rations

### 1. Oublier maxmemory en production

```conf
# âŒ Dangereux
maxmemory 0  # Pas de limite

# âœ… Toujours dÃ©finir
maxmemory 8gb
maxmemory-policy allkeys-lru
```

### 2. noeviction sans monitoring

```conf
# âŒ Bombe Ã  retardement
maxmemory 2gb
maxmemory-policy noeviction
# ... aucun monitoring

# âœ… Avec monitoring
maxmemory 2gb
maxmemory-policy noeviction
# + Alerting si used_memory > 80%
# + Nettoyage automatique ou manuel
```

### 3. volatile-* sans discipline TTL

```python
# âŒ Erreur OOM en production
redis.set('cache:data', value)  # Pas de TTL !
redis.set('important:data', value)  # Pas de TTL !

# Configuration: volatile-lru
# â†’ Erreur OOM car aucune clÃ© Ã©victable

# âœ… Discipline stricte
redis.setex('cache:data', 3600, value)  # Cache avec TTL
redis.set('important:data', value)      # Permanent sans TTL
```

### 4. samples trop faible

```conf
# âŒ Mauvaise prÃ©cision
maxmemory-samples 1  # ~50% prÃ©cision

# âœ… Au moins 5
maxmemory-samples 5  # ~85% prÃ©cision
```

### 5. Confusion LRU vs LFU

```
Cas d'usage          Recommandation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AccÃ¨s uniformes      â†’ LRU
AccÃ¨s rÃ©pÃ©titifs     â†’ LFU
Scans frÃ©quents      â†’ LFU
Cache de requÃªtes    â†’ LRU
Hot data stable      â†’ LFU
```

### 6. Ã‰viction et rÃ©plication

**Important** : L'Ã©viction se produit sur le master ET les replicas :

```
Master:
â”œâ”€ DÃ©tecte maxmemory atteinte
â”œâ”€ Applique Ã©viction
â”œâ”€ Supprime clÃ© (DEL)
â””â”€ RÃ©plique DEL vers replicas

Replica:
â”œâ”€ ReÃ§oit DEL du master
â””â”€ Supprime clÃ©

Important: Replica peut AUSSI atteindre maxmemory localement
â†’ Configure maxmemory sur les replicas aussi !
```

### 7. Grande clÃ©s et Ã©viction

```bash
# ProblÃ¨me: Ã‰viction d'une grande clÃ© peut bloquer
SADD bigset $(seq 1 10000000)  # 10M membres

# Si bigset est Ã©victÃ©e:
# DEL bigset â†’ ~100ms de blocage !

# Solution: Activer lazyfree
CONFIG SET lazyfree-lazy-eviction yes
# Ã‰viction devient asynchrone (UNLINK)
```

## Configuration production recommandÃ©e

```conf
# redis.conf

################################ MEMORY ################################

# Limite mÃ©moire (ajuster selon votre RAM)
maxmemory 8gb

# Politique d'Ã©viction (choisir selon cas d'usage)
maxmemory-policy allkeys-lru

# PrÃ©cision de l'Ã©viction
maxmemory-samples 10

# Ã‰viction asynchrone (recommandÃ©)
lazyfree-lazy-eviction yes
lazyfree-lazy-expire yes
lazyfree-lazy-server-del yes
replica-lazy-flush yes

# Si allkeys-lfu ou volatile-lfu
lfu-log-factor 10
lfu-decay-time 1

# Seuil latence monitoring
latency-monitor-threshold 100

################################ MONITORING ################################

# Stats dÃ©taillÃ©es
info-print-stats yes

# Slowlog
slowlog-log-slower-than 10000
slowlog-max-len 128
```

## Conclusion

Les politiques d'Ã©viction sont un mÃ©canisme crucial pour gÃ©rer Redis en production. Points clÃ©s :

- **noeviction** : SÃ»r mais nÃ©cessite gestion applicative
- **allkeys-lru** : Meilleur choix par dÃ©faut pour du cache pur
- **allkeys-lfu** : Meilleur pour patterns d'accÃ¨s rÃ©pÃ©titifs
- **volatile-*** : Protection des donnÃ©es permanentes
- **maxmemory-samples** : Balance entre prÃ©cision et CPU (5-10 recommandÃ©)
- **lazyfree-lazy-eviction** : Toujours activer en production

Le choix de la politique dÃ©pend de votre cas d'usage, mais la rÃ¨gle d'or est : **toujours dÃ©finir maxmemory et une politique adaptÃ©e**.

La section suivante approfondira la comparaison LRU vs LFU vs Random avec des benchmarks dÃ©taillÃ©s.

â­ï¸ [LRU vs LFU vs Random : Choisir la bonne stratÃ©gie](/04-cycle-vie-donnee/04-lru-vs-lfu-vs-random.md)
