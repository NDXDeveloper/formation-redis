ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 4.5 Namespaces et bonnes pratiques de nommage (Key patterns)

## Introduction

Dans Redis, **tout est une clÃ©**. Contrairement aux bases de donnÃ©es relationnelles avec leurs schÃ©mas, tables et colonnes, Redis est un simple espace de clÃ©s plat (flat keyspace). Cette simplicitÃ© est Ã  la fois sa force et son dÃ©fi : sans discipline de nommage, un keyspace Redis peut rapidement devenir un chaos ingÃ©rable.

Les namespaces et patterns de nommage ne sont pas une fonctionnalitÃ© native de Redis, mais une **convention d'organisation** que vous imposez. Bien implÃ©mentÃ©s, ils permettent :

- ğŸ¯ **Organisation logique** : Retrouver facilement les donnÃ©es
- ğŸ” **Recherche efficace** : Filtrer avec SCAN/KEYS
- ğŸš€ **ScalabilitÃ©** : Partitionnement et sharding prÃ©visibles
- ğŸ”’ **SÃ©curitÃ©** : ACLs granulaires par namespace
- ğŸ“Š **Monitoring** : MÃ©triques par type de donnÃ©es
- ğŸ§¹ **Maintenance** : Nettoyage et TTL par catÃ©gorie

## Le keyspace Redis : Architecture plate

### Structure fondamentale

```
Redis Database (DB 0):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flat Keyspace                      â”‚
â”‚                                    â”‚
â”‚ "user:1:name"                      â”‚
â”‚ "user:1:email"                     â”‚
â”‚ "user:2:name"                      â”‚
â”‚ "session:abc123"                   â”‚
â”‚ "cache:api:weather:paris"          â”‚
â”‚ "queue:emails"                     â”‚
â”‚ "counter:views:article:42"         â”‚
â”‚ "lock:resource:db"                 â”‚
â”‚ ...                                â”‚
â”‚                                    â”‚
â”‚ PAS de hiÃ©rarchie rÃ©elle           â”‚
â”‚ PAS de dossiers                    â”‚
â”‚ PAS de tables                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implication de la structure plate

```c
// Internalement, Redis stocke TOUT dans un dictionnaire
typedef struct redisDb {
    dict *dict;           // Hash table: key â†’ value
    dict *expires;        // Hash table: key â†’ expiration
    // ...
} redisDb;

// Une clÃ© est juste une string, RIEN de plus
// "user:1:name" n'a PAS de relation sÃ©mantique avec "user:2:name"
// C'est juste deux strings diffÃ©rentes
```

**ConsÃ©quence critique** : Toute organisation logique doit Ãªtre **imposÃ©e par convention** dans le nom des clÃ©s.

## SÃ©parateurs : Le choix fondamental

### Les trois sÃ©parateurs courants

#### 1. Deux-points `:` (RECOMMANDÃ‰)

```bash
user:123:profile
cache:api:weather:paris
session:abc123:data
counter:views:article:42
```

**Avantages** :
- âœ… Standard de facto dans la communautÃ© Redis
- âœ… Lisible et concis
- âœ… Pas d'Ã©chappement nÃ©cessaire
- âœ… Compatible URL-encoding
- âœ… Fonctionne avec SCAN patterns

**Documentation officielle** : Redis utilise `:` dans tous ses exemples.

#### 2. Slash `/` (style REST)

```bash
user/123/profile
cache/api/weather/paris
session/abc123/data
```

**Avantages** :
- âœ… Familier aux dÃ©veloppeurs web
- âœ… Style hiÃ©rarchique visuel

**InconvÃ©nients** :
- âš ï¸ Moins standard dans Redis
- âš ï¸ Peut nÃ©cessiter Ã©chappement dans certains contextes

#### 3. Pipe `|` (rare)

```bash
user|123|profile
cache|api|weather|paris
```

**InconvÃ©nients** :
- âŒ Non standard
- âŒ Moins lisible
- âŒ Peut causer confusion avec opÃ©rateurs Unix

### Comparaison technique

```bash
# SCAN avec pattern
SCAN 0 MATCH user:*     # âœ… Standard
SCAN 0 MATCH user/*     # âš ï¸ Fonctionne mais moins idiomatique
SCAN 0 MATCH user|*     # âš ï¸ Fonctionne mais dÃ©routant

# Tri lexicographique
user:1:name
user:2:name
user:10:name   # Ordre: 1, 10, 2 (tri string !)

# Longueur
"user:123:profile"  â†’ 17 bytes
"user/123/profile"  â†’ 17 bytes
"user|123|profile"  â†’ 17 bytes
# Identique, choix purement conventionnel
```

**Recommandation** : **Toujours utiliser `:`** sauf raison spÃ©cifique.

### MÃ©lange de sÃ©parateurs (ANTI-PATTERN)

```bash
# âŒ MAUVAIS : IncohÃ©rent
user:123/profile
cache|api:weather/paris
session:abc123|data

# âœ… BON : CohÃ©rent
user:123:profile
cache:api:weather:paris
session:abc123:data
```

## Patterns de nommage standard

### Pattern gÃ©nÃ©ral recommandÃ©

```
<type>:<entity>:<id>:<attribute>
  â”‚      â”‚       â”‚      â”‚
  â”‚      â”‚       â”‚      â””â”€ Attribut spÃ©cifique (optionnel)
  â”‚      â”‚       â””â”€ Identifiant unique
  â”‚      â””â”€ Type d'entitÃ©
  â””â”€ CatÃ©gorie de donnÃ©es
```

**Exemples** :

```bash
# Utilisateur
user:123:profile          # Type: user, ID: 123, Attr: profile
user:123:settings
user:123:preferences

# Session
session:abc123:data       # Type: session, ID: abc123
session:abc123:cart

# Cache
cache:api:weather:paris   # Type: cache, Source: api, Query: weather:paris
cache:db:user:123
cache:query:a1b2c3

# Compteur
counter:views:article:42  # Type: counter, Metric: views, Target: article:42
counter:likes:post:789

# File d'attente
queue:emails              # Type: queue, Purpose: emails
queue:jobs:high
queue:notifications

# Lock
lock:resource:database    # Type: lock, Resource: database
lock:file:upload:123
```

### Pattern avec namespace d'application

Pour applications multi-tenants ou microservices :

```bash
<app>:<type>:<entity>:<id>:<attribute>
  â”‚     â”‚      â”‚       â”‚      â”‚
  â”‚     â”‚      â”‚       â”‚      â””â”€ Attribut
  â”‚     â”‚      â”‚       â””â”€ ID
  â”‚     â”‚      â””â”€ EntitÃ©
  â”‚     â””â”€ Type
  â””â”€ Application/Tenant

# Exemples
myapp:user:123:profile
myapp:session:abc:data
myapp:cache:api:result

# Multi-tenant
tenant:acme:user:123:profile
tenant:acme:cache:data
tenant:xyz:user:456:profile
```

### Pattern hiÃ©rarchique profond

```bash
# E-commerce
product:category:electronics:subcategory:phones:brand:apple:model:iphone15

# Trop profond ! Difficile Ã  maintenir
# PrÃ©fÃ©rer:
product:electronics:phones:apple:iphone15

# Ou sÃ©parer les dimensions:
product:iphone15:category   â†’ "electronics:phones"
product:iphone15:brand      â†’ "apple"
product:iphone15:price      â†’ "999.99"
```

**RÃ¨gle** : Maximum 4-5 niveaux de profondeur.

## Conventions par type de donnÃ©es

### Strings (valeurs simples)

```bash
# Profil utilisateur (JSON sÃ©rialisÃ©)
user:123:profile          â†’ '{"name":"Alice","age":30}'

# Configuration
config:app:max_connections â†’ "100"
config:app:timeout         â†’ "30"

# Feature flags
feature:new_ui:enabled     â†’ "true"
feature:beta:users         â†’ "user:1,user:2,user:3"
```

### Hashes (objets structurÃ©s)

```bash
# Utilisateur comme hash
user:123                   # Hash
  â”œâ”€ name: "Alice"
  â”œâ”€ email: "alice@example.com"
  â”œâ”€ age: "30"
  â””â”€ city: "Paris"

# HGETALL user:123
# Vs
# user:123:name, user:123:email (strings sÃ©parÃ©es)

# Avantage: Structure atomique, HINCRBY, etc.
```

**Pattern recommandÃ© pour hashes** :

```bash
<type>:<id>              # Hash contient tous les attributs
user:123
product:456
order:789
```

### Lists (files d'attente, historiques)

```bash
# Files d'attente
queue:emails              # LPUSH/RPOP
queue:jobs:high
queue:jobs:low
queue:notifications

# Historique
history:user:123:logins   # LPUSH timestamp
history:user:123:purchases
log:errors:app            # LPUSH log entries
```

### Sets (collections uniques)

```bash
# Tags
tags:article:42           # SADD tag1 tag2 tag3
tags:user:123:interests

# Membres
members:group:admins      # SADD user:1 user:2
members:room:lobby

# Indices inversÃ©s
index:tag:redis           # SADD article:1 article:5 article:9
index:author:alice        # SADD post:1 post:3
```

### Sorted Sets (classements, indices)

```bash
# Leaderboards
leaderboard:game:global   # ZADD score member
leaderboard:game:2024

# Index temporel
index:posts:by_date       # ZADD timestamp post_id
index:users:by_created

# PrioritÃ©s
tasks:by_priority         # ZADD priority task_id
```

### Streams (Ã©vÃ©nements)

```bash
# Ã‰vÃ©nements
stream:events:user:123    # XADD
stream:logs:application
stream:orders:new

# Pattern gÃ©nÃ©ral
stream:<domain>:<type>
```

## Cas d'usage dÃ©taillÃ©s

### Cas 1 : Session Store

**Besoins** :
- Sessions utilisateur HTTP
- DonnÃ©es associÃ©es (panier, prÃ©fÃ©rences)
- TTL automatique

**Nommage** :

```bash
# Option 1 : String avec JSON
session:<session_id>:data
  â†’ '{"user_id":123,"cart":[1,2,3],"created_at":"..."}'

# Option 2 : Hash (RECOMMANDÃ‰)
session:<session_id>
  â”œâ”€ user_id: "123"
  â”œâ”€ cart: "1,2,3"
  â”œâ”€ created_at: "2024-12-09T15:30:00Z"
  â””â”€ last_activity: "2024-12-09T16:00:00Z"

# DonnÃ©es additionnelles
session:<session_id>:cart       # List pour panier dÃ©taillÃ©
session:<session_id>:preferences # Hash pour prÃ©fÃ©rences
```

**ImplÃ©mentation** :

```python
# CrÃ©ation session
session_id = generate_session_id()
redis.hset(f"session:{session_id}", mapping={
    "user_id": user_id,
    "created_at": datetime.now().isoformat()
})
redis.expire(f"session:{session_id}", 1800)  # 30 min

# Panier dans une liste sÃ©parÃ©e
redis.lpush(f"session:{session_id}:cart", product_id)
redis.expire(f"session:{session_id}:cart", 1800)

# Lecture
session_data = redis.hgetall(f"session:{session_id}")
cart_items = redis.lrange(f"session:{session_id}:cart", 0, -1)
```

### Cas 2 : Cache multi-niveaux

**Besoins** :
- Cache de diffÃ©rentes sources (DB, API, calculs)
- TTL variables
- Invalidation sÃ©lective

**Nommage** :

```bash
# Par source
cache:db:<table>:<id>
cache:api:<service>:<endpoint>:<params_hash>
cache:computed:<function>:<args_hash>

# Exemples concrets
cache:db:users:123                    # User depuis DB
cache:api:weather:current:paris       # API mÃ©tÃ©o
cache:api:github:user:octocat         # API GitHub
cache:computed:fibonacci:50           # Calcul coÃ»teux

# Avec versioning
cache:v2:db:users:123                 # Version du cache
cache:v2:api:weather:current:paris
```

**ImplÃ©mentation** :

```python
def cache_key(source, *parts):
    """GÃ©nÃ¨re clÃ© de cache cohÃ©rente"""
    return f"cache:{source}:" + ":".join(str(p) for p in parts)

# Utilisation
def get_user_from_db(user_id):
    key = cache_key("db", "users", user_id)

    # Try cache
    cached = redis.get(key)
    if cached:
        return json.loads(cached)

    # Cache miss
    user = db.query("SELECT * FROM users WHERE id = ?", user_id)
    redis.setex(key, 3600, json.dumps(user))
    return user

def get_weather(city):
    key = cache_key("api", "weather", "current", city.lower())

    cached = redis.get(key)
    if cached:
        return json.loads(cached)

    weather = api.fetch_weather(city)
    redis.setex(key, 1800, json.dumps(weather))
    return weather
```

**Invalidation** :

```python
# Invalider tous les caches DB d'un type
keys = redis.keys("cache:db:users:*")  # âš ï¸ Utiliser SCAN en prod
for key in keys:
    redis.delete(key)

# Invalider par pattern (avec SCAN)
cursor = 0
while True:
    cursor, keys = redis.scan(cursor, match="cache:api:weather:*", count=100)
    if keys:
        redis.delete(*keys)
    if cursor == 0:
        break
```

### Cas 3 : Rate Limiting

**Besoins** :
- Limitation par IP, user, API key
- FenÃªtres temporelles
- Plusieurs limites (par seconde, minute, heure)

**Nommage** :

```bash
# Pattern gÃ©nÃ©ral
rate:<scope>:<identifier>:<window>

# Par IP
rate:ip:192.168.1.100:second    # Limite par seconde
rate:ip:192.168.1.100:minute    # Limite par minute
rate:ip:192.168.1.100:hour      # Limite par heure

# Par user
rate:user:123:api:calls:minute
rate:user:123:api:calls:hour

# Par API key
rate:apikey:abc123:requests:second

# Avec timestamp (sliding window)
rate:ip:192.168.1.100:1733847600  # Timestamp epoch
```

**ImplÃ©mentation Fixed Window** :

```python
def rate_limit_fixed(redis, identifier, limit=100, window=60):
    """Rate limiting avec fenÃªtre fixe"""
    current_window = int(time.time() // window)
    key = f"rate:ip:{identifier}:{current_window}"

    count = redis.incr(key)

    if count == 1:
        redis.expire(key, window * 2)  # Safety margin

    return count <= limit

# Utilisation
if not rate_limit_fixed(redis, client_ip, limit=100, window=60):
    raise RateLimitExceeded("Too many requests")
```

**ImplÃ©mentation Sliding Window** :

```python
def rate_limit_sliding(redis, identifier, limit=100, window=60):
    """Rate limiting avec fenÃªtre glissante"""
    now = time.time()
    key = f"rate:sliding:{identifier}"

    # Supprime Ã©vÃ©nements expirÃ©s
    redis.zremrangebyscore(key, 0, now - window)

    # Compte Ã©vÃ©nements dans la fenÃªtre
    count = redis.zcard(key)

    if count < limit:
        # Ajoute nouvel Ã©vÃ©nement
        redis.zadd(key, {f"{now}:{random.random()}": now})
        redis.expire(key, window)
        return True

    return False
```

### Cas 4 : Distributed Locking

**Besoins** :
- Locks sur ressources
- TTL automatique (Ã©viter deadlocks)
- Identification du propriÃ©taire

**Nommage** :

```bash
# Pattern
lock:<resource_type>:<resource_id>

# Exemples
lock:user:123                    # Lock sur user
lock:file:upload:abc             # Lock sur upload
lock:resource:database:write     # Lock Ã©criture DB
lock:job:processing:order:456    # Lock traitement job

# Valeur : Identifier unique du lock owner
# SET lock:user:123 "server1:thread42:uuid123" NX EX 10
```

**ImplÃ©mentation** :

```python
import uuid

def acquire_lock(redis, resource, ttl=10):
    """Acquiert un lock distribuÃ©"""
    identifier = f"{socket.gethostname()}:{threading.get_ident()}:{uuid.uuid4()}"
    key = f"lock:{resource}"

    if redis.set(key, identifier, nx=True, ex=ttl):
        return identifier
    return None

def release_lock(redis, resource, identifier):
    """LibÃ¨re un lock de maniÃ¨re atomique"""
    key = f"lock:{resource}"

    # Script Lua pour atomicitÃ©
    script = """
    if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
    else
        return 0
    end
    """

    return redis.eval(script, 1, key, identifier)

# Utilisation
lock_id = acquire_lock(redis, "user:123:profile")
if lock_id:
    try:
        # OpÃ©ration critique
        update_user_profile(123)
    finally:
        release_lock(redis, "user:123:profile", lock_id)
else:
    raise ResourceLocked("Profile is being updated")
```

### Cas 5 : Compteurs et analytics

**Besoins** :
- MÃ©triques diverses (vues, likes, etc.)
- AgrÃ©gation temporelle
- IncrÃ©ments atomiques

**Nommage** :

```bash
# Compteurs simples
counter:views:article:42
counter:likes:post:123
counter:downloads:file:abc

# Avec dimension temporelle
counter:views:article:42:2024:12:09      # Par jour
counter:views:article:42:2024:12         # Par mois
counter:views:article:42:2024            # Par annÃ©e

# Avec granularitÃ© heure
counter:views:article:42:2024:12:09:15   # 15h

# Pattern gÃ©nÃ©ral
counter:<metric>:<entity>:<id>[:<timestamp>]
```

**ImplÃ©mentation** :

```python
def increment_counter(redis, metric, entity, entity_id, granularity='day'):
    """IncrÃ©mente compteur avec granularitÃ© temporelle"""
    now = datetime.now()

    if granularity == 'day':
        timestamp = now.strftime('%Y:%m:%d')
    elif granularity == 'hour':
        timestamp = now.strftime('%Y:%m:%d:%H')
    elif granularity == 'minute':
        timestamp = now.strftime('%Y:%m:%d:%H:%M')
    else:
        timestamp = ''

    key = f"counter:{metric}:{entity}:{entity_id}"
    if timestamp:
        key += f":{timestamp}"

    count = redis.incr(key)

    # TTL automatique selon granularitÃ©
    if granularity == 'day':
        redis.expire(key, 86400 * 90)  # 90 jours
    elif granularity == 'hour':
        redis.expire(key, 3600 * 24 * 7)  # 7 jours

    return count

# Utilisation
views_today = increment_counter(redis, "views", "article", 42, "day")
views_this_hour = increment_counter(redis, "views", "article", 42, "hour")

# Lecture agrÃ©gÃ©e
def get_views_range(redis, article_id, start_date, end_date):
    """RÃ©cupÃ¨re vues sur une pÃ©riode"""
    total = 0
    current = start_date

    while current <= end_date:
        key = f"counter:views:article:{article_id}:{current.strftime('%Y:%m:%d')}"
        count = redis.get(key)
        if count:
            total += int(count)
        current += timedelta(days=1)

    return total
```

### Cas 6 : Tags et recherche

**Besoins** :
- Tags sur entitÃ©s
- Recherche par tags
- Indices inversÃ©s

**Nommage** :

```bash
# Tags directs (Set)
tags:article:42              # SADD redis nosql database
tags:user:123:interests      # SADD python redis docker

# Index inversÃ© (Set)
index:tag:redis              # SADD article:42 article:58 article:91
index:tag:python             # SADD article:42 article:101

# Pattern gÃ©nÃ©ral
tags:<entity>:<id>           # Tags de l'entitÃ©
index:tag:<tag>              # EntitÃ©s avec ce tag
```

**ImplÃ©mentation** :

```python
def add_tags(redis, entity_type, entity_id, *tags):
    """Ajoute tags et met Ã  jour indices"""
    entity_key = f"tags:{entity_type}:{entity_id}"
    entity_ref = f"{entity_type}:{entity_id}"

    for tag in tags:
        # Tag direct
        redis.sadd(entity_key, tag)

        # Index inversÃ©
        index_key = f"index:tag:{tag.lower()}"
        redis.sadd(index_key, entity_ref)

def remove_tags(redis, entity_type, entity_id, *tags):
    """Supprime tags et met Ã  jour indices"""
    entity_key = f"tags:{entity_type}:{entity_id}"
    entity_ref = f"{entity_type}:{entity_id}"

    for tag in tags:
        redis.srem(entity_key, tag)
        index_key = f"index:tag:{tag.lower()}"
        redis.srem(index_key, entity_ref)

def find_by_tags(redis, entity_type, *tags, operator='AND'):
    """Trouve entitÃ©s par tags"""
    if operator == 'AND':
        # Intersection
        keys = [f"index:tag:{tag.lower()}" for tag in tags]
        return redis.sinter(*keys)
    else:  # OR
        # Union
        keys = [f"index:tag:{tag.lower()}" for tag in tags]
        return redis.sunion(*keys)

# Utilisation
add_tags(redis, "article", 42, "redis", "nosql", "cache")
add_tags(redis, "article", 43, "redis", "python")

# Recherche
redis_articles = find_by_tags(redis, "article", "redis")
# {'article:42', 'article:43'}

redis_and_python = find_by_tags(redis, "article", "redis", "python", operator='AND')
# {'article:43'}
```

## Versioning et Ã©volution de schÃ©ma

### Besoin de versioning

```bash
# V1 : Structure initiale
user:123:profile â†’ '{"name":"Alice","email":"alice@example.com"}'

# V2 : Ajout de champs
user:123:profile â†’ '{"name":"Alice","email":"alice@example.com","phone":"+33..."}'

# ProblÃ¨me : Comment distinguer V1 de V2 ?
```

### StratÃ©gies de versioning

#### 1. Version dans la clÃ© (RECOMMANDÃ‰)

```bash
# Pattern
<type>:v<version>:<entity>:<id>

# Exemples
user:v1:123:profile
user:v2:123:profile
cache:v3:api:weather:paris
```

**Avantages** :
- âœ… Cohabitation de versions
- âœ… Migration progressive
- âœ… Rollback facile

**Migration** :

```python
def migrate_user_v1_to_v2(redis, user_id):
    """Migre user de V1 Ã  V2"""
    old_key = f"user:v1:{user_id}:profile"
    new_key = f"user:v2:{user_id}:profile"

    # Lire V1
    old_data = redis.get(old_key)
    if not old_data:
        return False

    data = json.loads(old_data)

    # Transformer
    data['phone'] = None  # Nouveau champ
    data['version'] = 2

    # Ã‰crire V2
    redis.set(new_key, json.dumps(data))

    # Optionnel : Supprimer V1
    # redis.delete(old_key)

    return True

# Lecture avec fallback
def get_user_profile(redis, user_id):
    """Lit profil avec fallback V2 â†’ V1"""
    # Essaye V2
    v2_key = f"user:v2:{user_id}:profile"
    data = redis.get(v2_key)
    if data:
        return json.loads(data)

    # Fallback V1
    v1_key = f"user:v1:{user_id}:profile"
    data = redis.get(v1_key)
    if data:
        # Migration lazy
        migrate_user_v1_to_v2(redis, user_id)
        return json.loads(data)

    return None
```

#### 2. Version dans la valeur

```bash
# ClÃ© sans version
user:123:profile

# Valeur avec version
{
    "_version": 2,
    "name": "Alice",
    "email": "alice@example.com",
    "phone": "+33..."
}
```

**Avantages** :
- âœ… ClÃ©s stables
- âœ… Backward compatibility possible

**InconvÃ©nients** :
- âŒ NÃ©cessite dÃ©sÃ©rialisation pour lire version
- âŒ Migration sur place uniquement

#### 3. Metadata sÃ©parÃ©e

```bash
# DonnÃ©es
user:123:profile â†’ {...}

# Metadata
meta:user:123:profile â†’ '{"version":2,"schema":"profile_v2"}'
```

**Avantages** :
- âœ… SÃ©paration concerns
- âœ… Metadata interrogeable sans lire data

**InconvÃ©nients** :
- âŒ Deux requÃªtes
- âŒ Risque de dÃ©synchronisation

## Patterns avancÃ©s

### Composition de clÃ©s dynamique

```python
class KeyBuilder:
    """Builder pour construction cohÃ©rente de clÃ©s"""

    def __init__(self, separator=':'):
        self.parts = []
        self.separator = separator

    def add(self, *parts):
        """Ajoute parties"""
        self.parts.extend(str(p) for p in parts)
        return self

    def build(self):
        """Construit clÃ© finale"""
        return self.separator.join(self.parts)

    @classmethod
    def user(cls, user_id, *extra):
        """ClÃ© user"""
        return cls().add('user', user_id, *extra).build()

    @classmethod
    def cache(cls, source, *path):
        """ClÃ© cache"""
        return cls().add('cache', source, *path).build()

    @classmethod
    def counter(cls, metric, entity, entity_id, timestamp=None):
        """ClÃ© counter"""
        builder = cls().add('counter', metric, entity, entity_id)
        if timestamp:
            builder.add(timestamp)
        return builder.build()

# Utilisation
user_key = KeyBuilder.user(123, 'profile')
# "user:123:profile"

cache_key = KeyBuilder.cache('api', 'weather', 'paris')
# "cache:api:weather:paris"

counter_key = KeyBuilder.counter('views', 'article', 42, '2024:12:09')
# "counter:views:article:42:2024:12:09"
```

### Namespaces par environnement

```bash
# Pattern avec environnement
<env>:<type>:<entity>:<id>

# DÃ©veloppement
dev:user:123:profile
dev:cache:api:weather

# Staging
staging:user:123:profile
staging:cache:api:weather

# Production
prod:user:123:profile
prod:cache:api:weather

# Ou via databases sÃ©parÃ©es (DB 0, 1, 2)
```

**Configuration** :

```python
import os

class RedisClient:
    def __init__(self):
        self.env = os.getenv('ENVIRONMENT', 'dev')
        self.redis = redis.Redis()

    def make_key(self, *parts):
        """Ajoute prefix environnement"""
        return f"{self.env}:" + ":".join(str(p) for p in parts)

    def get(self, *parts):
        key = self.make_key(*parts)
        return self.redis.get(key)

    def set(self, *parts, value, **kwargs):
        key = self.make_key(*parts)
        return self.redis.set(key, value, **kwargs)

# Utilisation
client = RedisClient()
client.set('user', 123, 'profile', value='{"name":"Alice"}')
# Stocke: "dev:user:123:profile" ou "prod:user:123:profile"
```

### Multi-tenancy

```bash
# Pattern
<tenant_id>:<type>:<entity>:<id>

# Tenant ACME
acme:user:123:profile
acme:cache:data
acme:counter:views:article:42

# Tenant XYZ
xyz:user:456:profile
xyz:cache:data
xyz:counter:views:article:42
```

**Isolation complÃ¨te** :

```python
class TenantRedisClient:
    def __init__(self, tenant_id):
        self.tenant_id = tenant_id
        self.redis = redis.Redis()

    def make_key(self, *parts):
        return f"{self.tenant_id}:" + ":".join(str(p) for p in parts)

    def get(self, *parts):
        return self.redis.get(self.make_key(*parts))

    def set(self, *parts, value, **kwargs):
        return self.redis.set(self.make_key(*parts), value, **kwargs)

    def scan_tenant(self, pattern='*', count=100):
        """Scan uniquement les clÃ©s du tenant"""
        full_pattern = f"{self.tenant_id}:{pattern}"
        cursor = 0
        while True:
            cursor, keys = self.redis.scan(cursor, match=full_pattern, count=count)
            yield from keys
            if cursor == 0:
                break

# Utilisation
acme_client = TenantRedisClient('acme')
xyz_client = TenantRedisClient('xyz')

acme_client.set('user', 123, 'name', value='Alice')
xyz_client.set('user', 123, 'name', value='Bob')

# Isolation totale
print(acme_client.get('user', 123, 'name'))  # "Alice"
print(xyz_client.get('user', 123, 'name'))   # "Bob"
```

## Recherche et filtrage

### SCAN avec patterns

```bash
# Scan par namespace
SCAN 0 MATCH user:* COUNT 100
SCAN 0 MATCH cache:api:* COUNT 100
SCAN 0 MATCH session:* COUNT 100

# Wildcards
SCAN 0 MATCH user:*:profile COUNT 100       # Tous les profils
SCAN 0 MATCH counter:views:article:* COUNT 100  # Tous compteurs vues articles

# Un seul wildcard par niveau
SCAN 0 MATCH user:*:*                       # user:123:profile, user:123:settings, etc.
```

**ImplÃ©mentation sÃ»re** :

```python
def scan_keys(redis, pattern, count=100):
    """Scan avec pattern, retourne generator"""
    cursor = 0
    while True:
        cursor, keys = redis.scan(cursor, match=pattern, count=count)
        yield from keys
        if cursor == 0:
            break

# Utilisation
for key in scan_keys(redis, "user:*:profile"):
    profile = redis.get(key)
    process(profile)

# Collecte en liste (attention mÃ©moire !)
user_profiles = list(scan_keys(redis, "user:*:profile"))
```

### KEYS : Ã€ Ã©viter en production

```bash
# âŒ BLOQUE Redis en production
KEYS user:*

# âœ… Utiliser SCAN Ã  la place
SCAN 0 MATCH user:* COUNT 100
```

**Pourquoi KEYS est dangereux** :

```
KEYS avec 1 million de clÃ©s:
â”œâ”€ Bloque Redis pendant ~1 seconde
â”œâ”€ Aucune requÃªte servie pendant ce temps
â””â”€ Peut causer timeout des clients

SCAN avec 1 million de clÃ©s:
â”œâ”€ Traite par batch de 100 (configurable)
â”œâ”€ Chaque itÃ©ration < 1ms
â””â”€ RequÃªtes clients servies entre les batchs
```

### Suppression par pattern

```python
def delete_by_pattern(redis, pattern, batch_size=100):
    """Supprime clÃ©s par pattern (safe avec SCAN)"""
    cursor = 0
    total_deleted = 0

    while True:
        cursor, keys = redis.scan(cursor, match=pattern, count=batch_size)

        if keys:
            # Supprime batch
            redis.delete(*keys)
            total_deleted += len(keys)

        if cursor == 0:
            break

    return total_deleted

# Utilisation
deleted = delete_by_pattern(redis, "cache:api:*")
print(f"Deleted {deleted} cache entries")
```

## Performance et optimisations

### Longueur des clÃ©s

```bash
# Impact mÃ©moire
# Overhead par clÃ© : ~100 bytes (RedisObject + dict entry + key)

# ClÃ© courte
u:123:p             â†’ 7 bytes clÃ© + 100 bytes overhead = 107 bytes

# ClÃ© descriptive
user:123:profile    â†’ 17 bytes clÃ© + 100 bytes overhead = 117 bytes

# DiffÃ©rence : 10 bytes par clÃ©
# Sur 10M clÃ©s : 100 MB de diffÃ©rence

# Recommandation : PrÃ©fÃ©rer la lisibilitÃ©
# 100 MB sur 10M clÃ©s est nÃ©gligeable vs maintenabilitÃ©
```

**Ã‰quilibre lisibilitÃ©/performance** :

```bash
# âŒ Trop court (illisible)
u:123:p
c:a:w:p

# âœ… Bon Ã©quilibre
user:123:profile
cache:api:weather:paris

# âš ï¸ Trop long (rare mais possible)
application:production:cache:api:external:weather:current:paris:france:europe
```

### Hash slots et clustering

Pour Redis Cluster, les clÃ©s sont distribuÃ©es selon **hash slots** :

```bash
# Hash slot calculÃ© sur la clÃ© entiÃ¨re
user:123:profile        â†’ Slot 15495
user:123:settings       â†’ Slot 10234  # Slots diffÃ©rents !

# ProblÃ¨me : Multi-key ops impossibles
MGET user:123:profile user:123:settings
# (error) CROSSSLOT Keys in request don't hash to the same slot
```

**Solution : Hash tags** :

```bash
# Utiliser {} pour forcer mÃªme slot
user:{123}:profile      â†’ Slot basÃ© sur "123"
user:{123}:settings     â†’ Slot basÃ© sur "123"  # MÃªme slot !

# Multi-key operations OK
MGET user:{123}:profile user:{123}:settings
# âœ… Fonctionne dans un cluster
```

**Pattern recommandÃ© pour cluster** :

```bash
# Grouper par entitÃ© avec hash tag
user:{user_id}:profile
user:{user_id}:settings
user:{user_id}:preferences

# OpÃ©rations multi-clÃ©s possibles
MGET user:{123}:profile user:{123}:settings
DEL user:{123}:profile user:{123}:settings user:{123}:preferences
```

### PrÃ©fixes et ACLs

Redis ACLs permettent des rÃ¨gles par pattern :

```bash
# redis.conf ou CONFIG SET

# User "cache-reader" : Lecture seule sur cache:*
ACL SETUSER cache-reader on >password ~cache:* +get +mget

# User "session-manager" : Full sur session:*
ACL SETUSER session-manager on >password ~session:* +@all

# User "admin" : Full sur tout
ACL SETUSER admin on >password ~* +@all
```

**StratÃ©gie de nommage pour ACLs** :

```bash
# Organiser par privilÃ¨ge
cache:*           â†’ Lecture par tous
session:*         â†’ Gestion par session-service
admin:*           â†’ Admin uniquement
metrics:*         â†’ Lecture par monitoring

# Exemple rÃ¨gles
ACL SETUSER app on >pass ~cache:* ~session:* +get +set +del
ACL SETUSER monitoring on >pass ~metrics:* +get +scan
ACL SETUSER admin on >pass ~* +@all
```

## Anti-patterns Ã  Ã©viter

### 1. ClÃ©s trop gÃ©nÃ©riques

```bash
# âŒ MAUVAIS : Collisions garanties
data
temp
cache
config

# âœ… BON : SpÃ©cifique
user:123:data
temp:upload:abc123
cache:api:result:xyz
config:app:database
```

### 2. SÃ©parateurs incohÃ©rents

```bash
# âŒ MAUVAIS : MÃ©lange sÃ©parateurs
user:123/profile
cache|api:result
session_abc123

# âœ… BON : CohÃ©rent
user:123:profile
cache:api:result
session:abc123
```

### 3. ID non uniques

```bash
# âŒ MAUVAIS : ID peut collisionner
user:profile        # Quel user ?
article:data        # Quel article ?

# âœ… BON : ID unique obligatoire
user:123:profile
article:42:data
```

### 4. Espaces dans les clÃ©s

```bash
# âŒ MAUVAIS : Espaces = problÃ¨mes
"user 123 profile"
"cache api weather"

# âœ… BON : Pas d'espaces
user:123:profile
cache:api:weather
```

### 5. CaractÃ¨res spÃ©ciaux

```bash
# âš ï¸ Ã€ Ã©viter
user:123:@email
cache:api:result?query=1
session:abc#123

# âœ… PrÃ©fÃ©rer
user:123:email
cache:api:result:query_1
session:abc_123
```

### 6. ClÃ©s dynamiques non maÃ®trisÃ©es

```python
# âŒ MAUVAIS : User input direct
search_term = request.get('q')
key = f"cache:search:{search_term}"
# Risque : Injection, clÃ©s infinies si pas de limite

# âœ… BON : Validation et hashing
search_term = request.get('q')
if len(search_term) > 100:
    raise ValueError("Search term too long")

# Hash pour clÃ©s longues/complexes
search_hash = hashlib.md5(search_term.encode()).hexdigest()
key = f"cache:search:{search_hash}"
```

### 7. Pas de TTL sur donnÃ©es temporaires

```bash
# âŒ MAUVAIS : Fuite mÃ©moire
SET session:abc123 "{data}"
SET cache:temp:xyz "{data}"

# âœ… BON : TTL systÃ©matique
SETEX session:abc123 1800 "{data}"
SETEX cache:temp:xyz 300 "{data}"
```

### 8. HiÃ©rarchie trop profonde

```bash
# âŒ MAUVAIS : 10 niveaux
app:prod:service:api:cache:db:table:users:country:france:city:paris:user:123

# âœ… BON : Maximum 5 niveaux
app:cache:users:france:paris:123
```

## Documentation et gouvernance

### Registry de namespaces

Maintenir un document centralÃ© :

```yaml
# namespaces.yml
namespaces:
  user:
    description: "DonnÃ©es utilisateurs"
    pattern: "user:<id>:<attribute>"
    examples:
      - "user:123:profile"
      - "user:123:settings"
    ttl: "permanent"
    owner: "user-service"

  session:
    description: "Sessions HTTP"
    pattern: "session:<session_id>[:<attribute>]"
    examples:
      - "session:abc123"
      - "session:abc123:cart"
    ttl: "1800 seconds"
    owner: "auth-service"

  cache:
    description: "Cache multi-sources"
    pattern: "cache:<source>:<path>"
    examples:
      - "cache:db:users:123"
      - "cache:api:weather:paris"
    ttl: "variable (300-3600s)"
    owner: "all services"
```

### Validation programmatique

```python
import re

class KeyValidator:
    """Valide les clÃ©s selon conventions"""

    PATTERNS = {
        'user': r'^user:\d+:[a-z_]+$',
        'session': r'^session:[a-f0-9]+(?::[a-z_]+)?$',
        'cache': r'^cache:[a-z]+:.+$',
        'counter': r'^counter:[a-z_]+:[a-z]+:\d+(?::\d{4}:\d{2}:\d{2})?$',
    }

    @classmethod
    def validate(cls, key):
        """Valide format de clÃ©"""
        namespace = key.split(':')[0]

        if namespace not in cls.PATTERNS:
            raise ValueError(f"Unknown namespace: {namespace}")

        pattern = cls.PATTERNS[namespace]
        if not re.match(pattern, key):
            raise ValueError(f"Invalid key format: {key}")

        return True

    @classmethod
    def suggest_fix(cls, key):
        """SuggÃ¨re correction"""
        # ImplÃ©mentation de suggestions...
        pass

# Utilisation
try:
    KeyValidator.validate("user:123:profile")  # âœ…
    KeyValidator.validate("user:abc:profile")  # âŒ ValueError
except ValueError as e:
    print(f"Invalid key: {e}")
```

### Code review checklist

```markdown
## Redis Key Naming Review

Avant de merger, vÃ©rifier :

â˜ SÃ©parateur cohÃ©rent (`:` partout)
â˜ Namespace clair et documentÃ©
â˜ ID unique prÃ©sent
â˜ Maximum 5 niveaux de profondeur
â˜ Pas d'espaces ni caractÃ¨res spÃ©ciaux
â˜ TTL dÃ©fini si donnÃ©es temporaires
â˜ Pattern compatible SCAN
â˜ Compatible Redis Cluster (hash tags si nÃ©cessaire)
â˜ Validation des inputs utilisateur
â˜ Documentation Ã  jour
```

## RÃ©sumÃ© : Best practices

### Checklist complÃ¨te

```
âœ… Toujours utiliser `:` comme sÃ©parateur
âœ… Pattern : <type>:<entity>:<id>:<attribute>
âœ… ID unique obligatoire
âœ… Maximum 4-5 niveaux de profondeur
âœ… Namespace par type de donnÃ©es
âœ… TTL sur donnÃ©es temporaires
âœ… Validation des inputs
âœ… Hash tags pour clustering ({id})
âœ… SCAN au lieu de KEYS
âœ… Documentation centralisÃ©e
âœ… Versioning pour Ã©volution schÃ©ma
âœ… Builder/helper pour cohÃ©rence
âœ… ACLs par namespace
âœ… Monitoring par pattern
```

### Pattern de rÃ©fÃ©rence

```bash
# Standard recommandÃ©
<namespace>:<entity>:<id>[:<attribute>][:<timestamp>]

# Exemples
user:123:profile
session:abc123:data
cache:api:weather:paris
counter:views:article:42:2024:12:09
lock:resource:database
queue:emails
stream:events:orders

# Avec versioning
user:v2:123:profile
cache:v3:api:result

# Multi-tenant
tenant:acme:user:123:profile

# Cluster-ready
user:{123}:profile
user:{123}:settings
```

## Conclusion

Le nommage des clÃ©s Redis n'est pas qu'une question de convention esthÃ©tique. C'est une **architecture de donnÃ©es** qui impacte :

- **MaintenabilitÃ©** : Retrouver et comprendre les donnÃ©es
- **Performance** : Recherche, clustering, ACLs
- **ScalabilitÃ©** : Partitionnement prÃ©visible
- **FiabilitÃ©** : Ã‰viter collisions et bugs
- **SÃ©curitÃ©** : ACLs granulaires

Investir du temps dans la dÃ©finition de conventions solides dÃ¨s le dÃ©but d'un projet Redis Ã©vite des refactoring coÃ»teux plus tard. Les patterns prÃ©sentÃ©s ici sont Ã©prouvÃ©s en production et constituent une base solide pour vos projets.

La section suivante abordera SCAN vs KEYS et comment ne jamais bloquer la production lors de l'exploration du keyspace.

â­ï¸ [SCAN vs KEYS : Ne jamais bloquer la production](/04-cycle-vie-donnee/06-scan-vs-keys-production.md)
