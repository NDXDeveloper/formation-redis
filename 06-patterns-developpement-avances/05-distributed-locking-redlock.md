üîù Retour au [Sommaire](/SOMMAIRE.md)

# 6.5 Distributed Locking : Le pattern Redlock

## Introduction

Dans un syst√®me distribu√©, coordonner l'acc√®s exclusif √† une ressource partag√©e est un probl√®me fondamental. Le **Distributed Locking** permet de garantir qu'une seule instance d'une application peut ex√©cuter une section critique √† un moment donn√©, m√™me quand plusieurs instances s'ex√©cutent en parall√®le.

Redis propose une solution √©l√©gante avec le pattern **Redlock**, mais son utilisation correcte n√©cessite une compr√©hension profonde de ses garanties et limitations.

## Le probl√®me des verrous distribu√©s

### Sc√©nario sans verrou

```text
PROBL√àME : Traitement concurrent sans coordination

Instance 1                    Redis                    Instance 2
    ‚îÇ                           ‚îÇ                          ‚îÇ
    ‚îú‚îÄ Check job:123 status ‚îÄ‚îÄ‚îÄ>‚îÇ                          ‚îÇ
    ‚îÇ<‚îÄ "pending" ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                          ‚îÇ
    ‚îÇ                           ‚îÇ                          ‚îÇ
    ‚îÇ                           ‚îÇ<‚îÄ‚îÄ‚îÄ Check job:123 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ                           ‚îú‚îÄ‚îÄ> "pending" ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
    ‚îÇ                           ‚îÇ                          ‚îÇ
    ‚îú‚îÄ Process job:123 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                          ‚îÇ
    ‚îÇ                           ‚îÇ                          ‚îÇ
    ‚îÇ                           ‚îÇ<‚îÄ‚îÄ‚îÄ Process job:123 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ                           ‚îÇ                          ‚îÇ
    ‚ùå Job trait√© 2 fois!       ‚îÇ                          ‚îÇ
    ‚ùå R√©sultats incoh√©rents    ‚îÇ                          ‚îÇ
    ‚ùå Waste de ressources      ‚îÇ                          ‚îÇ
```

### Cas d'usage typiques

**1. Job processing (traitement de t√¢ches)**
```text
Sc√©nario : 10 workers lisent depuis une queue

Sans lock:
- Worker 1 lit job:123
- Worker 2 lit job:123 (en m√™me temps)
- Les deux traitent le job
- Double processing! ‚ùå

Avec lock:
- Worker 1 acquiert lock:job:123
- Worker 2 tente d'acqu√©rir lock:job:123 ‚Üí FAIL
- Worker 2 passe au job suivant
- Worker 1 traite job:123
- Single processing ‚úÖ
```

**2. Rate limiting distribu√©**
```text
Sc√©nario : Limiter les appels API √† 100/minute par user

Sans lock:
- Instance 1 : check count = 99, increment ‚Üí 100 ‚úÖ
- Instance 2 : check count = 99, increment ‚Üí 100 ‚úÖ (race!)
- R√©sultat : 101 calls (limite d√©pass√©e) ‚ùå

Avec lock:
- Instance 1 : acquire lock ‚Üí check count = 99 ‚Üí increment ‚Üí release
- Instance 2 : attend le lock ‚Üí check count = 100 ‚Üí refuse
- R√©sultat : 100 calls exactement ‚úÖ
```

**3. Resource allocation (slots, tickets, inventory)**
```text
Sc√©nario : E-commerce - Vente flash avec 1 produit restant

Sans lock:
- User A : check stock = 1 ‚Üí ach√®te ‚Üí stock = 0
- User B : check stock = 1 ‚Üí ach√®te ‚Üí stock = -1 (overselling!) ‚ùå

Avec lock:
- User A : acquire lock ‚Üí check stock = 1 ‚Üí ach√®te ‚Üí release
- User B : attend lock ‚Üí check stock = 0 ‚Üí refuse
- No overselling ‚úÖ
```

---

## Simple Redis Lock (Approche basique)

### Principe

Le lock simple utilise une commande atomique Redis : `SET key value NX EX seconds`

```text
SET lock:resource "owner-id" NX EX 30

NX : Only set if Not eXists (atomique)
EX : EXpire after N seconds (auto-release si crash)

Returns:
- OK si lock acquis
- nil si lock d√©j√† pris
```

### Impl√©mentation Python basique

```python
import redis
import uuid
import time

class SimpleRedisLock:
    """
    Verrou Redis simple avec SET NX EX
    """

    def __init__(self, redis_client, lock_name, ttl=30):
        self.redis = redis_client
        self.lock_name = f"lock:{lock_name}"
        self.ttl = ttl
        self.lock_id = str(uuid.uuid4())  # ID unique pour ce lock

    def acquire(self, blocking=True, timeout=None):
        """
        Acquiert le verrou

        Args:
            blocking: Si True, attend jusqu'√† obtenir le lock
            timeout: Temps max d'attente (secondes)

        Returns:
            bool: True si lock acquis, False sinon
        """
        start_time = time.time()

        while True:
            # Tentative d'acquisition atomique
            acquired = self.redis.set(
                self.lock_name,
                self.lock_id,
                nx=True,  # Only if not exists
                ex=self.ttl  # Expire after TTL seconds
            )

            if acquired:
                print(f"‚úì Lock '{self.lock_name}' acquired by {self.lock_id}")
                return True

            # Lock d√©j√† pris
            if not blocking:
                print(f"‚úó Lock '{self.lock_name}' already held")
                return False

            # V√©rifier timeout
            if timeout and (time.time() - start_time) >= timeout:
                print(f"‚úó Lock '{self.lock_name}' timeout after {timeout}s")
                return False

            # Attendre un peu avant de r√©essayer
            time.sleep(0.1)

    def release(self):
        """
        Lib√®re le verrou (seulement si on le poss√®de)
        """
        # Script Lua pour v√©rifier que c'est bien notre lock avant de le supprimer
        lua_script = """
        if redis.call("get", KEYS[1]) == ARGV[1] then
            return redis.call("del", KEYS[1])
        else
            return 0
        end
        """

        result = self.redis.eval(lua_script, 1, self.lock_name, self.lock_id)

        if result:
            print(f"‚úì Lock '{self.lock_name}' released by {self.lock_id}")
            return True
        else:
            print(f"‚ö†Ô∏è  Lock '{self.lock_name}' not owned by {self.lock_id}")
            return False

    def __enter__(self):
        """Support du context manager"""
        self.acquire()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Lib√©ration automatique du lock"""
        self.release()


# ============================================================
# EXEMPLE D'UTILISATION
# ============================================================

def process_job_with_lock(job_id):
    """
    Traite un job avec protection par lock
    """
    redis_client = redis.Redis(decode_responses=True)

    # Utiliser le context manager
    with SimpleRedisLock(redis_client, f"job:{job_id}", ttl=30):
        print(f"Processing job {job_id}...")

        # Section critique prot√©g√©e
        time.sleep(2)  # Simuler un traitement

        print(f"Job {job_id} completed")

    # Lock automatiquement lib√©r√©


# ============================================================
# TEST CONCURRENT
# ============================================================

import threading

def worker_thread(worker_id, job_id):
    """Thread worker simulant un traitement concurrent"""
    print(f"Worker {worker_id} starting...")

    redis_client = redis.Redis(decode_responses=True)
    lock = SimpleRedisLock(redis_client, f"job:{job_id}", ttl=10)

    # Tentative non-bloquante
    if lock.acquire(blocking=False):
        try:
            print(f"  Worker {worker_id} is processing job {job_id}")
            time.sleep(3)
            print(f"  Worker {worker_id} finished job {job_id}")
        finally:
            lock.release()
    else:
        print(f"  Worker {worker_id} could not acquire lock (job being processed)")


def test_concurrent_access():
    """Test avec plusieurs workers concurrents"""
    print("=" * 60)
    print("TEST: Concurrent Access with Simple Lock")
    print("=" * 60 + "\n")

    job_id = 123
    threads = []

    # Lancer 5 workers concurrents
    for i in range(5):
        t = threading.Thread(target=worker_thread, args=(i, job_id))
        threads.append(t)
        t.start()

    # Attendre tous les threads
    for t in threads:
        t.join()

    print("\n‚úì Test completed: Only one worker processed the job")
```

### Visualisation du flux

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               SIMPLE REDIS LOCK FLOW                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Worker 1                      Redis                      Worker 2
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îú‚îÄ SET lock:job NX EX 30 ‚îÄ‚îÄ‚îÄ>‚îÇ                            ‚îÇ
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ OK ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  Lock acquired ‚úÖ          ‚îÇ
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ                            ‚îÇ<‚îÄ‚îÄ‚îÄ SET lock:job NX EX ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ                            ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ nil ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
   ‚îÇ                            ‚îÇ   Lock already held ‚ùå     ‚îÇ
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ  [Processing job...]       ‚îÇ                            ‚îÇ
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ  DEL lock:job (Lua script) ‚îÇ                            ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                            ‚îÇ
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  Lock released ‚úÖ          ‚îÇ
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ                            ‚îÇ<‚îÄ‚îÄ‚îÄ SET lock:job NX EX ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ                            ‚îÇ                            ‚îÇ
   ‚îÇ                            ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ OK ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
   ‚îÇ                            ‚îÇ   Lock acquired ‚úÖ         ‚îÇ
```

---

## Probl√®mes du Simple Lock

### 1. Single Point of Failure

```text
PROBL√àME : Si le master Redis crash, les locks sont perdus

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    REDIS MASTER CRASH                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Time    Worker 1         Master Redis         Replica         Worker 2
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
t0      Acquire lock ‚îÄ‚îÄ> [lock:job = id1]       ‚îÇ              ‚îÇ
t1      Processing...    [lock:job = id1]       ‚îÇ              ‚îÇ
t2      Processing...    üí• CRASH!              ‚îÇ              ‚îÇ
t3      Processing...         X            Promoted to         ‚îÇ
                                            Master             ‚îÇ
t4      Processing...                      [empty!]            ‚îÇ
                                         (no lock data)        ‚îÇ
t5      Processing...                      [empty]  <‚îÄ‚îÄ‚îÄ Acquire lock
                                                         (succeeds!)
t6      ‚ùå Both workers processing the same job!

R√©sultat : Lock perdu ‚Üí Double processing
```

### 2. Clock Drift (D√©rive d'horloge)

```text
PROBL√àME : TTL expire trop t√¥t √† cause de d√©rive d'horloge

Worker                        Redis (clock +5s ahead)
  ‚îÇ                                 ‚îÇ
  ‚îú‚îÄ SET lock:job NX EX 10 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ  t=0 (Redis time)
  ‚îÇ                                 ‚îÇ  Lock expires at t=10
  ‚îÇ                                 ‚îÇ
  ‚îÇ  [Processing... long task]      ‚îÇ
  ‚îÇ  [Takes 8 seconds]              ‚îÇ  t=5 (real time)
  ‚îÇ                                 ‚îÇ  But Redis thinks t=10
  ‚îÇ                                 ‚îÇ  Lock expires! ‚ùå
  ‚îÇ                                 ‚îÇ
  ‚îÇ  Still processing...            ‚îÇ  Lock gone!
  ‚îÇ                                 ‚îÇ
  ‚îÇ                                 ‚îÇ<‚îÄ‚îÄ‚îÄ SET lock:job (Worker 2)
  ‚îÇ                                 ‚îÇ     Acquires lock ‚úÖ
  ‚îÇ                                 ‚îÇ
  ‚ùå Both workers now have "the lock"
```

### 3. Network Partition

```text
PROBL√àME : Worker isol√© par partition r√©seau

Worker A            Network           Redis            Worker B
   ‚îÇ                   ‚îÇ                 ‚îÇ                 ‚îÇ
   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ                 ‚îÇ
   ‚îÇ  Acquire lock     ‚îÇ                 ‚îÇ  Lock acquired  ‚îÇ
   ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                 ‚îÇ
   ‚îÇ                   ‚îÇ                 ‚îÇ                 ‚îÇ
   ‚îÇ  Processing...    ‚îÇ                 ‚îÇ                 ‚îÇ
   ‚îÇ                   ‚îÇ                 ‚îÇ                 ‚îÇ
   ‚îÇ                   ‚úÇÔ∏è PARTITION      ‚îÇ                 ‚îÇ
   ‚îÇ  X X X X X X X X  ‚îÇ                 ‚îÇ                 ‚îÇ
   ‚îÇ  Can't reach      ‚îÇ                 ‚îÇ                 ‚îÇ
   ‚îÇ  Redis to renew   ‚îÇ                 ‚îÇ  TTL expires    ‚îÇ
   ‚îÇ                   ‚îÇ                 ‚îÇ  (no renewal)   ‚îÇ
   ‚îÇ                   ‚îÇ                 ‚îÇ                 ‚îÇ
   ‚îÇ  Still thinks it  ‚îÇ                 ‚îÇ<‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
   ‚îÇ  has the lock!    ‚îÇ                 ‚îÇ  Worker B       ‚îÇ
   ‚îÇ                   ‚îÇ                 ‚îÇ  acquires lock  ‚îÇ
   ‚îÇ                   ‚îÇ                 ‚îÇ                 ‚îÇ
   ‚ùå Both workers think they have the lock
```

---

## Le pattern Redlock

### Principe

**Redlock** r√©sout les probl√®mes du simple lock en utilisant **plusieurs instances Redis ind√©pendantes** (pas de r√©plication) et en exigeant un **quorum** pour consid√©rer le lock acquis.

### Architecture Redlock

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              REDLOCK ARCHITECTURE (N=5)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                           Worker
                             ‚îÇ
                             ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ              ‚îÇ              ‚îÇ
              ‚ñº              ‚ñº              ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇRedis 1 ‚îÇ     ‚îÇRedis 2 ‚îÇ     ‚îÇRedis 3 ‚îÇ
         ‚îÇMaster  ‚îÇ     ‚îÇMaster  ‚îÇ     ‚îÇMaster  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚ñ≤              ‚ñ≤
              ‚îÇ              ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                             ‚ñº
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇRedis 4 ‚îÇ     ‚îÇRedis 5 ‚îÇ
                        ‚îÇMaster  ‚îÇ     ‚îÇMaster  ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Quorum = N/2 + 1 = 3/5

Lock acquired if:
‚úÖ At least 3/5 instances respond OK
‚úÖ Total time < Lock TTL
‚úÖ Valid time remaining > 0
```

### Algorithme Redlock

```text
ALGORITHM: Acquire Redlock
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

1. Get current timestamp (milliseconds)
   start_time = now()

2. Try to acquire lock on ALL N instances sequentially:
   FOR each Redis instance:
       SET lock:resource "unique-id" NX PX ttl
       (with small timeout, e.g., 5-50ms)

3. Calculate elapsed time:
   elapsed = now() - start_time

4. Lock is acquired if and only if:
   - Got OK from at least N/2 + 1 instances (quorum)
   - elapsed < lock_ttl (we're not too slow)
   - validity_time = lock_ttl - elapsed > 0

5. If lock acquired:
   - Use resource with remaining validity_time
   - When done, release lock on ALL instances

6. If lock NOT acquired:
   - Release lock on ALL instances (cleanup)
   - Retry after random delay

ALGORITHM: Release Redlock
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

1. FOR each Redis instance:
       Execute Lua script:
       if redis.call("get",KEYS[1]) == ARGV[1] then
           return redis.call("del",KEYS[1])
       else
           return 0
       end

2. Don't check results (best effort release)
```

---

## Impl√©mentation Python compl√®te

### Redlock Implementation

```python
import redis
import uuid
import time
import random

class Redlock:
    """
    Impl√©mentation du pattern Redlock pour locks distribu√©s
    """

    # Script Lua pour release atomique
    UNLOCK_SCRIPT = """
    if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
    else
        return 0
    end
    """

    def __init__(self, redis_instances, lock_name, ttl=10000, retry_count=3, retry_delay=200):
        """
        Args:
            redis_instances: Liste de connexions Redis
            lock_name: Nom du lock
            ttl: Time-to-live en millisecondes
            retry_count: Nombre de tentatives
            retry_delay: D√©lai entre tentatives (ms)
        """
        self.instances = redis_instances
        self.lock_name = f"redlock:{lock_name}"
        self.ttl = ttl
        self.retry_count = retry_count
        self.retry_delay = retry_delay
        self.lock_id = str(uuid.uuid4())
        self.quorum = len(redis_instances) // 2 + 1
        self.validity_time = 0

    def acquire(self):
        """
        Acquiert le lock Redlock

        Returns:
            bool: True si lock acquis avec quorum
        """
        for attempt in range(self.retry_count):
            if attempt > 0:
                # Random delay avant retry (√©vite thundering herd)
                delay = random.uniform(0, self.retry_delay) / 1000.0
                time.sleep(delay)

            # Tentative d'acquisition
            if self._try_acquire():
                return True

        # √âchec apr√®s tous les retries
        return False

    def _try_acquire(self):
        """
        Tentative unique d'acquisition du lock
        """
        start_time = self._current_time_ms()
        acquired_count = 0

        # Tenter d'acqu√©rir sur toutes les instances
        for instance in self.instances:
            if self._acquire_instance(instance):
                acquired_count += 1

        # Calculer le temps √©coul√©
        elapsed = self._current_time_ms() - start_time

        # Calculer le temps de validit√© restant
        self.validity_time = self.ttl - elapsed - self._drift()

        # V√©rifier le quorum et la validit√©
        if acquired_count >= self.quorum and self.validity_time > 0:
            print(f"‚úì Redlock acquired: {acquired_count}/{len(self.instances)} instances")
            print(f"  Lock ID: {self.lock_id}")
            print(f"  Validity: {self.validity_time}ms")
            return True
        else:
            # √âchec : nettoyer les locks partiels
            print(f"‚úó Redlock failed: {acquired_count}/{len(self.instances)} instances")
            print(f"  Quorum needed: {self.quorum}")
            self._release_all()
            return False

    def _acquire_instance(self, instance):
        """
        Tente d'acqu√©rir le lock sur une instance Redis
        """
        try:
            # SET avec NX (not exists) et PX (expire milliseconds)
            result = instance.set(
                self.lock_name,
                self.lock_id,
                nx=True,
                px=self.ttl
            )
            return result is not None
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to acquire on instance: {e}")
            return False

    def release(self):
        """
        Lib√®re le lock sur toutes les instances
        """
        released_count = 0

        for instance in self.instances:
            try:
                result = instance.eval(
                    self.UNLOCK_SCRIPT,
                    1,
                    self.lock_name,
                    self.lock_id
                )
                if result:
                    released_count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è  Failed to release on instance: {e}")

        print(f"‚úì Redlock released on {released_count}/{len(self.instances)} instances")

    def _release_all(self):
        """
        Lib√®re le lock sur toutes les instances (best effort)
        """
        for instance in self.instances:
            try:
                instance.eval(self.UNLOCK_SCRIPT, 1, self.lock_name, self.lock_id)
            except:
                pass  # Ignore errors during cleanup

    def _current_time_ms(self):
        """Timestamp actuel en millisecondes"""
        return int(time.time() * 1000)

    def _drift(self):
        """
        Clock drift adjustment (recommandation Redlock)
        Typiquement 1% du TTL
        """
        return int(self.ttl * 0.01)

    def __enter__(self):
        """Support du context manager"""
        if not self.acquire():
            raise Exception("Failed to acquire Redlock")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Lib√©ration automatique"""
        self.release()


# ============================================================
# CONFIGURATION DES INSTANCES REDIS
# ============================================================

def setup_redis_instances():
    """
    Configure 5 instances Redis ind√©pendantes
    """
    # En production : 5 serveurs physiques diff√©rents
    # Pour le test : 5 instances sur ports diff√©rents

    instances = [
        redis.Redis(host='localhost', port=6379, decode_responses=True),
        redis.Redis(host='localhost', port=6380, decode_responses=True),
        redis.Redis(host='localhost', port=6381, decode_responses=True),
        redis.Redis(host='localhost', port=6382, decode_responses=True),
        redis.Redis(host='localhost', port=6383, decode_responses=True),
    ]

    return instances


# ============================================================
# EXEMPLE D'UTILISATION
# ============================================================

def process_critical_section():
    """
    Ex√©cute une section critique prot√©g√©e par Redlock
    """
    instances = setup_redis_instances()

    lock = Redlock(
        instances,
        lock_name="critical:resource",
        ttl=10000,  # 10 secondes
        retry_count=3,
        retry_delay=200
    )

    if lock.acquire():
        try:
            print("\nüîí Lock acquired - Processing critical section...")

            # Section critique
            time.sleep(2)
            print("   Processing...")
            time.sleep(2)
            print("   Almost done...")

            print("‚úì Critical section completed\n")

        finally:
            lock.release()
    else:
        print("‚ùå Could not acquire lock")


# ============================================================
# TEST AVEC CONTEXT MANAGER
# ============================================================

def process_with_context_manager():
    """
    Utilisation simplifi√©e avec context manager
    """
    instances = setup_redis_instances()

    try:
        with Redlock(instances, "critical:job", ttl=5000):
            print("üîí Processing with Redlock protection...")
            time.sleep(1)
            print("‚úì Done")
    except Exception as e:
        print(f"‚ùå Failed to acquire lock: {e}")


# ============================================================
# TEST CONCURRENT
# ============================================================

import threading

def worker_with_redlock(worker_id):
    """Worker utilisant Redlock"""
    print(f"Worker {worker_id} starting...")

    instances = setup_redis_instances()
    lock = Redlock(instances, "shared:resource", ttl=5000)

    if lock.acquire():
        try:
            print(f"  ‚úì Worker {worker_id} acquired lock")
            time.sleep(2)
            print(f"  ‚úì Worker {worker_id} finished work")
        finally:
            lock.release()
    else:
        print(f"  ‚úó Worker {worker_id} could not acquire lock")


def test_concurrent_redlock():
    """Test avec plusieurs workers concurrents"""
    print("=" * 60)
    print("TEST: Concurrent Access with Redlock")
    print("=" * 60 + "\n")

    threads = []

    # Lancer 3 workers concurrents
    for i in range(3):
        t = threading.Thread(target=worker_with_redlock, args=(i,))
        threads.append(t)
        t.start()
        time.sleep(0.1)  # Petit d√©lai entre d√©marrages

    for t in threads:
        t.join()

    print("\n‚úì Test completed")


# ============================================================
# BENCHMARK : Simple Lock vs Redlock
# ============================================================

def benchmark_lock_acquisition():
    """
    Compare les performances des deux approches
    """
    print("=" * 60)
    print("BENCHMARK: Lock Acquisition Performance")
    print("=" * 60 + "\n")

    # Simple lock
    redis_client = redis.Redis(decode_responses=True)
    simple_lock = SimpleRedisLock(redis_client, "benchmark", ttl=10)

    start = time.time()
    simple_lock.acquire()
    simple_elapsed = (time.time() - start) * 1000
    simple_lock.release()

    print(f"Simple Lock: {simple_elapsed:.2f}ms")

    # Redlock
    instances = setup_redis_instances()
    redlock = Redlock(instances, "benchmark", ttl=10000)

    start = time.time()
    redlock.acquire()
    redlock_elapsed = (time.time() - start) * 1000
    redlock.release()

    print(f"Redlock:     {redlock_elapsed:.2f}ms")
    print(f"\nOverhead: {redlock_elapsed - simple_elapsed:.2f}ms ({redlock_elapsed / simple_elapsed:.1f}x slower)")


# ============================================================
# MAIN
# ============================================================

if __name__ == '__main__':
    # Test basique
    print("=" * 60)
    print("REDLOCK BASIC TEST")
    print("=" * 60 + "\n")
    process_critical_section()

    # Test concurrent
    test_concurrent_redlock()

    # Benchmark
    benchmark_lock_acquisition()
```

---

## Impl√©mentation Node.js

### Redlock avec node-redlock

```javascript
const Redis = require('ioredis');
const Redlock = require('redlock');

// ============================================================
// CONFIGURATION DES INSTANCES
// ============================================================

function setupRedisInstances() {
    // Cr√©er 5 instances Redis ind√©pendantes
    return [
        new Redis({ host: 'localhost', port: 6379 }),
        new Redis({ host: 'localhost', port: 6380 }),
        new Redis({ host: 'localhost', port: 6381 }),
        new Redis({ host: 'localhost', port: 6382 }),
        new Redis({ host: 'localhost', port: 6383 }),
    ];
}

// ============================================================
// REDLOCK CLIENT
// ============================================================

function createRedlockClient() {
    const clients = setupRedisInstances();

    const redlock = new Redlock(clients, {
        // Retry automatique
        retryCount: 3,
        retryDelay: 200,  // milliseconds
        retryJitter: 50,  // random jitter

        // Drift factor (clock drift adjustment)
        driftFactor: 0.01,  // 1%

        // Timeouts
        automaticExtensionThreshold: 500,  // extend if < 500ms remaining
    });

    // Event listeners
    redlock.on('clientError', (err) => {
        console.error('Redlock client error:', err);
    });

    return { redlock, clients };
}

// ============================================================
// EXEMPLE BASIQUE
// ============================================================

async function basicExample() {
    console.log('='.repeat(60));
    console.log('REDLOCK BASIC EXAMPLE');
    console.log('='.repeat(60) + '\n');

    const { redlock, clients } = createRedlockClient();

    try {
        // Acqu√©rir le lock
        const lock = await redlock.acquire(
            ['redlock:critical:resource'],
            5000  // TTL: 5 secondes
        );

        console.log('‚úì Lock acquired');
        console.log(`  Resource: ${lock.resources}`);
        console.log(`  Value: ${lock.value}`);
        console.log(`  Expiration: ${lock.expiration}`);

        // Section critique
        console.log('\nüîí Processing critical section...');
        await new Promise(resolve => setTimeout(resolve, 2000));
        console.log('‚úì Processing completed\n');

        // Lib√©rer le lock
        await lock.release();
        console.log('‚úì Lock released');

    } catch (error) {
        console.error('‚ùå Error:', error.message);
    } finally {
        // Fermer les connexions
        await Promise.all(clients.map(client => client.quit()));
    }
}

// ============================================================
// USING BLOCK (Pattern recommand√©)
// ============================================================

async function usingBlockExample() {
    console.log('\n' + '='.repeat(60));
    console.log('REDLOCK USING BLOCK PATTERN');
    console.log('='.repeat(60) + '\n');

    const { redlock, clients } = createRedlockClient();

    try {
        // Using block : acquire + execute + release automatique
        await redlock.using(
            ['redlock:job:123'],
            5000,  // TTL
            async (signal) => {
                // Section critique
                console.log('üîí Lock acquired, processing job...');

                // V√©rifier si le lock est toujours valide
                if (signal.aborted) {
                    throw new Error('Lock expired during processing');
                }

                await new Promise(resolve => setTimeout(resolve, 1000));
                console.log('‚úì Job completed');
            }
        );

        console.log('‚úì Lock automatically released');

    } catch (error) {
        console.error('‚ùå Error:', error.message);
    } finally {
        await Promise.all(clients.map(client => client.quit()));
    }
}

// ============================================================
// LOCK EXTENSION (Prolonger le TTL)
// ============================================================

async function lockExtensionExample() {
    console.log('\n' + '='.repeat(60));
    console.log('LOCK EXTENSION EXAMPLE');
    console.log('='.repeat(60) + '\n');

    const { redlock, clients } = createRedlockClient();

    try {
        // Acqu√©rir avec TTL court
        let lock = await redlock.acquire(['redlock:long:task'], 3000);
        console.log('‚úì Lock acquired (3s TTL)');

        // Traitement long
        for (let i = 0; i < 5; i++) {
            console.log(`  Processing step ${i + 1}/5...`);
            await new Promise(resolve => setTimeout(resolve, 1000));

            // Prolonger le lock si n√©cessaire
            if (i < 4) {
                lock = await lock.extend(3000);
                console.log('  ‚Üª Lock extended (+3s)');
            }
        }

        console.log('‚úì Long task completed');
        await lock.release();
        console.log('‚úì Lock released');

    } catch (error) {
        console.error('‚ùå Error:', error.message);
    } finally {
        await Promise.all(clients.map(client => client.quit()));
    }
}

// ============================================================
// MULTI-RESOURCE LOCK
// ============================================================

async function multiResourceExample() {
    console.log('\n' + '='.repeat(60));
    console.log('MULTI-RESOURCE LOCK EXAMPLE');
    console.log('='.repeat(60) + '\n');

    const { redlock, clients } = createRedlockClient();

    try {
        // Acqu√©rir plusieurs ressources atomiquement
        const lock = await redlock.acquire(
            [
                'redlock:user:123',
                'redlock:account:456',
                'redlock:transaction:789'
            ],
            5000
        );

        console.log('‚úì Multi-resource lock acquired');
        console.log(`  Resources: ${lock.resources.length}`);

        // Op√©ration n√©cessitant toutes les ressources
        console.log('\nüîí Processing multi-resource transaction...');
        await new Promise(resolve => setTimeout(resolve, 1000));
        console.log('‚úì Transaction completed\n');

        await lock.release();
        console.log('‚úì All resources released');

    } catch (error) {
        console.error('‚ùå Error:', error.message);
    } finally {
        await Promise.all(clients.map(client => client.quit()));
    }
}

// ============================================================
// CONCURRENT TEST
// ============================================================

async function concurrentTest() {
    console.log('\n' + '='.repeat(60));
    console.log('CONCURRENT ACCESS TEST');
    console.log('='.repeat(60) + '\n');

    const { redlock, clients } = createRedlockClient();

    async function worker(id) {
        try {
            console.log(`Worker ${id} attempting to acquire lock...`);

            const lock = await redlock.acquire(
                ['redlock:shared:resource'],
                3000
            );

            console.log(`  ‚úì Worker ${id} acquired lock`);
            await new Promise(resolve => setTimeout(resolve, 1000));
            console.log(`  ‚úì Worker ${id} completed work`);

            await lock.release();

        } catch (error) {
            console.log(`  ‚úó Worker ${id} failed: ${error.message}`);
        }
    }

    // Lancer 5 workers concurrents
    await Promise.all([
        worker(1),
        worker(2),
        worker(3),
        worker(4),
        worker(5)
    ]);

    console.log('\n‚úì Concurrent test completed');

    await Promise.all(clients.map(client => client.quit()));
}

// ============================================================
// ERROR HANDLING
// ============================================================

async function errorHandlingExample() {
    console.log('\n' + '='.repeat(60));
    console.log('ERROR HANDLING EXAMPLE');
    console.log('='.repeat(60) + '\n');

    const { redlock, clients } = createRedlockClient();

    try {
        await redlock.using(
            ['redlock:critical:resource'],
            5000,
            async (signal) => {
                console.log('üîí Processing...');

                // Simuler une erreur
                await new Promise(resolve => setTimeout(resolve, 500));
                throw new Error('Processing failed!');
            }
        );
    } catch (error) {
        console.error('‚ùå Error caught:', error.message);
        console.log('‚úì Lock was automatically released despite error');
    } finally {
        await Promise.all(clients.map(client => client.quit()));
    }
}

// ============================================================
// PATTERN : JOB QUEUE WITH REDLOCK
// ============================================================

class JobQueue {
    constructor(redlock) {
        this.redlock = redlock;
    }

    async processJob(jobId) {
        console.log(`\nProcessing job ${jobId}...`);

        try {
            await this.redlock.using(
                [`redlock:job:${jobId}`],
                30000,  // 30s TTL
                async (signal) => {
                    console.log(`  ‚úì Lock acquired for job ${jobId}`);

                    // Simulate job processing
                    await this.simulateJobProcessing(jobId, signal);

                    console.log(`  ‚úì Job ${jobId} completed`);
                }
            );
        } catch (error) {
            if (error.message.includes('lock already held')) {
                console.log(`  ‚ö†Ô∏è  Job ${jobId} is being processed by another worker`);
            } else {
                console.error(`  ‚ùå Job ${jobId} failed:`, error.message);
            }
        }
    }

    async simulateJobProcessing(jobId, signal) {
        // Check signal periodically
        for (let i = 0; i < 5; i++) {
            if (signal.aborted) {
                throw new Error('Job processing aborted (lock expired)');
            }

            console.log(`    Step ${i + 1}/5...`);
            await new Promise(resolve => setTimeout(resolve, 500));
        }
    }
}

async function jobQueueExample() {
    console.log('\n' + '='.repeat(60));
    console.log('JOB QUEUE WITH REDLOCK');
    console.log('='.repeat(60));

    const { redlock, clients } = createRedlockClient();
    const queue = new JobQueue(redlock);

    // Process multiple jobs concurrently
    await Promise.all([
        queue.processJob(1),
        queue.processJob(2),
        queue.processJob(1),  // Duplicate - should fail
        queue.processJob(3),
    ]);

    console.log('\n‚úì Job queue test completed');

    await Promise.all(clients.map(client => client.quit()));
}

// ============================================================
// MAIN
// ============================================================

async function main() {
    try {
        await basicExample();
        await usingBlockExample();
        await lockExtensionExample();
        await multiResourceExample();
        await concurrentTest();
        await errorHandlingExample();
        await jobQueueExample();

    } catch (error) {
        console.error('Fatal error:', error);
    }
}

// Run
main();
```

---

## Cas d'usage r√©els

### 1. Scheduled Jobs (Cron distribu√©)

```python
import schedule
import time

class DistributedScheduler:
    """
    Scheduler distribu√© avec Redlock pour √©viter les doublons
    """

    def __init__(self, redis_instances):
        self.redis_instances = redis_instances

    def run_once(self, job_name, func, *args, **kwargs):
        """
        Ex√©cute un job une seule fois, m√™me avec plusieurs instances
        """
        lock = Redlock(
            self.redis_instances,
            f"cron:{job_name}",
            ttl=60000,  # 1 minute max
            retry_count=1  # Pas de retry pour les crons
        )

        if lock.acquire():
            try:
                print(f"üïê Executing scheduled job: {job_name}")
                result = func(*args, **kwargs)
                print(f"‚úì Job {job_name} completed")
                return result
            finally:
                lock.release()
        else:
            print(f"‚è≠Ô∏è  Job {job_name} already running on another instance")
            return None


# Utilisation
def send_daily_report():
    print("Generating daily report...")
    time.sleep(2)
    print("Report sent!")

def backup_database():
    print("Backing up database...")
    time.sleep(3)
    print("Backup completed!")

# Setup
instances = setup_redis_instances()
scheduler = DistributedScheduler(instances)

# Schedule jobs (lanc√© sur toutes les instances, mais ex√©cut√© une seule fois)
schedule.every().day.at("09:00").do(
    scheduler.run_once,
    "daily_report",
    send_daily_report
)

schedule.every().day.at("02:00").do(
    scheduler.run_once,
    "db_backup",
    backup_database
)

# Run scheduler
while True:
    schedule.run_pending()
    time.sleep(60)
```

### 2. Rate Limiting distribu√©

```python
class DistributedRateLimiter:
    """
    Rate limiter distribu√© avec Redlock
    """

    def __init__(self, redis_instances):
        self.redis_instances = redis_instances

    def allow_request(self, user_id, max_requests=100, window=60):
        """
        V√©rifie si la requ√™te est autoris√©e

        Args:
            user_id: ID de l'utilisateur
            max_requests: Nombre max de requ√™tes
            window: Fen√™tre en secondes

        Returns:
            bool: True si autoris√©
        """
        lock_key = f"ratelimit:{user_id}"
        counter_key = f"counter:{user_id}"

        lock = Redlock(
            self.redis_instances,
            lock_key,
            ttl=1000,  # 1 seconde
            retry_count=3
        )

        if lock.acquire():
            try:
                # Utiliser la premi√®re instance pour le compteur
                redis_client = self.redis_instances[0]

                # Obtenir le compteur actuel
                count = redis_client.get(counter_key)
                count = int(count) if count else 0

                if count >= max_requests:
                    print(f"‚ùå Rate limit exceeded for user {user_id}")
                    return False

                # Incr√©menter
                pipe = redis_client.pipeline()
                pipe.incr(counter_key)
                pipe.expire(counter_key, window)
                pipe.execute()

                print(f"‚úì Request allowed for user {user_id} ({count + 1}/{max_requests})")
                return True

            finally:
                lock.release()
        else:
            # Si on ne peut pas acqu√©rir le lock, on refuse par s√©curit√©
            print(f"‚ö†Ô∏è  Could not acquire lock for user {user_id}, request denied")
            return False


# Utilisation
limiter = DistributedRateLimiter(setup_redis_instances())

# Simuler des requ√™tes
for i in range(105):
    allowed = limiter.allow_request("user:123", max_requests=100, window=60)
    if not allowed:
        print(f"Request {i + 1} blocked")
```

### 3. Inventory Management (E-commerce)

```python
class DistributedInventory:
    """
    Gestion d'inventaire distribu√© sans overselling
    """

    def __init__(self, redis_instances):
        self.redis_instances = redis_instances

    def purchase_item(self, product_id, quantity=1):
        """
        Ach√®te un produit avec garantie anti-overselling
        """
        lock = Redlock(
            self.redis_instances,
            f"inventory:{product_id}",
            ttl=5000,
            retry_count=5,
            retry_delay=100
        )

        if lock.acquire():
            try:
                # Utiliser la premi√®re instance pour l'inventaire
                redis_client = self.redis_instances[0]
                stock_key = f"stock:{product_id}"

                # V√©rifier le stock
                current_stock = redis_client.get(stock_key)
                current_stock = int(current_stock) if current_stock else 0

                if current_stock < quantity:
                    print(f"‚ùå Insufficient stock for product {product_id}")
                    print(f"   Available: {current_stock}, Requested: {quantity}")
                    return False

                # D√©cr√©menter le stock
                new_stock = redis_client.decrby(stock_key, quantity)

                print(f"‚úì Purchase successful!")
                print(f"   Product: {product_id}")
                print(f"   Quantity: {quantity}")
                print(f"   Remaining stock: {new_stock}")

                return True

            finally:
                lock.release()
        else:
            print(f"‚ùå Could not acquire lock for product {product_id}")
            return False


# Simulation vente flash avec 10 workers concurrents
import threading

def simulate_purchase(inventory, product_id, worker_id):
    print(f"Worker {worker_id} attempting purchase...")
    success = inventory.purchase_item(product_id, quantity=1)
    if success:
        print(f"  Worker {worker_id} purchased successfully")
    else:
        print(f"  Worker {worker_id} purchase failed")

# Setup
instances = setup_redis_instances()
inventory = DistributedInventory(instances)

# Initialiser le stock
instances[0].set("stock:product:123", 5)  # Seulement 5 items

# Lancer 10 workers qui tentent d'acheter
threads = []
for i in range(10):
    t = threading.Thread(
        target=simulate_purchase,
        args=(inventory, "product:123", i)
    )
    threads.append(t)
    t.start()

for t in threads:
    t.join()

# V√©rifier le stock final
final_stock = instances[0].get("stock:product:123")
print(f"\n‚úì Final stock: {final_stock}")
print(f"  Expected: 0 (5 purchases from 10 attempts)")
```

---

## Limitations et alternatives

### Limitations de Redlock

```text
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    REDLOCK LIMITATIONS                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. ‚ùå Pas de garantie absolue en cas de :
   - Pause GC (garbage collection) longue
   - Clock drift important entre instances
   - Network partition prolong√©e

2. ‚ö†Ô∏è  Complexit√© op√©rationnelle :
   - Besoin de N instances Redis (N=5 recommand√©)
   - Monitoring de toutes les instances
   - Coordination r√©seau

3. üêå Performance :
   - Latence = N √ó RTT (s√©quentiel)
   - Overhead par rapport √† simple lock

4. üí∞ Co√ªt :
   - N instances Redis √† maintenir
   - Plus de ressources n√©cessaires
```

### Tableau comparatif

| Aspect | Simple Lock | Redlock | ZooKeeper | etcd |
|--------|-------------|---------|-----------|------|
| **Setup** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Simple | ‚≠ê‚≠ê‚≠ê Medium | ‚≠ê‚≠ê Complex | ‚≠ê‚≠ê Complex |
| **Performance** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê Good |
| **Garanties** | ‚≠ê‚≠ê Weak | ‚≠ê‚≠ê‚≠ê Medium | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Strong | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Strong |
| **Disponibilit√©** | ‚≠ê‚≠ê Low | ‚≠ê‚≠ê‚≠ê‚≠ê High | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very High | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Very High |
| **Use case** | Cache, jobs | Critical jobs | Coordination | Coordination |

### Quand utiliser quoi ?

```python
# ‚úÖ Simple Redis Lock
def use_simple_lock():
    """
    Bon pour :
    - Cache invalidation
    - Job processing (non-critique)
    - Rate limiting (soft)
    - Une seule instance Redis suffit
    - Performance critique
    """
    lock = SimpleRedisLock(redis_client, "job:123")
    with lock:
        process_job()

# ‚úÖ Redlock
def use_redlock():
    """
    Bon pour :
    - Op√©rations importantes mais pas critiques
    - E-commerce (inventory)
    - Scheduled jobs (cron)
    - Balance entre performance et garanties
    - Tol√©rance aux erreurs acceptable
    """
    lock = Redlock(redis_instances, "inventory:123")
    with lock:
        update_inventory()

# ‚úÖ ZooKeeper/etcd
def use_zookeeper():
    """
    Bon pour :
    - Transactions financi√®res
    - Leader election
    - Configuration distribu√©e
    - Garanties fortes requises
    - Coordination de services
    - Tol√©rance z√©ro aux erreurs
    """
    # Utiliser ZooKeeper ou etcd pour strong consistency
    pass
```

---

## Bonnes pratiques

### Checklist de production

**Configuration Redlock :**
- ‚úÖ Utiliser N=5 instances minimum (quorum = 3)
- ‚úÖ Instances sur machines/datacenters diff√©rents
- ‚úÖ Pas de r√©plication master-slave (ind√©pendantes)
- ‚úÖ Monitoring de toutes les instances

**TTL et Timing :**
- ‚úÖ TTL > temps de traitement attendu √ó 2
- ‚úÖ Clock drift factor configur√© (1%)
- ‚úÖ Retry avec exponential backoff
- ‚úÖ Random jitter sur les retries

**Error Handling :**
- ‚úÖ Toujours lib√©rer le lock (finally/cleanup)
- ‚úÖ G√©rer les cas o√π le lock expire pendant le traitement
- ‚úÖ Logging complet des acquisitions/releases
- ‚úÖ Alertes si taux d'√©chec > seuil

**Testing :**
- ‚úÖ Tester avec failures d'instances
- ‚úÖ Tester avec clock drift simul√©
- ‚úÖ Tester avec network partitions
- ‚úÖ Tester les cas de contention (concurrent access)

### Anti-patterns √† √©viter

```python
# ‚ùå BAD: TTL trop court
lock = Redlock(instances, "job", ttl=1000)  # 1 seconde
with lock:
    time.sleep(5)  # Processing prend 5 secondes
    # Lock expire avant la fin!

# ‚úÖ GOOD: TTL appropri√©
lock = Redlock(instances, "job", ttl=10000)  # 10 secondes
with lock:
    time.sleep(5)  # OK, marge de s√©curit√©


# ‚ùå BAD: Pas de cleanup en cas d'erreur
lock = Redlock(instances, "resource", ttl=5000)
lock.acquire()
process()  # Si erreur ici, lock jamais lib√©r√©!
lock.release()

# ‚úÖ GOOD: Toujours cleanup
lock = Redlock(instances, "resource", ttl=5000)
try:
    lock.acquire()
    process()
finally:
    lock.release()


# ‚ùå BAD: Lock sur cl√© trop large
lock = Redlock(instances, "users", ttl=5000)  # Tous les users!
with lock:
    update_user(user_id)  # Bloque TOUS les users

# ‚úÖ GOOD: Lock granulaire
lock = Redlock(instances, f"user:{user_id}", ttl=5000)
with lock:
    update_user(user_id)  # Bloque seulement ce user
```

---

## Monitoring et m√©triques

### M√©triques importantes

```python
from prometheus_client import Counter, Histogram, Gauge

# M√©triques Redlock
redlock_acquisitions = Counter(
    'redlock_acquisitions_total',
    'Total lock acquisitions',
    ['status']  # 'success', 'failure'
)

redlock_duration = Histogram(
    'redlock_acquisition_duration_seconds',
    'Time to acquire lock'
)

redlock_validity = Histogram(
    'redlock_validity_time_seconds',
    'Remaining validity time after acquisition'
)

redlock_releases = Counter(
    'redlock_releases_total',
    'Total lock releases'
)

redlock_active_locks = Gauge(
    'redlock_active_locks',
    'Number of currently held locks'
)


class MonitoredRedlock(Redlock):
    """
    Redlock avec monitoring Prometheus
    """

    def acquire(self):
        start = time.time()

        success = super().acquire()

        duration = time.time() - start
        redlock_duration.observe(duration)

        if success:
            redlock_acquisitions.labels(status='success').inc()
            redlock_validity.observe(self.validity_time / 1000.0)
            redlock_active_locks.inc()
        else:
            redlock_acquisitions.labels(status='failure').inc()

        return success

    def release(self):
        super().release()
        redlock_releases.inc()
        redlock_active_locks.dec()
```

---

## Conclusion

Le **Distributed Locking** est essentiel pour coordonner des applications distribu√©es. Les points cl√©s :

**Simple Redis Lock :**
- ‚úÖ Facile √† impl√©menter
- ‚úÖ Excellent pour cas non-critiques
- ‚ùå Pas de garanties fortes
- ‚ùå Single point of failure

**Redlock :**
- ‚úÖ Meilleures garanties que simple lock
- ‚úÖ Haute disponibilit√© (quorum)
- ‚úÖ Bon compromis performance/fiabilit√©
- ‚ùå Configuration plus complexe
- ‚ùå Pas de garanties absolues

**ZooKeeper/etcd :**
- ‚úÖ Garanties fortes (consensus)
- ‚úÖ Coordination avanc√©e
- ‚ùå Plus complexe et plus lent
- ‚ùå Overhead important

**Recommandations :**
1. Commencer avec Simple Lock si possible
2. Passer √† Redlock pour plus de fiabilit√©
3. Utiliser ZooKeeper/etcd si garanties critiques
4. Toujours tester avec failures
5. Monitoring obligatoire en production

Le choix d√©pend de votre cas d'usage : privil√©gier la simplicit√© tant que les garanties ne sont pas critiques, puis monter en complexit√© si n√©cessaire.

---


‚è≠Ô∏è [Rate Limiting : Fixed Window, Sliding Window, Token Bucket](/06-patterns-developpement-avances/06-rate-limiting-patterns.md)
