ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 6.6 Rate Limiting : Fixed Window, Sliding Window, Token Bucket

## Introduction

Le **Rate Limiting** est une technique essentielle pour protÃ©ger vos services contre les abus, garantir une qualitÃ© de service Ã©quitable entre utilisateurs, et respecter les quotas d'APIs externes. Redis, avec ses opÃ©rations atomiques et son support natif de TTL, est parfaitement adaptÃ© pour implÃ©menter diffÃ©rents algorithmes de rate limiting.

Cette section explore les principaux algorithmes : Fixed Window, Sliding Window (Log et Counter), et Token Bucket, avec leurs avantages, inconvÃ©nients et implÃ©mentations production-ready.

## Pourquoi le Rate Limiting ?

### Cas d'usage typiques

**1. Protection contre les abus (DDoS, bruteforce)**

```text
ScÃ©nario : Attaque bruteforce sur login

Sans rate limiting:
- Attacker tente 10,000 passwords/seconde
- Serveur surchargÃ©
- Service indisponible pour tous âŒ

Avec rate limiting (5 tentatives/minute):
- Attacker limitÃ© Ã  5 tentatives
- Serveur protÃ©gÃ©
- Service disponible âœ…
```

**2. Fairness entre utilisateurs (Quality of Service)**

```text
ScÃ©nario : API partagÃ©e entre clients

Sans rate limiting:
- Client A fait 10,000 req/s
- Client B ne peut plus accÃ©der
- Client C attend âŒ

Avec rate limiting (100 req/s par client):
- Chaque client a son quota
- Ressources partagÃ©es Ã©quitablement
- Tous les clients satisfaits âœ…
```

**3. Respect des quotas APIs externes**

```text
ScÃ©nario : Appel d'une API tierce (ex: Twitter API)

Twitter API limit: 300 req/15min

Sans rate limiting interne:
- Application fait 500 requÃªtes
- Twitter bloque l'application âŒ
- Service indisponible 15 minutes

Avec rate limiting (290 req/15min):
- Application respecte la limite
- Pas de blocage
- Service stable âœ…
```

**4. ContrÃ´le des coÃ»ts**

```text
ScÃ©nario : Service cloud avec pricing par requÃªte

Sans rate limiting:
- Bug gÃ©nÃ¨re 1M requÃªtes
- Facture = $10,000 âŒ

Avec rate limiting (10K req/hour):
- Maximum 10K requÃªtes
- Facture contrÃ´lÃ©e âœ…
```

---

## Pattern 1: Fixed Window Counter

### Principe

Le **Fixed Window** divise le temps en fenÃªtres fixes (ex: 1 minute) et compte les requÃªtes dans chaque fenÃªtre.

```text
Timeline:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         Window 1            Window 2            Window 3
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    00:00          00:60 01:00          02:00 02:00

Limit: 10 requests per window

Window 1:  [â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…]     8 requests  âœ… OK
Window 2:  [â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…] 12 requests âŒ 2 rejected
Window 3:  [â˜…â˜…â˜…]           3 requests  âœ… OK
```

### Avantages et inconvÃ©nients

**Avantages :**
- âœ… TrÃ¨s simple Ã  implÃ©menter
- âœ… TrÃ¨s rapide (O(1))
- âœ… Peu de mÃ©moire (une clÃ© par fenÃªtre)
- âœ… Compatible avec TTL Redis

**InconvÃ©nients :**
- âŒ Burst Ã  la frontiÃ¨re des fenÃªtres
- âŒ Peut permettre 2Ã— la limite

### ProblÃ¨me du burst

```text
PROBLÃˆME : Burst Ã  la frontiÃ¨re

Limit: 10 req/minute

Timeline:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
           Window 1                 Window 2
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      00:00            00:59  01:00            01:59

t=00:59  [â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…] 10 requests (window 1) âœ…
         â†“ Window change
t=01:00  [â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…] 10 requests (window 2) âœ…

Result: 20 requests in 1 second! (10 at 00:59 + 10 at 01:00)
Expected: Maximum 10 requests per minute
```

### ImplÃ©mentation Python

```python
import redis
import time
from datetime import datetime

class FixedWindowRateLimiter:
    """
    Rate limiter avec Fixed Window Counter
    """

    def __init__(self, redis_client, max_requests=100, window_seconds=60):
        """
        Args:
            redis_client: Client Redis
            max_requests: Nombre max de requÃªtes par fenÃªtre
            window_seconds: DurÃ©e de la fenÃªtre en secondes
        """
        self.redis = redis_client
        self.max_requests = max_requests
        self.window_seconds = window_seconds

    def allow_request(self, user_id):
        """
        VÃ©rifie si la requÃªte est autorisÃ©e

        Returns:
            tuple: (allowed: bool, remaining: int, reset_time: int)
        """
        # Calculer la fenÃªtre actuelle
        current_window = int(time.time() / self.window_seconds)
        key = f"rate_limit:fixed:{user_id}:{current_window}"

        # Obtenir le compteur actuel
        current_count = self.redis.get(key)
        current_count = int(current_count) if current_count else 0

        # VÃ©rifier la limite
        if current_count >= self.max_requests:
            # Calculer le temps de reset
            reset_time = (current_window + 1) * self.window_seconds
            remaining = 0

            print(f"âŒ Rate limit exceeded for {user_id}")
            print(f"   Current: {current_count}/{self.max_requests}")
            print(f"   Reset in: {reset_time - int(time.time())}s")

            return False, remaining, reset_time

        # IncrÃ©menter le compteur
        pipe = self.redis.pipeline()
        pipe.incr(key)
        pipe.expire(key, self.window_seconds * 2)  # Safety margin
        results = pipe.execute()

        new_count = results[0]
        remaining = self.max_requests - new_count
        reset_time = (current_window + 1) * self.window_seconds

        print(f"âœ“ Request allowed for {user_id}")
        print(f"   Used: {new_count}/{self.max_requests}")
        print(f"   Remaining: {remaining}")

        return True, remaining, reset_time


# ============================================================
# EXEMPLE D'UTILISATION
# ============================================================

def test_fixed_window():
    """Test du Fixed Window rate limiter"""
    redis_client = redis.Redis(decode_responses=True)

    # Limiter Ã  5 requÃªtes par 10 secondes
    limiter = FixedWindowRateLimiter(
        redis_client,
        max_requests=5,
        window_seconds=10
    )

    print("=" * 60)
    print("FIXED WINDOW RATE LIMITER TEST")
    print("=" * 60 + "\n")

    user_id = "user:123"

    # Tester 7 requÃªtes
    for i in range(7):
        print(f"\nRequest {i + 1}:")
        allowed, remaining, reset_time = limiter.allow_request(user_id)

        if not allowed:
            print(f"Blocked! Wait {reset_time - int(time.time())}s")

        time.sleep(0.5)


# ============================================================
# IMPLÃ‰MENTATION AVEC LUA SCRIPT (Plus performant)
# ============================================================

class OptimizedFixedWindowRateLimiter:
    """
    Version optimisÃ©e avec Lua script atomique
    """

    LUA_SCRIPT = """
    local key = KEYS[1]
    local max_requests = tonumber(ARGV[1])
    local window = tonumber(ARGV[2])

    local current = redis.call('GET', key)

    if current and tonumber(current) >= max_requests then
        return {0, tonumber(current), 0}
    end

    local count = redis.call('INCR', key)

    if count == 1 then
        redis.call('EXPIRE', key, window * 2)
    end

    return {1, count, max_requests - count}
    """

    def __init__(self, redis_client, max_requests=100, window_seconds=60):
        self.redis = redis_client
        self.max_requests = max_requests
        self.window_seconds = window_seconds

        # Enregistrer le script Lua
        self.script_sha = self.redis.script_load(self.LUA_SCRIPT)

    def allow_request(self, user_id):
        """VÃ©rifie si la requÃªte est autorisÃ©e (version atomique)"""
        current_window = int(time.time() / self.window_seconds)
        key = f"rate_limit:fixed:{user_id}:{current_window}"

        # ExÃ©cuter le script Lua
        result = self.redis.evalsha(
            self.script_sha,
            1,
            key,
            self.max_requests,
            self.window_seconds
        )

        allowed = bool(result[0])
        current_count = result[1]
        remaining = result[2]

        reset_time = (current_window + 1) * self.window_seconds

        return allowed, remaining, reset_time


# ============================================================
# DECORATOR POUR FLASK/FASTAPI
# ============================================================

from functools import wraps
from flask import request, jsonify

def rate_limit(max_requests=100, window_seconds=60):
    """
    Decorator pour rate limiting sur endpoints Flask
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            redis_client = redis.Redis(decode_responses=True)
            limiter = FixedWindowRateLimiter(
                redis_client,
                max_requests=max_requests,
                window_seconds=window_seconds
            )

            # Identifier l'utilisateur (IP ou user_id)
            user_id = request.remote_addr

            allowed, remaining, reset_time = limiter.allow_request(user_id)

            if not allowed:
                return jsonify({
                    'error': 'Rate limit exceeded',
                    'retry_after': reset_time - int(time.time())
                }), 429

            # Ajouter les headers de rate limiting
            response = func(*args, **kwargs)
            if isinstance(response, tuple):
                response, status_code = response
            else:
                status_code = 200

            headers = {
                'X-RateLimit-Limit': str(max_requests),
                'X-RateLimit-Remaining': str(remaining),
                'X-RateLimit-Reset': str(reset_time)
            }

            return response, status_code, headers

        return wrapper
    return decorator


# Utilisation avec Flask
# @app.route('/api/data')
# @rate_limit(max_requests=100, window_seconds=60)
# def get_data():
#     return {'data': 'some data'}
```

---

## Pattern 2: Sliding Window Log

### Principe

Le **Sliding Window Log** enregistre le timestamp de chaque requÃªte et compte combien de requÃªtes sont dans la fenÃªtre glissante actuelle.

```text
Timeline (limit: 10 req/minute):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Current time: 12:01:30

Sliding Window = [12:00:30 - 12:01:30] (last 60 seconds)

Request log:
  12:00:15  â† Outside window (removed)
  12:00:45  â˜… In window
  12:00:50  â˜… In window
  12:01:00  â˜… In window
  12:01:10  â˜… In window
  12:01:20  â˜… In window
  12:01:25  â˜… In window
             â”‚
             â””â”€ Count: 6 requests âœ… Allow

New request at 12:01:30:
  Add timestamp to log
  Remove timestamps < 12:00:30
  Count = 7 âœ… Still OK
```

### Avantages et inconvÃ©nients

**Avantages :**
- âœ… PrÃ©cision parfaite (vraie fenÃªtre glissante)
- âœ… Pas de burst Ã  la frontiÃ¨re
- âœ… Limite strictement respectÃ©e

**InconvÃ©nients :**
- âŒ Beaucoup de mÃ©moire (stocke tous les timestamps)
- âŒ Performance O(N) oÃ¹ N = nombre de requÃªtes
- âŒ Cleanup nÃ©cessaire des vieux timestamps

### ImplÃ©mentation Python

```python
import redis
import time

class SlidingWindowLogRateLimiter:
    """
    Rate limiter avec Sliding Window Log
    Utilise un Sorted Set Redis pour stocker les timestamps
    """

    def __init__(self, redis_client, max_requests=100, window_seconds=60):
        self.redis = redis_client
        self.max_requests = max_requests
        self.window_seconds = window_seconds

    def allow_request(self, user_id):
        """
        VÃ©rifie si la requÃªte est autorisÃ©e

        Returns:
            tuple: (allowed: bool, remaining: int)
        """
        key = f"rate_limit:sliding_log:{user_id}"
        now = time.time()
        window_start = now - self.window_seconds

        # Utiliser une transaction pour atomicitÃ©
        pipe = self.redis.pipeline()

        # 1. Supprimer les entrÃ©es expirÃ©es (avant la fenÃªtre)
        pipe.zremrangebyscore(key, 0, window_start)

        # 2. Compter les requÃªtes dans la fenÃªtre
        pipe.zcard(key)

        # 3. Ajouter la requÃªte actuelle (on l'ajoute avant de vÃ©rifier)
        pipe.zadd(key, {str(now): now})

        # 4. DÃ©finir expiration de la clÃ©
        pipe.expire(key, self.window_seconds)

        results = pipe.execute()

        # Le compte est avant l'ajout de la requÃªte actuelle
        current_count = results[1]

        if current_count >= self.max_requests:
            # Supprimer la requÃªte qu'on vient d'ajouter
            self.redis.zrem(key, str(now))

            remaining = 0
            print(f"âŒ Rate limit exceeded for {user_id}")
            print(f"   Current: {current_count}/{self.max_requests}")

            return False, remaining

        remaining = self.max_requests - current_count - 1

        print(f"âœ“ Request allowed for {user_id}")
        print(f"   Used: {current_count + 1}/{self.max_requests}")
        print(f"   Remaining: {remaining}")

        return True, remaining


# ============================================================
# VERSION OPTIMISÃ‰E AVEC LUA
# ============================================================

class OptimizedSlidingWindowLogRateLimiter:
    """
    Version optimisÃ©e avec Lua script
    """

    LUA_SCRIPT = """
    local key = KEYS[1]
    local now = tonumber(ARGV[1])
    local window = tonumber(ARGV[2])
    local max_requests = tonumber(ARGV[3])
    local request_id = ARGV[4]

    local window_start = now - window

    -- Supprimer les anciennes entrÃ©es
    redis.call('ZREMRANGEBYSCORE', key, 0, window_start)

    -- Compter les requÃªtes dans la fenÃªtre
    local count = redis.call('ZCARD', key)

    if count >= max_requests then
        return {0, count, 0}
    end

    -- Ajouter la nouvelle requÃªte
    redis.call('ZADD', key, now, request_id)
    redis.call('EXPIRE', key, window)

    return {1, count + 1, max_requests - count - 1}
    """

    def __init__(self, redis_client, max_requests=100, window_seconds=60):
        self.redis = redis_client
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.script_sha = self.redis.script_load(self.LUA_SCRIPT)

    def allow_request(self, user_id):
        """Version atomique avec Lua"""
        key = f"rate_limit:sliding_log:{user_id}"
        now = time.time()
        request_id = f"{now}:{id(self)}"

        result = self.redis.evalsha(
            self.script_sha,
            1,
            key,
            now,
            self.window_seconds,
            self.max_requests,
            request_id
        )

        allowed = bool(result[0])
        current_count = result[1]
        remaining = result[2]

        return allowed, remaining


# ============================================================
# TEST ET COMPARAISON
# ============================================================

def test_sliding_window_log():
    """Test du Sliding Window Log"""
    redis_client = redis.Redis(decode_responses=True)
    redis_client.flushdb()

    limiter = SlidingWindowLogRateLimiter(
        redis_client,
        max_requests=5,
        window_seconds=10
    )

    print("=" * 60)
    print("SLIDING WINDOW LOG TEST")
    print("=" * 60 + "\n")

    user_id = "user:456"

    # Test avec timestamps prÃ©cis
    print("Making 5 requests at t=0:")
    for i in range(5):
        allowed, remaining = limiter.allow_request(user_id)
        print(f"  Request {i + 1}: {'âœ“' if allowed else 'âœ—'} (remaining: {remaining})")

    print("\nRequest at t=0 (should fail):")
    allowed, remaining = limiter.allow_request(user_id)
    print(f"  {'âœ“' if allowed else 'âœ—'} (remaining: {remaining})")

    print("\nWaiting 6 seconds...")
    time.sleep(6)

    print("\nRequest at t=6 (should succeed - window sliding):")
    allowed, remaining = limiter.allow_request(user_id)
    print(f"  {'âœ“' if allowed else 'âœ—'} (remaining: {remaining})")
```

---

## Pattern 3: Sliding Window Counter

### Principe

Le **Sliding Window Counter** est un compromis entre Fixed Window et Sliding Log. Il utilise deux compteurs (fenÃªtre actuelle et prÃ©cÃ©dente) et calcule une approximation de la fenÃªtre glissante.

```text
Timeline:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Window size: 60 seconds
Current time: 12:01:30 (30 seconds into current window)

Previous Window [12:00:00 - 12:01:00]:  count = 8
Current Window  [12:01:00 - 12:02:00]:  count = 3

Calculation:
  30 seconds into current window = 50% progress

  Estimated count = current_count + (previous_count Ã— overlap_percentage)
                  = 3 + (8 Ã— 50%)
                  = 3 + 4
                  = 7 requests

If limit = 10: 7 < 10 âœ… Allow
```

### Formule

```text
estimated_count = current_window_count +
                  (previous_window_count Ã— overlap_ratio)

overlap_ratio = (window_size - elapsed_time_in_current_window) / window_size

Example:
  window_size = 60s
  current_time = 12:01:45 (45s into current window)
  elapsed = 45s

  overlap_ratio = (60 - 45) / 60 = 15 / 60 = 0.25 (25%)

  If previous = 10, current = 2:
  estimated = 2 + (10 Ã— 0.25) = 2 + 2.5 = 4.5 â‰ˆ 5
```

### Avantages et inconvÃ©nients

**Avantages :**
- âœ… Bon compromis prÃ©cision/performance
- âœ… MÃ©moire O(1) (seulement 2 compteurs)
- âœ… Performance O(1)
- âœ… Meilleur que Fixed Window pour les bursts

**InconvÃ©nients :**
- âŒ Approximation (pas parfaitement prÃ©cis)
- âŒ Peut permettre lÃ©gÃ¨rement plus que la limite
- âŒ Plus complexe Ã  comprendre

### ImplÃ©mentation Python

```python
import redis
import time
import math

class SlidingWindowCounterRateLimiter:
    """
    Rate limiter avec Sliding Window Counter
    Utilise deux fenÃªtres (actuelle et prÃ©cÃ©dente)
    """

    def __init__(self, redis_client, max_requests=100, window_seconds=60):
        self.redis = redis_client
        self.max_requests = max_requests
        self.window_seconds = window_seconds

    def allow_request(self, user_id):
        """
        VÃ©rifie si la requÃªte est autorisÃ©e

        Returns:
            tuple: (allowed: bool, remaining: int)
        """
        now = time.time()
        current_window = int(now / self.window_seconds)
        previous_window = current_window - 1

        # ClÃ©s pour les deux fenÃªtres
        current_key = f"rate_limit:sliding_counter:{user_id}:{current_window}"
        previous_key = f"rate_limit:sliding_counter:{user_id}:{previous_window}"

        # Obtenir les compteurs
        pipe = self.redis.pipeline()
        pipe.get(current_key)
        pipe.get(previous_key)
        results = pipe.execute()

        current_count = int(results[0]) if results[0] else 0
        previous_count = int(results[1]) if results[1] else 0

        # Calculer le pourcentage d'overlap avec la fenÃªtre prÃ©cÃ©dente
        elapsed_time_in_current_window = now - (current_window * self.window_seconds)
        overlap_ratio = (self.window_seconds - elapsed_time_in_current_window) / self.window_seconds

        # Estimation du nombre de requÃªtes dans la fenÃªtre glissante
        estimated_count = current_count + (previous_count * overlap_ratio)

        if estimated_count >= self.max_requests:
            remaining = 0
            print(f"âŒ Rate limit exceeded for {user_id}")
            print(f"   Estimated: {estimated_count:.2f}/{self.max_requests}")
            print(f"   Current window: {current_count}")
            print(f"   Previous window: {previous_count} (Ã—{overlap_ratio:.2%})")

            return False, remaining

        # IncrÃ©menter le compteur de la fenÃªtre actuelle
        pipe = self.redis.pipeline()
        pipe.incr(current_key)
        pipe.expire(current_key, self.window_seconds * 2)
        pipe.execute()

        remaining = math.floor(self.max_requests - estimated_count - 1)

        print(f"âœ“ Request allowed for {user_id}")
        print(f"   Estimated: {estimated_count + 1:.2f}/{self.max_requests}")
        print(f"   Remaining: {remaining}")

        return True, remaining


# ============================================================
# VERSION OPTIMISÃ‰E AVEC LUA
# ============================================================

class OptimizedSlidingWindowCounterRateLimiter:
    """
    Version optimisÃ©e avec Lua script
    """

    LUA_SCRIPT = """
    local current_key = KEYS[1]
    local previous_key = KEYS[2]
    local now = tonumber(ARGV[1])
    local window = tonumber(ARGV[2])
    local max_requests = tonumber(ARGV[3])
    local current_window_start = tonumber(ARGV[4])

    -- Obtenir les compteurs
    local current_count = tonumber(redis.call('GET', current_key) or 0)
    local previous_count = tonumber(redis.call('GET', previous_key) or 0)

    -- Calculer l'overlap ratio
    local elapsed = now - current_window_start
    local overlap_ratio = (window - elapsed) / window

    -- Estimation
    local estimated_count = current_count + (previous_count * overlap_ratio)

    if estimated_count >= max_requests then
        return {0, math.floor(estimated_count), 0}
    end

    -- IncrÃ©menter
    redis.call('INCR', current_key)
    redis.call('EXPIRE', current_key, window * 2)

    local new_estimated = estimated_count + 1
    local remaining = math.floor(max_requests - new_estimated)

    return {1, math.floor(new_estimated), remaining}
    """

    def __init__(self, redis_client, max_requests=100, window_seconds=60):
        self.redis = redis_client
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.script_sha = self.redis.script_load(self.LUA_SCRIPT)

    def allow_request(self, user_id):
        """Version atomique avec Lua"""
        now = time.time()
        current_window = int(now / self.window_seconds)
        previous_window = current_window - 1
        current_window_start = current_window * self.window_seconds

        current_key = f"rate_limit:sliding_counter:{user_id}:{current_window}"
        previous_key = f"rate_limit:sliding_counter:{user_id}:{previous_window}"

        result = self.redis.evalsha(
            self.script_sha,
            2,
            current_key,
            previous_key,
            now,
            self.window_seconds,
            self.max_requests,
            current_window_start
        )

        allowed = bool(result[0])
        estimated_count = result[1]
        remaining = result[2]

        return allowed, remaining
```

---

## Pattern 4: Token Bucket

### Principe

Le **Token Bucket** est comme un seau avec des jetons. Les jetons sont ajoutÃ©s Ã  un taux constant, et chaque requÃªte consomme un jeton. Si le seau est vide, la requÃªte est refusÃ©e.

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TOKEN BUCKET                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Bucket capacity: 10 tokens
Refill rate: 1 token/second

State at t=0:  [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 10 tokens

t=0   Request â†’ take 1 token â†’ [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 9 tokens âœ…
t=1   Request â†’ take 1 token â†’ [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 8 tokens âœ…
      + Refill 1 token       â†’ [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 9 tokens

t=2   Request â†’ take 1 token â†’ [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 8 tokens âœ…
      + Refill 1 token       â†’ [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 9 tokens

Burst of 10 requests at t=3:
  Take 9 tokens              â†’ [âšª] 0 tokens
  10th request fails âŒ

Wait 5 seconds...
  + Refill 5 tokens          â†’ [ğŸª™ğŸª™ğŸª™ğŸª™ğŸª™] 5 tokens

New request at t=8           â†’ [ğŸª™ğŸª™ğŸª™ğŸª™] 4 tokens âœ…
```

### Algorithme

```text
ALGORITHM: Token Bucket

State:
- tokens: current number of tokens in bucket
- last_refill: timestamp of last refill
- capacity: maximum tokens (bucket size)
- refill_rate: tokens added per second

On each request:
1. Calculate elapsed time since last refill
   elapsed = now - last_refill

2. Calculate tokens to add
   tokens_to_add = elapsed Ã— refill_rate

3. Refill bucket (up to capacity)
   tokens = min(tokens + tokens_to_add, capacity)
   last_refill = now

4. Check if enough tokens
   if tokens >= 1:
       tokens = tokens - 1
       return ALLOW
   else:
       return DENY
```

### Avantages et inconvÃ©nients

**Avantages :**
- âœ… Permet les bursts contrÃ´lÃ©s (jusqu'Ã  capacity)
- âœ… Lissage du trafic
- âœ… MÃ©moire O(1)
- âœ… Flexible (diffÃ©rents rates pour diffÃ©rentes actions)

**InconvÃ©nients :**
- âŒ Plus complexe Ã  implÃ©menter
- âŒ NÃ©cessite calcul Ã  chaque requÃªte
- âŒ Pas de fenÃªtre temporelle fixe

### ImplÃ©mentation Python

```python
import redis
import time
import json

class TokenBucketRateLimiter:
    """
    Rate limiter avec Token Bucket algorithm
    """

    def __init__(self, redis_client, capacity=100, refill_rate=10):
        """
        Args:
            redis_client: Client Redis
            capacity: Taille du bucket (nombre max de tokens)
            refill_rate: Nombre de tokens ajoutÃ©s par seconde
        """
        self.redis = redis_client
        self.capacity = capacity
        self.refill_rate = refill_rate

    def allow_request(self, user_id, tokens_required=1):
        """
        VÃ©rifie si la requÃªte est autorisÃ©e

        Args:
            user_id: ID de l'utilisateur
            tokens_required: Nombre de tokens requis (par dÃ©faut 1)

        Returns:
            tuple: (allowed: bool, tokens_available: float)
        """
        key = f"rate_limit:token_bucket:{user_id}"
        now = time.time()

        # Obtenir l'Ã©tat actuel du bucket
        bucket_data = self.redis.get(key)

        if bucket_data:
            bucket = json.loads(bucket_data)
            tokens = bucket['tokens']
            last_refill = bucket['last_refill']
        else:
            # Premier accÃ¨s : bucket plein
            tokens = self.capacity
            last_refill = now

        # Calculer les tokens Ã  ajouter depuis le dernier refill
        elapsed = now - last_refill
        tokens_to_add = elapsed * self.refill_rate

        # Refill le bucket (sans dÃ©passer capacity)
        tokens = min(tokens + tokens_to_add, self.capacity)

        # VÃ©rifier si assez de tokens
        if tokens >= tokens_required:
            # Consommer les tokens
            tokens -= tokens_required

            # Sauvegarder le nouvel Ã©tat
            new_bucket = {
                'tokens': tokens,
                'last_refill': now
            }
            self.redis.setex(
                key,
                int(self.capacity / self.refill_rate) * 2,  # TTL
                json.dumps(new_bucket)
            )

            print(f"âœ“ Request allowed for {user_id}")
            print(f"   Tokens used: {tokens_required}")
            print(f"   Tokens remaining: {tokens:.2f}/{self.capacity}")

            return True, tokens
        else:
            # Pas assez de tokens
            # On met Ã  jour quand mÃªme pour le refill
            new_bucket = {
                'tokens': tokens,
                'last_refill': now
            }
            self.redis.setex(
                key,
                int(self.capacity / self.refill_rate) * 2,
                json.dumps(new_bucket)
            )

            print(f"âŒ Rate limit exceeded for {user_id}")
            print(f"   Tokens needed: {tokens_required}")
            print(f"   Tokens available: {tokens:.2f}/{self.capacity}")

            # Calculer le temps d'attente
            tokens_needed = tokens_required - tokens
            wait_time = tokens_needed / self.refill_rate
            print(f"   Wait time: {wait_time:.1f}s")

            return False, tokens


# ============================================================
# VERSION OPTIMISÃ‰E AVEC LUA
# ============================================================

class OptimizedTokenBucketRateLimiter:
    """
    Token Bucket avec Lua script pour atomicitÃ©
    """

    LUA_SCRIPT = """
    local key = KEYS[1]
    local capacity = tonumber(ARGV[1])
    local refill_rate = tonumber(ARGV[2])
    local tokens_required = tonumber(ARGV[3])
    local now = tonumber(ARGV[4])
    local ttl = tonumber(ARGV[5])

    -- Obtenir l'Ã©tat actuel
    local bucket_data = redis.call('GET', key)
    local tokens, last_refill

    if bucket_data then
        local bucket = cjson.decode(bucket_data)
        tokens = tonumber(bucket.tokens)
        last_refill = tonumber(bucket.last_refill)
    else
        tokens = capacity
        last_refill = now
    end

    -- Refill
    local elapsed = now - last_refill
    local tokens_to_add = elapsed * refill_rate
    tokens = math.min(tokens + tokens_to_add, capacity)

    -- Check et consommation
    if tokens >= tokens_required then
        tokens = tokens - tokens_required

        local new_bucket = {
            tokens = tokens,
            last_refill = now
        }

        redis.call('SETEX', key, ttl, cjson.encode(new_bucket))

        return {1, tokens}
    else
        local new_bucket = {
            tokens = tokens,
            last_refill = now
        }

        redis.call('SETEX', key, ttl, cjson.encode(new_bucket))

        return {0, tokens}
    end
    """

    def __init__(self, redis_client, capacity=100, refill_rate=10):
        self.redis = redis_client
        self.capacity = capacity
        self.refill_rate = refill_rate
        self.script_sha = self.redis.script_load(self.LUA_SCRIPT)

    def allow_request(self, user_id, tokens_required=1):
        """Version atomique avec Lua"""
        key = f"rate_limit:token_bucket:{user_id}"
        now = time.time()
        ttl = int(self.capacity / self.refill_rate) * 2

        result = self.redis.evalsha(
            self.script_sha,
            1,
            key,
            self.capacity,
            self.refill_rate,
            tokens_required,
            now,
            ttl
        )

        allowed = bool(result[0])
        tokens_available = result[1]

        return allowed, tokens_available


# ============================================================
# TOKEN BUCKET AVEC COÃ›TS VARIABLES
# ============================================================

class WeightedTokenBucketRateLimiter:
    """
    Token Bucket avec coÃ»ts diffÃ©rents par opÃ©ration
    """

    def __init__(self, redis_client, capacity=1000, refill_rate=10):
        self.limiter = OptimizedTokenBucketRateLimiter(
            redis_client,
            capacity=capacity,
            refill_rate=refill_rate
        )

        # CoÃ»ts par type d'opÃ©ration
        self.costs = {
            'read': 1,          # Lecture simple
            'write': 5,         # Ã‰criture
            'search': 10,       # Recherche complexe
            'report': 50,       # GÃ©nÃ©ration de rapport
            'export': 100,      # Export massif
        }

    def allow_operation(self, user_id, operation_type):
        """
        VÃ©rifie si l'opÃ©ration est autorisÃ©e

        Args:
            user_id: ID de l'utilisateur
            operation_type: Type d'opÃ©ration ('read', 'write', etc.)
        """
        cost = self.costs.get(operation_type, 1)

        allowed, tokens = self.limiter.allow_request(user_id, tokens_required=cost)

        if allowed:
            print(f"âœ“ {operation_type} operation allowed (cost: {cost} tokens)")
        else:
            print(f"âŒ {operation_type} operation denied (cost: {cost} tokens)")

        return allowed, tokens


# ============================================================
# TEST
# ============================================================

def test_token_bucket():
    """Test du Token Bucket"""
    redis_client = redis.Redis(decode_responses=True)
    redis_client.flushdb()

    # Bucket avec 10 tokens, refill 2 tokens/seconde
    limiter = TokenBucketRateLimiter(
        redis_client,
        capacity=10,
        refill_rate=2
    )

    print("=" * 60)
    print("TOKEN BUCKET RATE LIMITER TEST")
    print("=" * 60 + "\n")

    user_id = "user:789"

    # Test burst
    print("Testing burst (10 requests immediately):")
    for i in range(12):
        allowed, tokens = limiter.allow_request(user_id)
        print(f"  Request {i + 1}: {'âœ“' if allowed else 'âœ—'} ({tokens:.2f} tokens left)")

    print("\nWaiting 5 seconds for refill...")
    time.sleep(5)

    print("\nAfter 5 seconds (should have ~10 tokens):")
    allowed, tokens = limiter.allow_request(user_id)
    print(f"  Request: {'âœ“' if allowed else 'âœ—'} ({tokens:.2f} tokens left)")


def test_weighted_token_bucket():
    """Test avec coÃ»ts variables"""
    redis_client = redis.Redis(decode_responses=True)
    redis_client.flushdb()

    limiter = WeightedTokenBucketRateLimiter(
        redis_client,
        capacity=100,
        refill_rate=10
    )

    print("\n" + "=" * 60)
    print("WEIGHTED TOKEN BUCKET TEST")
    print("=" * 60 + "\n")

    user_id = "user:premium"

    # DiffÃ©rentes opÃ©rations
    operations = [
        'read', 'read', 'write', 'search', 'read',
        'write', 'report', 'export', 'read'
    ]

    for op in operations:
        allowed, tokens = limiter.allow_operation(user_id, op)
        print(f"  Remaining tokens: {tokens:.2f}/100\n")
        time.sleep(0.5)
```

---

## ImplÃ©mentation Node.js

### Fixed Window

```javascript
const Redis = require('ioredis');

class FixedWindowRateLimiter {
    constructor(redis, maxRequests = 100, windowSeconds = 60) {
        this.redis = redis;
        this.maxRequests = maxRequests;
        this.windowSeconds = windowSeconds;
    }

    async allowRequest(userId) {
        const currentWindow = Math.floor(Date.now() / 1000 / this.windowSeconds);
        const key = `rate_limit:fixed:${userId}:${currentWindow}`;

        const currentCount = await this.redis.get(key) || 0;

        if (currentCount >= this.maxRequests) {
            const resetTime = (currentWindow + 1) * this.windowSeconds;
            return {
                allowed: false,
                remaining: 0,
                resetTime: resetTime
            };
        }

        const pipeline = this.redis.pipeline();
        pipeline.incr(key);
        pipeline.expire(key, this.windowSeconds * 2);
        const results = await pipeline.exec();

        const newCount = results[0][1];
        const remaining = this.maxRequests - newCount;
        const resetTime = (currentWindow + 1) * this.windowSeconds;

        return {
            allowed: true,
            remaining: remaining,
            resetTime: resetTime,
            current: newCount
        };
    }
}

// Usage
async function testFixedWindow() {
    const redis = new Redis();
    const limiter = new FixedWindowRateLimiter(redis, 5, 10);

    console.log('='.repeat(60));
    console.log('FIXED WINDOW TEST');
    console.log('='.repeat(60) + '\n');

    for (let i = 0; i < 7; i++) {
        const result = await limiter.allowRequest('user:123');
        console.log(`Request ${i + 1}: ${result.allowed ? 'âœ“' : 'âœ—'} (${result.remaining} remaining)`);
        await new Promise(resolve => setTimeout(resolve, 500));
    }

    await redis.quit();
}

testFixedWindow();
```

### Sliding Window Log

```javascript
class SlidingWindowLogRateLimiter {
    constructor(redis, maxRequests = 100, windowSeconds = 60) {
        this.redis = redis;
        this.maxRequests = maxRequests;
        this.windowSeconds = windowSeconds;

        // Lua script for atomic operations
        this.luaScript = `
            local key = KEYS[1]
            local now = tonumber(ARGV[1])
            local window = tonumber(ARGV[2])
            local max_requests = tonumber(ARGV[3])
            local request_id = ARGV[4]

            local window_start = now - window

            redis.call('ZREMRANGEBYSCORE', key, 0, window_start)

            local count = redis.call('ZCARD', key)

            if count >= max_requests then
                return {0, count, 0}
            end

            redis.call('ZADD', key, now, request_id)
            redis.call('EXPIRE', key, window)

            return {1, count + 1, max_requests - count - 1}
        `;
    }

    async allowRequest(userId) {
        const key = `rate_limit:sliding_log:${userId}`;
        const now = Date.now() / 1000;
        const requestId = `${now}:${Math.random()}`;

        const result = await this.redis.eval(
            this.luaScript,
            1,
            key,
            now,
            this.windowSeconds,
            this.maxRequests,
            requestId
        );

        return {
            allowed: Boolean(result[0]),
            current: result[1],
            remaining: result[2]
        };
    }
}
```

### Token Bucket

```javascript
class TokenBucketRateLimiter {
    constructor(redis, capacity = 100, refillRate = 10) {
        this.redis = redis;
        this.capacity = capacity;
        this.refillRate = refillRate;

        this.luaScript = `
            local key = KEYS[1]
            local capacity = tonumber(ARGV[1])
            local refill_rate = tonumber(ARGV[2])
            local tokens_required = tonumber(ARGV[3])
            local now = tonumber(ARGV[4])
            local ttl = tonumber(ARGV[5])

            local bucket_data = redis.call('GET', key)
            local tokens, last_refill

            if bucket_data then
                local bucket = cjson.decode(bucket_data)
                tokens = tonumber(bucket.tokens)
                last_refill = tonumber(bucket.last_refill)
            else
                tokens = capacity
                last_refill = now
            end

            local elapsed = now - last_refill
            local tokens_to_add = elapsed * refill_rate
            tokens = math.min(tokens + tokens_to_add, capacity)

            if tokens >= tokens_required then
                tokens = tokens - tokens_required

                local new_bucket = {
                    tokens = tokens,
                    last_refill = now
                }

                redis.call('SETEX', key, ttl, cjson.encode(new_bucket))

                return {1, tokens}
            else
                local new_bucket = {
                    tokens = tokens,
                    last_refill = now
                }

                redis.call('SETEX', key, ttl, cjson.encode(new_bucket))

                return {0, tokens}
            end
        `;
    }

    async allowRequest(userId, tokensRequired = 1) {
        const key = `rate_limit:token_bucket:${userId}`;
        const now = Date.now() / 1000;
        const ttl = Math.floor(this.capacity / this.refillRate) * 2;

        const result = await this.redis.eval(
            this.luaScript,
            1,
            key,
            this.capacity,
            this.refillRate,
            tokensRequired,
            now,
            ttl
        );

        return {
            allowed: Boolean(result[0]),
            tokensAvailable: result[1]
        };
    }
}

// Express middleware
function createRateLimitMiddleware(limiter) {
    return async (req, res, next) => {
        const userId = req.user?.id || req.ip;

        const result = await limiter.allowRequest(userId);

        // Add headers
        res.setHeader('X-RateLimit-Limit', limiter.maxRequests || limiter.capacity);
        res.setHeader('X-RateLimit-Remaining', result.remaining || Math.floor(result.tokensAvailable));

        if (!result.allowed) {
            res.setHeader('Retry-After', 60);
            return res.status(429).json({
                error: 'Too Many Requests',
                message: 'Rate limit exceeded. Please try again later.'
            });
        }

        next();
    };
}

// Usage with Express
// const limiter = new TokenBucketRateLimiter(redis, 100, 10);
// app.use('/api', createRateLimitMiddleware(limiter));
```

---

## Comparaison des algorithmes

### Tableau comparatif

| Algorithme | MÃ©moire | Performance | PrÃ©cision | Bursts | ComplexitÃ© |
|------------|---------|-------------|-----------|--------|------------|
| **Fixed Window** | â­â­â­â­â­ O(1) | â­â­â­â­â­ Excellent | â­â­ Faible | âŒ Permet 2Ã— | â­â­â­â­â­ Simple |
| **Sliding Log** | â­â­ O(N) | â­â­â­ Moyen | â­â­â­â­â­ Parfait | âœ… ContrÃ´lÃ© | â­â­ Complexe |
| **Sliding Counter** | â­â­â­â­ O(1) | â­â­â­â­ Bon | â­â­â­â­ Bon | âœ… Meilleur | â­â­â­ Moyen |
| **Token Bucket** | â­â­â­â­ O(1) | â­â­â­â­ Bon | â­â­â­â­ Bon | âœ… Flexible | â­â­â­ Moyen |

### Visualisation des bursts

```text
Limit: 10 req/min

FIXED WINDOW:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Window 1     â”‚ Window 2
00:59 [â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…] 10 req âœ…
01:00 [â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…] 10 req âœ…
Result: 20 req in 1 second! âŒ

SLIDING WINDOW LOG:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Any 60-second window: MAX 10 requests
00:59 to 01:59: [â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…] EXACTLY 10 âœ…

SLIDING WINDOW COUNTER:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Estimation based on 2 windows
Slightly more accurate than Fixed Window
May allow ~11-12 req (approximation) âš ï¸

TOKEN BUCKET:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Burst of 10 initially: [â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…] âœ…
Then 1 token/6s refill
Smooth traffic over time âœ…
```

### Quand utiliser chaque algorithme ?

```python
# âœ… Fixed Window
"""
Bon pour:
- APIs publiques simples
- Protection basique
- Haute performance requise
- MÃ©moire limitÃ©e

Cas d'usage:
- Rate limiting gÃ©nÃ©ral
- Protection anti-spam basique
- Quotas journaliers
"""

# âœ… Sliding Window Log
"""
Bon pour:
- Limites strictes requises
- Pas de tolÃ©rance aux bursts
- PrÃ©cision critique

Cas d'usage:
- APIs de paiement
- OpÃ©rations critiques
- Respect strict de quotas externes
"""

# âœ… Sliding Window Counter
"""
Bon pour:
- Compromis performance/prÃ©cision
- Limites moyennement strictes
- Production standard

Cas d'usage:
- APIs d'entreprise
- Services SaaS
- Rate limiting gÃ©nÃ©ral (recommandÃ©)
"""

# âœ… Token Bucket
"""
Bon pour:
- Trafic variable
- Bursts contrÃ´lÃ©s acceptables
- CoÃ»ts variables par opÃ©ration

Cas d'usage:
- CDN
- File upload/download
- APIs avec opÃ©rations diffÃ©rentes
- Gaming (actions diffÃ©rentes)
"""
```

---

## Patterns avancÃ©s

### Multi-tier Rate Limiting

```python
class MultiTierRateLimiter:
    """
    Rate limiting Ã  plusieurs niveaux
    """

    def __init__(self, redis_client):
        self.redis = redis_client

        # DiffÃ©rents tiers
        self.tiers = {
            'free': {
                'per_second': 1,
                'per_minute': 10,
                'per_hour': 100,
                'per_day': 1000
            },
            'basic': {
                'per_second': 5,
                'per_minute': 100,
                'per_hour': 1000,
                'per_day': 10000
            },
            'premium': {
                'per_second': 50,
                'per_minute': 1000,
                'per_hour': 10000,
                'per_day': 100000
            }
        }

    def allow_request(self, user_id, tier='free'):
        """
        VÃ©rifie toutes les limites du tier
        """
        limits = self.tiers[tier]

        # VÃ©rifier chaque limite
        checks = [
            ('per_second', FixedWindowRateLimiter(
                self.redis, limits['per_second'], 1)),
            ('per_minute', FixedWindowRateLimiter(
                self.redis, limits['per_minute'], 60)),
            ('per_hour', FixedWindowRateLimiter(
                self.redis, limits['per_hour'], 3600)),
            ('per_day', FixedWindowRateLimiter(
                self.redis, limits['per_day'], 86400)),
        ]

        for name, limiter in checks:
            allowed, remaining, reset_time = limiter.allow_request(user_id)

            if not allowed:
                print(f"âŒ {tier.upper()} tier {name} limit exceeded")
                return False, name, remaining, reset_time

        print(f"âœ“ Request allowed for {tier.upper()} tier user")
        return True, None, None, None
```

### Adaptive Rate Limiting

```python
class AdaptiveRateLimiter:
    """
    Rate limiter adaptatif basÃ© sur la charge systÃ¨me
    """

    def __init__(self, redis_client, base_limit=100):
        self.redis = redis_client
        self.base_limit = base_limit

    def get_current_load(self):
        """
        Obtient la charge systÃ¨me actuelle
        (SimplifiÃ© - en prod, utiliser vraies mÃ©triques)
        """
        # Simuler : 0.0 (pas de charge) Ã  1.0 (pleine charge)
        return 0.5  # 50% de charge

    def get_adjusted_limit(self):
        """
        Ajuste la limite en fonction de la charge
        """
        load = self.get_current_load()

        if load < 0.5:
            # Charge faible : autoriser plus
            multiplier = 1.5
        elif load < 0.8:
            # Charge normale
            multiplier = 1.0
        else:
            # Charge Ã©levÃ©e : rÃ©duire
            multiplier = 0.5

        adjusted_limit = int(self.base_limit * multiplier)

        print(f"System load: {load*100:.0f}%")
        print(f"Adjusted limit: {adjusted_limit} req/min (base: {self.base_limit})")

        return adjusted_limit

    def allow_request(self, user_id):
        """VÃ©rifie avec limite ajustÃ©e"""
        current_limit = self.get_adjusted_limit()

        limiter = FixedWindowRateLimiter(
            self.redis,
            max_requests=current_limit,
            window_seconds=60
        )

        return limiter.allow_request(user_id)
```

### Rate Limiting par endpoint

```python
class EndpointRateLimiter:
    """
    Rate limiter diffÃ©rent par endpoint
    """

    def __init__(self, redis_client):
        self.redis = redis_client

        # Configuration par endpoint
        self.limits = {
            '/api/search': {'limit': 10, 'window': 60},    # Expensive
            '/api/read': {'limit': 100, 'window': 60},     # Cheap
            '/api/write': {'limit': 50, 'window': 60},     # Medium
            '/api/export': {'limit': 5, 'window': 3600},   # Very expensive
        }

    def allow_request(self, user_id, endpoint):
        """VÃ©rifie la limite pour l'endpoint spÃ©cifique"""
        config = self.limits.get(endpoint, {'limit': 60, 'window': 60})

        limiter = FixedWindowRateLimiter(
            self.redis,
            max_requests=config['limit'],
            window_seconds=config['window']
        )

        key = f"{user_id}:{endpoint}"
        return limiter.allow_request(key)
```

---

## Bonnes pratiques

### Checklist de production

**Configuration :**
- âœ… Choisir l'algorithme adaptÃ© au cas d'usage
- âœ… DÃ©finir des limites rÃ©alistes (tester en production)
- âœ… DiffÃ©rencier les tiers d'utilisateurs (free/premium)
- âœ… Rate limiting par endpoint (coÃ»ts diffÃ©rents)

**Headers HTTP :**
- âœ… `X-RateLimit-Limit`: Limite totale
- âœ… `X-RateLimit-Remaining`: RequÃªtes restantes
- âœ… `X-RateLimit-Reset`: Timestamp de reset
- âœ… `Retry-After`: Temps d'attente en secondes (429)

**Monitoring :**
- âœ… Tracker le nombre de requÃªtes bloquÃ©es
- âœ… Alerter si taux de blocage > 5%
- âœ… Mesurer l'impact sur la latence
- âœ… Logger les abus (potentiels attacks)

**Error Handling :**
- âœ… Retourner 429 (Too Many Requests)
- âœ… Message d'erreur clair
- âœ… Indiquer quand rÃ©essayer
- âœ… Ne pas rÃ©vÃ©ler d'infos sensibles

**Testing :**
- âœ… Tester les limites exactes
- âœ… Tester les bursts
- âœ… Tester le comportement Ã  la frontiÃ¨re
- âœ… Load testing avec rate limiter actif

### Anti-patterns Ã  Ã©viter

```python
# âŒ BAD: Limites trop restrictives
limiter = FixedWindowRateLimiter(redis_client, max_requests=1, window_seconds=3600)
# 1 requÃªte par heure = service inutilisable

# âœ… GOOD: Limites raisonnables
limiter = FixedWindowRateLimiter(redis_client, max_requests=100, window_seconds=60)


# âŒ BAD: Pas de diffÃ©renciation
# Tous les endpoints ont la mÃªme limite
# /api/read et /api/export coÃ»tent pareil

# âœ… GOOD: Limites par endpoint
limits = {
    '/api/read': 1000,    # Cheap operation
    '/api/export': 10,    # Expensive operation
}


# âŒ BAD: Bloquer sans explication
if not limiter.allow_request(user_id):
    return 429  # Pas d'info pour l'utilisateur

# âœ… GOOD: Messages clairs
if not limiter.allow_request(user_id):
    return {
        'error': 'Rate limit exceeded',
        'limit': 100,
        'window': '60 seconds',
        'retry_after': 30
    }, 429


# âŒ BAD: Rate limiting uniquement cÃ´tÃ© client
# Client peut bypass facilement

# âœ… GOOD: Rate limiting cÃ´tÃ© serveur (obligatoire)
@app.route('/api/data')
@rate_limit(100, 60)
def get_data():
    return data
```

---

## Conclusion

Le **Rate Limiting** est essentiel pour protÃ©ger vos services et garantir une qualitÃ© de service Ã©quitable. Les points clÃ©s :

**Choix de l'algorithme :**
- **Fixed Window** : Simple, rapide, mais permet bursts
- **Sliding Window Log** : PrÃ©cis, mais gourmand en mÃ©moire
- **Sliding Window Counter** : Bon compromis (recommandÃ©)
- **Token Bucket** : Flexible, bon pour trafic variable

**Recommandations :**
1. Commencer avec Fixed Window pour simplicitÃ©
2. Passer Ã  Sliding Window Counter si bursts problÃ©matiques
3. Utiliser Token Bucket pour coÃ»ts variables
4. Sliding Window Log seulement si prÃ©cision critique

**Best Practices :**
- Toujours implÃ©menter cÃ´tÃ© serveur
- Utiliser des limites raisonnables
- DiffÃ©rencier par tier et endpoint
- Inclure les headers HTTP appropriÃ©s
- Monitoring obligatoire
- Messages d'erreur clairs

Le rate limiting n'est pas juste une protection technique, c'est aussi une question d'UX et de business model !

---


â­ï¸ [Session Store et gestion d'Ã©tat](/06-patterns-developpement-avances/07-session-store-gestion-etat.md)
