ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# Module 6 : Patterns de dÃ©veloppement avancÃ©s

## Introduction

Redis n'est pas simplement une base de donnÃ©es clÃ©-valeur rapide. C'est une plateforme puissante qui permet d'implÃ©menter des patterns architecturaux sophistiquÃ©s pour rÃ©soudre des problÃ¨mes complexes de dÃ©veloppement d'applications distribuÃ©es modernes.

Ce module explore les patterns de dÃ©veloppement avancÃ©s qui exploitent les capacitÃ©s uniques de Redis : sa rapiditÃ©, son modÃ¨le de donnÃ©es riche, ses opÃ©rations atomiques et ses primitives de synchronisation. Ces patterns sont Ã©prouvÃ©s en production par des entreprises gÃ©rant des millions de requÃªtes par seconde.

## Pourquoi des patterns avancÃ©s ?

### Les dÃ©fis des systÃ¨mes modernes

Les applications distribuÃ©es modernes font face Ã  des dÃ©fis complexes :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DÃ‰FIS ARCHITECTURAUX                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ğŸ”„ ScalabilitÃ© Horizontale                                 â”‚
â”‚     â””â”€ GÃ©rer des milliers de serveurs simultanÃ©ment         â”‚
â”‚                                                             â”‚
â”‚  âš¡ Performance Sub-milliseconde                            â”‚
â”‚     â””â”€ RÃ©pondre en moins de 1ms Ã  99.9% des requÃªtes        â”‚
â”‚                                                             â”‚
â”‚  ğŸ”’ CohÃ©rence des DonnÃ©es                                   â”‚
â”‚     â””â”€ Ã‰viter les race conditions dans un systÃ¨me distribuÃ© â”‚
â”‚                                                             â”‚
â”‚  ğŸ›¡ï¸  Protection contre les Abus                             â”‚
â”‚     â””â”€ Rate limiting, anti-spam, anti-fraude                â”‚
â”‚                                                             â”‚
â”‚  ğŸ“Š Gestion d'Ã‰tat DistribuÃ©                                â”‚
â”‚     â””â”€ Sessions, locks, compteurs partagÃ©s                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Redis comme solution

Redis offre des primitives uniques qui le rendent idÃ©al pour ces patterns :

| CaractÃ©ristique | BÃ©nÃ©fice pour les patterns |
|----------------|----------------------------|
| **OpÃ©rations atomiques** | Ã‰vite les race conditions sans locking complexe |
| **Single-threaded** | Garantit l'ordre d'exÃ©cution des commandes |
| **Sub-millisecond latency** | Permet des dÃ©cisions en temps rÃ©el |
| **Structures de donnÃ©es riches** | ModÃ©lise directement les problÃ¨mes mÃ©tier |
| **Persistence optionnelle** | Balance entre vitesse et durabilitÃ© |
| **Pub/Sub & Streams** | Communication temps rÃ©el entre services |

## Architecture des patterns avancÃ©s

### Vue d'ensemble

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PATTERNS REDIS AVANCÃ‰S                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€ ğŸ—„ï¸  CACHING PATTERNS
           â”‚    â”œâ”€ Cache-Aside (Lazy Loading)
           â”‚    â”œâ”€ Write-Through (Eager Writing)
           â”‚    â”œâ”€ Write-Back (Delayed Writing)
           â”‚    â””â”€ Cache-First (Read-Heavy)
           â”‚
           â”œâ”€â”€â”€ ğŸ›¡ï¸  RESILIENCE PATTERNS
           â”‚    â”œâ”€ Anti-Avalanche (Circuit Breaker)
           â”‚    â”œâ”€ Anti-Stampede (Lock + Queue)
           â”‚    â””â”€ Anti-Penetration (Bloom Filter)
           â”‚
           â”œâ”€â”€â”€ âš¡ PERFORMANCE PATTERNS
           â”‚    â”œâ”€ Pipelining (Batch Operations)
           â”‚    â”œâ”€ Client-Side Caching (Local Cache)
           â”‚    â””â”€ Lazy Expiration (TTL Strategy)
           â”‚
           â”œâ”€â”€â”€ ğŸ”’ SYNCHRONIZATION PATTERNS
           â”‚    â”œâ”€ Distributed Lock (Redlock)
           â”‚    â”œâ”€ Semaphore (Resource Limiting)
           â”‚    â””â”€ Leader Election
           â”‚
           â”œâ”€â”€â”€ ğŸš¦ RATE LIMITING PATTERNS
           â”‚    â”œâ”€ Fixed Window Counter
           â”‚    â”œâ”€ Sliding Window Log
           â”‚    â”œâ”€ Sliding Window Counter
           â”‚    â””â”€ Token Bucket
           â”‚
           â”œâ”€â”€â”€ ğŸ’¾ STATE MANAGEMENT PATTERNS
           â”‚    â”œâ”€ Session Store (User State)
           â”‚    â”œâ”€ Shopping Cart (E-commerce)
           â”‚    â””â”€ Real-time Presence (Online Users)
           â”‚
           â””â”€â”€â”€ ğŸ“¬ MESSAGING PATTERNS
                â”œâ”€ Job Queue (Background Tasks)
                â”œâ”€ Priority Queue (Urgent Tasks)
                â””â”€ Delayed Queue (Scheduled Tasks)
```

## Concepts fondamentaux

### 1. AtomicitÃ© et opÃ©rations composÃ©es

Redis garantit que chaque commande s'exÃ©cute atomiquement. Pour des opÃ©rations composÃ©es, trois approches existent :

```python
# âŒ MAUVAIS : Non-atomique (race condition possible)
import redis

r = redis.Redis()

# Thread 1 et Thread 2 peuvent exÃ©cuter ceci simultanÃ©ment
current_value = int(r.get('counter') or 0)
new_value = current_value + 1
r.set('counter', new_value)
# âš ï¸ Risque de perte de comptage !
```

```python
# âœ… BON : OpÃ©ration atomique native
r.incr('counter')  # Atomique, thread-safe
```

```python
# âœ… BON : Transaction MULTI/EXEC
pipe = r.pipeline()
pipe.multi()
pipe.incr('counter')
pipe.incr('total_requests')
pipe.execute()  # Les deux opÃ©rations sont exÃ©cutÃ©es atomiquement
```

```python
# âœ… BON : Script Lua (opÃ©ration complexe atomique)
lua_script = """
local current = redis.call('GET', KEYS[1])
if not current then
    current = 0
else
    current = tonumber(current)
end

if current < tonumber(ARGV[1]) then
    redis.call('INCR', KEYS[1])
    return 1
else
    return 0
end
"""

# IncrÃ©mente seulement si < max_value
result = r.eval(lua_script, 1, 'counter', '100')
```

### 2. Time-To-Live (TTL) stratÃ©gique

Le TTL est au cÅ“ur de nombreux patterns Redis :

```javascript
// Node.js avec ioredis
const Redis = require('ioredis');
const redis = new Redis();

// Pattern 1: TTL dÃ¨s la crÃ©ation
async function cacheWithTTL(key, value, ttlSeconds) {
    await redis.setex(key, ttlSeconds, JSON.stringify(value));
}

// Pattern 2: TTL conditionnel (refresh sur lecture)
async function getWithRefresh(key, ttlSeconds) {
    const value = await redis.get(key);
    if (value) {
        // RafraÃ®chir le TTL si accÃ©dÃ© (Sliding Window)
        await redis.expire(key, ttlSeconds);
    }
    return value ? JSON.parse(value) : null;
}

// Pattern 3: TTL diffÃ©renciÃ© par prioritÃ©
async function cacheByPriority(key, value, priority) {
    const ttlMap = {
        'high': 3600,    // 1 heure
        'medium': 1800,  // 30 minutes
        'low': 900       // 15 minutes
    };
    await redis.setex(key, ttlMap[priority] || 600, JSON.stringify(value));
}
```

### 3. Patterns de nommage

Une convention de nommage cohÃ©rente est critique :

```python
# Structure de clÃ© recommandÃ©e: {service}:{entity}:{id}:{attribute}

class RedisKeyBuilder:
    @staticmethod
    def user_session(user_id):
        return f"auth:session:{user_id}"

    @staticmethod
    def user_cart(user_id):
        return f"ecommerce:cart:{user_id}"

    @staticmethod
    def api_rate_limit(user_id, endpoint):
        return f"ratelimit:user:{user_id}:{endpoint}"

    @staticmethod
    def cache_query(query_hash):
        return f"cache:query:{query_hash}"

    @staticmethod
    def lock(resource_name):
        return f"lock:{resource_name}"

# Utilisation
session_key = RedisKeyBuilder.user_session("user_12345")
# RÃ©sultat: "auth:session:user_12345"

# Avantages:
# 1. Facilite le debugging (redis-cli KEYS auth:session:*)
# 2. Permet des TTL par namespace
# 3. Ã‰vite les collisions de clÃ©s
# 4. Facilite le monitoring par service
```

### 4. Gestion d'erreurs et rÃ©silience

```javascript
// Pattern de connexion robuste avec retry
const Redis = require('ioredis');

const redis = new Redis({
    host: 'localhost',
    port: 6379,
    retryStrategy: (times) => {
        const delay = Math.min(times * 50, 2000);
        return delay;
    },
    maxRetriesPerRequest: 3,
    enableReadyCheck: true,
    enableOfflineQueue: true
});

// Pattern de fallback
async function safeGet(key, defaultValue = null) {
    try {
        const value = await redis.get(key);
        return value ? JSON.parse(value) : defaultValue;
    } catch (error) {
        console.error('Redis error:', error);
        return defaultValue; // Graceful degradation
    }
}

// Pattern de timeout
async function getWithTimeout(key, timeoutMs = 100) {
    return Promise.race([
        redis.get(key),
        new Promise((_, reject) =>
            setTimeout(() => reject(new Error('Timeout')), timeoutMs)
        )
    ]);
}
```

## MÃ©triques et observabilitÃ©

### Instrumenter les patterns

```python
import time
from functools import wraps

class RedisMetrics:
    def __init__(self):
        self.hits = 0
        self.misses = 0
        self.errors = 0
        self.total_latency = 0
        self.operations = 0

    def record_hit(self):
        self.hits += 1

    def record_miss(self):
        self.misses += 1

    def record_error(self):
        self.errors += 1

    def record_latency(self, latency_ms):
        self.total_latency += latency_ms
        self.operations += 1

    def get_stats(self):
        hit_rate = (self.hits / (self.hits + self.misses) * 100) if (self.hits + self.misses) > 0 else 0
        avg_latency = (self.total_latency / self.operations) if self.operations > 0 else 0

        return {
            'hit_rate': f"{hit_rate:.2f}%",
            'total_hits': self.hits,
            'total_misses': self.misses,
            'total_errors': self.errors,
            'avg_latency_ms': f"{avg_latency:.2f}",
            'total_operations': self.operations
        }

metrics = RedisMetrics()

def measure_redis_operation(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            latency_ms = (time.time() - start_time) * 1000
            metrics.record_latency(latency_ms)

            # DÃ©tecter hit/miss selon le contexte
            if result is None:
                metrics.record_miss()
            else:
                metrics.record_hit()

            return result
        except Exception as e:
            metrics.record_error()
            raise e
    return wrapper

@measure_redis_operation
def get_from_cache(key):
    return r.get(key)

# Utilisation
value = get_from_cache('user:123')
print(metrics.get_stats())
# {'hit_rate': '75.00%', 'total_hits': 3, 'total_misses': 1, ...}
```

## Architecture de rÃ©fÃ©rence

### Application type avec patterns Redis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      CLIENT APPLICATIONS                    â”‚
â”‚         (Mobile Apps, Web Frontend, API Consumers)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      API GATEWAY / LB                       â”‚
â”‚                    (Rate Limiting Layer)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Service A  â”‚   â”‚   Service B  â”‚   â”‚   Service C  â”‚
â”‚              â”‚   â”‚              â”‚   â”‚              â”‚
â”‚ â€¢ Sessions   â”‚   â”‚ â€¢ Caching    â”‚   â”‚ â€¢ Job Queue  â”‚
â”‚ â€¢ User State â”‚   â”‚ â€¢ Query Cacheâ”‚   â”‚ â€¢ Tasks      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           REDIS LAYER               â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚                                     â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
        â”‚  â”‚   Master Node               â”‚    â”‚
        â”‚  â”‚   â€¢ All Write Operations    â”‚    â”‚
        â”‚  â”‚   â€¢ High Availability       â”‚    â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
        â”‚          â”‚           â”‚              â”‚
        â”‚          â†“           â†“              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
        â”‚  â”‚ Replica 1 â”‚ â”‚ Replica 2 â”‚        â”‚
        â”‚  â”‚ (Read)    â”‚ â”‚ (Read)    â”‚        â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
        â”‚                                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      PRIMARY DATA STORES              â”‚
        â”‚   (PostgreSQL, MongoDB, etc.)         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Patterns Coverage Matrix

Ce module couvre les patterns suivants avec leur complexitÃ© et cas d'usage :

| Pattern | ComplexitÃ© | Structures Redis | Cas d'usage principal |
|---------|-----------|------------------|----------------------|
| **Cache-Aside** | ğŸŸ¢ Facile | Strings | API responses, DB queries |
| **Write-Through** | ğŸŸ¡ Moyen | Strings, Hashes | Strong consistency |
| **Write-Back** | ğŸ”´ Difficile | Lists, Lua | Write-heavy workloads |
| **Anti-Avalanche** | ğŸŸ¡ Moyen | Strings, TTL | Cache warming, fallback |
| **Anti-Stampede** | ğŸ”´ Difficile | Locks, Lua | Cache regeneration |
| **Anti-Penetration** | ğŸŸ¡ Moyen | Bloom Filter | Invalid queries |
| **Pipelining** | ğŸŸ¢ Facile | All | Batch operations |
| **Client-Side Caching** | ğŸŸ¡ Moyen | RESP3 Protocol | Read-heavy apps |
| **Distributed Lock** | ğŸ”´ Difficile | Strings, Lua | Resource coordination |
| **Rate Limiting** | ğŸŸ¡ Moyen | Strings, Sorted Sets | API protection |
| **Session Store** | ğŸŸ¢ Facile | Hashes, Strings | User authentication |
| **Job Queue** | ğŸŸ¡ Moyen | Lists, Streams | Background processing |

## Exemple complet : Architecture multi-patterns

Voici une architecture rÃ©aliste combinant plusieurs patterns :

```python
import redis
import hashlib
import json
import time
from datetime import datetime, timedelta

class AdvancedRedisApp:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.metrics = RedisMetrics()

    # Pattern 1: Cache-Aside avec Anti-Penetration
    def get_user(self, user_id):
        """RÃ©cupÃ¨re un utilisateur avec cache et protection"""
        cache_key = f"user:{user_id}"
        bloom_key = "bloom:valid_users"

        # 1. VÃ©rifier le Bloom Filter (Anti-Penetration)
        if not self.redis.bf.exists(bloom_key, user_id):
            self.metrics.record_miss()
            return None  # User n'existe certainement pas

        # 2. Cache-Aside
        cached = self.redis.get(cache_key)
        if cached:
            self.metrics.record_hit()
            return json.loads(cached)

        # 3. Fallback vers DB (simulÃ©)
        user_data = self._fetch_from_db(user_id)

        if user_data:
            # Cacher pour 1 heure
            self.redis.setex(cache_key, 3600, json.dumps(user_data))
            self.metrics.record_miss()

        return user_data

    # Pattern 2: Rate Limiting (Sliding Window)
    def check_rate_limit(self, user_id, limit=100, window=60):
        """Rate limit avec fenÃªtre glissante"""
        key = f"ratelimit:{user_id}"
        now = time.time()

        # Pipeline pour atomicitÃ©
        pipe = self.redis.pipeline()

        # Supprimer les entrÃ©es expirÃ©es
        pipe.zremrangebyscore(key, 0, now - window)

        # Compter les requÃªtes dans la fenÃªtre
        pipe.zcard(key)

        # Ajouter la nouvelle requÃªte
        pipe.zadd(key, {str(now): now})

        # Expiration de la clÃ©
        pipe.expire(key, window)

        results = pipe.execute()
        request_count = results[1]

        return request_count < limit

    # Pattern 3: Distributed Lock
    def acquire_lock(self, resource, ttl=10):
        """Acquiert un lock distribuÃ©"""
        lock_key = f"lock:{resource}"
        identifier = str(time.time())

        # SET NX EX : atomique
        acquired = self.redis.set(
            lock_key,
            identifier,
            nx=True,  # Only if not exists
            ex=ttl    # Expiration
        )

        return identifier if acquired else None

    def release_lock(self, resource, identifier):
        """LibÃ¨re un lock de maniÃ¨re sÃ»re"""
        lock_key = f"lock:{resource}"

        # Script Lua pour garantir qu'on libÃ¨re notre propre lock
        lua_script = """
        if redis.call("GET", KEYS[1]) == ARGV[1] then
            return redis.call("DEL", KEYS[1])
        else
            return 0
        end
        """

        return self.redis.eval(lua_script, 1, lock_key, identifier)

    # Pattern 4: Session Store
    def create_session(self, user_id, session_data, ttl=3600):
        """CrÃ©e une session utilisateur"""
        session_id = hashlib.sha256(
            f"{user_id}:{time.time()}".encode()
        ).hexdigest()

        session_key = f"session:{session_id}"

        # Stocker avec TTL automatique
        session = {
            'user_id': user_id,
            'created_at': datetime.now().isoformat(),
            **session_data
        }

        self.redis.setex(
            session_key,
            ttl,
            json.dumps(session)
        )

        return session_id

    # Pattern 5: Job Queue
    def enqueue_job(self, queue_name, job_data, priority=0):
        """Ajoute un job Ã  la queue avec prioritÃ©"""
        job_id = hashlib.md5(
            f"{queue_name}:{time.time()}".encode()
        ).hexdigest()

        job = {
            'id': job_id,
            'data': job_data,
            'enqueued_at': time.time()
        }

        # Sorted Set pour prioritÃ©
        queue_key = f"queue:{queue_name}"
        self.redis.zadd(queue_key, {json.dumps(job): priority})

        return job_id

    def dequeue_job(self, queue_name, count=1):
        """RÃ©cupÃ¨re des jobs par ordre de prioritÃ©"""
        queue_key = f"queue:{queue_name}"

        # ZPOPMIN : atomique, retourne le score le plus bas
        jobs = self.redis.zpopmin(queue_key, count)

        return [json.loads(job[0]) for job in jobs]

    def _fetch_from_db(self, user_id):
        """Simule une requÃªte DB"""
        time.sleep(0.05)  # Simule latence DB
        return {'id': user_id, 'name': f'User {user_id}'}

# Utilisation
if __name__ == '__main__':
    r = redis.Redis(decode_responses=True)
    app = AdvancedRedisApp(r)

    # Test des patterns
    print("1. Cache-Aside:")
    user = app.get_user(123)
    print(f"   User: {user}")

    print("\n2. Rate Limiting:")
    for i in range(5):
        allowed = app.check_rate_limit('user_456', limit=3, window=10)
        print(f"   Request {i+1}: {'âœ“ Allowed' if allowed else 'âœ— Blocked'}")

    print("\n3. Distributed Lock:")
    lock_id = app.acquire_lock('critical_resource')
    if lock_id:
        print(f"   Lock acquired: {lock_id}")
        time.sleep(1)
        app.release_lock('critical_resource', lock_id)
        print("   Lock released")

    print("\n4. Session Management:")
    session_id = app.create_session('user_789', {'role': 'admin'})
    print(f"   Session created: {session_id}")

    print("\n5. Job Queue:")
    job_id = app.enqueue_job('email', {'to': 'user@example.com'}, priority=1)
    print(f"   Job enqueued: {job_id}")
    jobs = app.dequeue_job('email')
    print(f"   Jobs dequeued: {jobs}")
```

## Diagramme de dÃ©cision : Quel pattern utiliser ?

```
                    START: Besoin Redis
                            â”‚
                            â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Type de besoinâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“                   â†“
    [DonnÃ©es]          [ContrÃ´le]         [Communication]
        â”‚                   â”‚                   â”‚
        â†“                   â†“                   â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Caching?â”‚        â”‚Locking? â”‚        â”‚Messaging?â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚
        â†“                   â†“                   â†“
    [Read-Heavy?]     [Multi-Node?]      [Real-time?]
        â”‚                   â”‚                   â”‚
        â†“                   â†“                   â†“
    Yes â†’ Cache-Aside  Yes â†’ Redlock      Yes â†’ Pub/Sub
    No â†’ Write-Through No â†’ Local Lock    No â†’ Job Queue


    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     Questions Ã  se poser :               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                          â”‚
    â”‚ 1. Les donnÃ©es sont-elles lues souvent?  â”‚
    â”‚    â†’ Pattern de Caching                  â”‚
    â”‚                                          â”‚
    â”‚ 2. Y a-t-il un risque de surcharge?      â”‚
    â”‚    â†’ Pattern Anti-ProblÃ¨mes              â”‚
    â”‚                                          â”‚
    â”‚ 3. Besoin de coordination distribuÃ©e?    â”‚
    â”‚    â†’ Distributed Locking                 â”‚
    â”‚                                          â”‚
    â”‚ 4. Limiter les accÃ¨s par utilisateur?    â”‚
    â”‚    â†’ Rate Limiting                       â”‚
    â”‚                                          â”‚
    â”‚ 5. Traitement asynchrone nÃ©cessaire?     â”‚
    â”‚    â†’ Job Queue Pattern                   â”‚
    â”‚                                          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## PrÃ©requis pour ce module

Avant d'aborder les patterns avancÃ©s, assurez-vous de maÃ®triser :

### Connaissances techniques
- âœ… Structures de donnÃ©es Redis natives (Strings, Hashes, Lists, Sets, Sorted Sets)
- âœ… Commandes Redis de base (GET, SET, INCR, EXPIRE, etc.)
- âœ… Concepts de TTL et expiration
- âœ… Transactions MULTI/EXEC
- âœ… Scripting Lua basique

### Connaissances architecturales
- âœ… SystÃ¨mes distribuÃ©s et leurs challenges
- âœ… Race conditions et atomicitÃ©
- âœ… Patterns de cache traditionnels
- âœ… Concepts de haute disponibilitÃ©

### Outils
- âœ… Client Redis pour Python (`redis-py`) ou Node.js (`ioredis`)
- âœ… Redis CLI pour les tests
- âœ… Environnement de dÃ©veloppement local avec Redis

## Structure du module

Les sections suivantes approfondissent chaque famille de patterns :

1. **Caching Patterns** : StratÃ©gies pour optimiser les accÃ¨s aux donnÃ©es
2. **Resilience Patterns** : Protection contre les dÃ©faillances en cascade
3. **Performance Patterns** : Optimisation des performances et du dÃ©bit
4. **Synchronization Patterns** : Coordination dans les systÃ¨mes distribuÃ©s
5. **Rate Limiting Patterns** : Protection et fair-use des ressources
6. **State Management** : Gestion d'Ã©tat distribuÃ©
7. **Messaging Patterns** : Communication asynchrone entre services

Chaque section prÃ©sente :
- ğŸ“Š Les cas d'usage concrets
- ğŸ’» ImplÃ©mentations complÃ¨tes en Python et Node.js
- ğŸ¯ Les piÃ¨ges Ã  Ã©viter
- âš¡ Les optimisations possibles
- ğŸ“ˆ Les mÃ©triques Ã  surveiller

## Prochaine section

La section suivante explore en dÃ©tail les **Caching Patterns**, le fondement de l'utilisation de Redis dans la plupart des applications modernes.

---


â­ï¸ [Caching Patterns : Cache-Aside, Write-Through, Write-Back](/06-patterns-developpement-avances/01-caching-patterns.md)
