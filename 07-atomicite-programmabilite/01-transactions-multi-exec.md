ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 7.1 Transactions : MULTI/EXEC et pipeline transactionnel

## Introduction : Qu'est-ce qu'une transaction dans Redis ?

Les transactions Redis diffÃ¨rent fondamentalement des transactions ACID traditionnelles des bases de donnÃ©es relationnelles. Comprendre ces diffÃ©rences est crucial pour Ã©viter les erreurs conceptuelles qui peuvent mener Ã  des bugs de production subtils.

### Le modÃ¨le transactionnel de Redis

```redis
MULTI               # DÃ©but de la transaction
SET user:100:name "Alice"
INCR user:100:visits
LPUSH user:100:actions "login"
EXEC                # ExÃ©cution atomique
```

**Ce que Redis garantit** :
- âœ… **Isolation** : Les commandes sont mises en file d'attente et exÃ©cutÃ©es sÃ©quentiellement
- âœ… **AtomicitÃ© d'exÃ©cution** : Toutes les commandes s'exÃ©cutent d'un seul bloc
- âœ… **Ordre d'exÃ©cution** : Les commandes sont exÃ©cutÃ©es dans l'ordre exact

**Ce que Redis ne garantit PAS** :
- âŒ **Rollback automatique** : Si une commande Ã©choue, les prÃ©cÃ©dentes ne sont pas annulÃ©es
- âŒ **Isolation pendant la mise en file** : Entre MULTI et EXEC, d'autres clients peuvent modifier les donnÃ©es
- âŒ **VÃ©rifications de contraintes** : Pas de validation de cohÃ©rence avant exÃ©cution

### Comparaison avec les transactions SQL

| Aspect | Redis (MULTI/EXEC) | SQL (BEGIN/COMMIT) |
|--------|-------------------|-------------------|
| **Isolation** | âš ï¸ Partielle (uniquement pendant EXEC) | âœ… ComplÃ¨te (configurable) |
| **AtomicitÃ©** | âœ… ExÃ©cution groupÃ©e | âœ… Tout ou rien |
| **Rollback** | âŒ Non supportÃ© | âœ… ROLLBACK complet |
| **DurabilitÃ©** | âš ï¸ DÃ©pend de la config de persistance | âœ… Garantie aprÃ¨s COMMIT |
| **CohÃ©rence** | âŒ Pas de contraintes | âœ… Contraintes d'intÃ©gritÃ© |
| **Performance** | âœ… Ultra-rapide | âš ï¸ Overhead significatif |

## Fonctionnement interne de MULTI/EXEC

### Phase 1 : Mise en file d'attente (MULTI â†’ EXEC)

```redis
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> SET key1 "value1"
QUEUED
127.0.0.1:6379> INCR counter
QUEUED
127.0.0.1:6379> GET key1
QUEUED
```

**Que se passe-t-il en interne** :

1. **MULTI** : Redis crÃ©e une file d'attente temporaire pour cette connexion
2. **Commandes suivantes** : Chaque commande est validÃ©e syntaxiquement puis ajoutÃ©e Ã  la file
3. **RÃ©ponse immÃ©diate** : Le client reÃ§oit "QUEUED" sans exÃ©cution rÃ©elle
4. **Ã‰tat de la connexion** : MarquÃ©e comme "en transaction"

```
Ã‰tat mÃ©moire pendant MULTI:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client Connection Context      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ in_transaction: true         â”‚
â”‚  â€¢ command_queue: [             â”‚
â”‚      SET key1 "value1",         â”‚
â”‚      INCR counter,              â”‚
â”‚      GET key1                   â”‚
â”‚    ]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 2 : ExÃ©cution atomique (EXEC)

```redis
127.0.0.1:6379> EXEC
1) OK
2) (integer) 1
3) "value1"
```

**Processus d'exÃ©cution** :

1. **Verrouillage** : Redis empÃªche toute autre commande de s'intercaler
2. **ExÃ©cution sÃ©quentielle** : Chaque commande de la file est exÃ©cutÃ©e dans l'ordre
3. **Collecte des rÃ©sultats** : Les rÃ©sultats sont agrÃ©gÃ©s dans un tableau
4. **RÃ©ponse groupÃ©e** : Un seul aller-retour rÃ©seau pour tous les rÃ©sultats
5. **Nettoyage** : La file est vidÃ©e, la connexion repasse en mode normal

```
Timeline d'exÃ©cution:
Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
     â”‚
     â”‚ MULTI
     â”‚   â†“ (queue commands)
     â”‚ SET, INCR, GET
     â”‚   â†“
     â”‚ EXEC â”€â”€â”€â”€â”€â”
     â”‚           â”‚ [Atomic Block - No Interruption]
     â”‚           â”‚ â€¢ Execute SET
     â”‚           â”‚ â€¢ Execute INCR
     â”‚           â”‚ â€¢ Execute GET
     â”‚           â””â”€â”€â–º Return results array
     â”‚
```

## Exemple dÃ©taillÃ© : SystÃ¨me de transfert de points

Imaginons un systÃ¨me de gamification oÃ¹ les utilisateurs peuvent transfÃ©rer des points entre eux.

### Version sans transaction (VULNÃ‰RABLE)

```python
import redis

r = redis.Redis(decode_responses=True)

def transfer_points_unsafe(from_user, to_user, amount):
    """
    âŒ DANGEREUX : Race condition possible
    """
    # 1. VÃ©rifier le solde (lecture)
    from_balance = int(r.get(f"user:{from_user}:points") or 0)

    if from_balance < amount:
        return {"error": "Insufficient points"}

    # âš ï¸ DANGER : Entre cette vÃ©rification et les opÃ©rations suivantes,
    # un autre client peut modifier les soldes !

    # 2. DÃ©duire les points (Ã©criture)
    r.decrby(f"user:{from_user}:points", amount)

    # 3. Ajouter les points (Ã©criture)
    r.incrby(f"user:{to_user}:points", amount)

    return {"success": True}

# ScÃ©nario problÃ©matique :
# Thread A: transfer_points_unsafe("alice", "bob", 100)
#   â†’ lit balance=100, OK
# Thread B: transfer_points_unsafe("alice", "charlie", 100)
#   â†’ lit balance=100, OK (avant que A ne dÃ©duise)
# Thread A: dÃ©duit 100 â†’ balance=0
# Thread B: dÃ©duit 100 â†’ balance=-100 âŒ CORRUPTION !
```

### Version avec MULTI/EXEC (PARTIELLE)

```python
def transfer_points_with_transaction(from_user, to_user, amount):
    """
    âš ï¸ INCOMPLET : La transaction ne rÃ©sout pas tout
    """
    # VÃ©rification HORS transaction
    from_balance = int(r.get(f"user:{from_user}:points") or 0)

    if from_balance < amount:
        return {"error": "Insufficient points"}

    # âš ï¸ PROBLÃˆME : La vÃ©rification et la transaction sont sÃ©parÃ©es
    # La balance peut changer entre les deux !

    # Transaction pour les Ã©critures
    pipe = r.pipeline(transaction=True)
    pipe.decrby(f"user:{from_user}:points", amount)
    pipe.incrby(f"user:{to_user}:points", amount)

    # Enregistrement de la transaction
    tx_id = r.incr("transaction:counter")
    pipe.hset(f"transaction:{tx_id}", mapping={
        "from": from_user,
        "to": to_user,
        "amount": amount,
        "timestamp": int(time.time())
    })

    results = pipe.execute()
    return {"success": True, "transaction_id": tx_id}
```

**ProblÃ¨me identifiÃ©** : La vÃ©rification du solde est effectuÃ©e AVANT MULTI, crÃ©ant une fenÃªtre de vulnÃ©rabilitÃ©. La solution complÃ¨te nÃ©cessite WATCH (voir section 7.2).

### Transaction correcte avec logique simple

```python
def simple_transfer_with_transaction(from_user, to_user, amount):
    """
    âœ… CORRECT pour des transferts sans vÃ©rification prÃ©alable
    ou avec validation cÃ´tÃ© application
    """
    pipe = r.pipeline(transaction=True)

    # Toutes les commandes sont atomiques
    pipe.decrby(f"user:{from_user}:points", amount)
    pipe.incrby(f"user:{to_user}:points", amount)

    # Log de l'opÃ©ration
    tx_id = r.incr("transaction:counter")
    pipe.hset(f"transaction:{tx_id}", mapping={
        "from": from_user,
        "to": to_user,
        "amount": amount,
        "timestamp": int(time.time()),
        "status": "completed"
    })
    pipe.expire(f"transaction:{tx_id}", 86400)  # Expire aprÃ¨s 24h

    try:
        results = pipe.execute()
        return {
            "success": True,
            "transaction_id": tx_id,
            "from_new_balance": results[0],
            "to_new_balance": results[1]
        }
    except redis.RedisError as e:
        return {"error": str(e)}
```

## Anatomie d'une transaction Redis en Node.js

```javascript
const Redis = require('ioredis');
const redis = new Redis();

/**
 * Enregistrement d'une commande e-commerce
 * DÃ©montre l'utilisation de MULTI/EXEC avec gestion d'erreur
 */
async function createOrder(userId, productId, quantity, price) {
    const orderId = await redis.incr('order:counter');
    const timestamp = Date.now();

    // CrÃ©ation du pipeline transactionnel
    const pipeline = redis.multi();

    // 1. CrÃ©er l'objet commande
    pipeline.hset(`order:${orderId}`, {
        user_id: userId,
        product_id: productId,
        quantity: quantity,
        price: price,
        total: price * quantity,
        status: 'pending',
        created_at: timestamp
    });

    // 2. Ajouter Ã  l'index des commandes de l'utilisateur
    pipeline.zadd(`user:${userId}:orders`, timestamp, orderId);

    // 3. Ajouter Ã  l'index global des commandes en attente
    pipeline.zadd('orders:pending', timestamp, orderId);

    // 4. Mettre Ã  jour les statistiques
    pipeline.hincrby('stats:daily', 'total_orders', 1);
    pipeline.hincrbyfloat('stats:daily', 'total_revenue', price * quantity);

    // 5. DÃ©crÃ©menter le stock (sans vÃ©rification dans cette version simple)
    pipeline.decrby(`product:${productId}:stock`, quantity);

    try {
        // ExÃ©cution atomique de toutes les commandes
        const results = await pipeline.exec();

        // VÃ©rification des rÃ©sultats (ioredis retourne [error, result] pour chaque commande)
        const errors = results.filter(([err]) => err !== null);
        if (errors.length > 0) {
            console.error('Transaction had errors:', errors);
            return { success: false, errors };
        }

        return {
            success: true,
            orderId,
            message: 'Order created successfully'
        };

    } catch (error) {
        console.error('Transaction failed:', error);
        return { success: false, error: error.message };
    }
}

// Utilisation
createOrder(1001, 5042, 2, 29.99)
    .then(result => console.log(result));
```

### Analyse dÃ©taillÃ©e du code

**Points clÃ©s** :

1. **Pipeline vs Transaction** :
```javascript
// Pipeline simple (pas de transaction)
const pipeline = redis.pipeline();

// Pipeline transactionnel (avec MULTI/EXEC)
const pipeline = redis.multi();
```

2. **Gestion des rÃ©sultats** :
```javascript
// ioredis retourne un tableau de [error, result]
const results = await pipeline.exec();
// results = [
//   [null, 'OK'],              // HSET rÃ©ussi
//   [null, 1],                 // ZADD rÃ©ussi
//   [null, 1],                 // ZADD rÃ©ussi
//   [null, 1],                 // HINCRBY rÃ©ussi
//   [null, '59.98'],           // HINCRBYFLOAT rÃ©ussi
//   [Error('...'), undefined]  // DECRBY Ã©chouÃ© (si erreur)
// ]
```

3. **Pas de rollback automatique** :
Si `DECRBY` Ã©choue (par exemple, stock devient nÃ©gatif), les commandes prÃ©cÃ©dentes restent appliquÃ©es. C'est une limitation fondamentale de Redis.

## Pipeline vs Transaction : Clarification

### Pipeline simple (sans MULTI/EXEC)

```python
# Pipeline NON transactionnel
pipe = r.pipeline(transaction=False)
pipe.get("key1")
pipe.set("key2", "value2")
pipe.incr("counter")
results = pipe.execute()

# âš ï¸ D'autres clients peuvent s'intercaler entre les commandes !
```

**CaractÃ©ristiques** :
- Optimisation rÃ©seau : Toutes les commandes envoyÃ©es en un seul bloc
- RÃ©ponses groupÃ©es : Un seul aller-retour pour tous les rÃ©sultats
- **Pas d'atomicitÃ©** : D'autres commandes peuvent s'exÃ©cuter entre les vÃ´tres
- Usage : Quand vous voulez juste optimiser le rÃ©seau, pas garantir l'atomicitÃ©

### Pipeline transactionnel (avec MULTI/EXEC)

```python
# Pipeline transactionnel
pipe = r.pipeline(transaction=True)  # ou juste r.pipeline() (dÃ©faut)
pipe.get("key1")
pipe.set("key2", "value2")
pipe.incr("counter")
results = pipe.execute()

# âœ… ExÃ©cution atomique garantie
```

**CaractÃ©ristiques** :
- Tout ce qu'offre le pipeline simple
- **Plus** : AtomicitÃ© d'exÃ©cution (MULTI/EXEC automatique)
- Usage : Quand vous avez besoin d'atomicitÃ© ET d'optimisation rÃ©seau

### Comparaison visuelle

```
Pipeline simple (transaction=False):
Client â†’ Redis: GET key1
                â†“ Execute immediately
Client â† Redis: "value1"
                [Other clients can execute commands here]
Client â†’ Redis: SET key2 "value2"
                â†“ Execute immediately
Client â† Redis: OK
                [Other clients can execute commands here]
Client â†’ Redis: INCR counter
                â†“ Execute immediately
Client â† Redis: (integer) 5

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Pipeline transactionnel (transaction=True):
Client â†’ Redis: MULTI
Client â†’ Redis: GET key1
Client â†’ Redis: SET key2 "value2"
Client â†’ Redis: INCR counter
Client â†’ Redis: EXEC
                â†“ Execute ALL atomically
                [No other commands can interrupt]
Client â† Redis: [
                  "value1",
                  OK,
                  (integer) 5
                ]
```

## Gestion des erreurs dans les transactions

### Types d'erreurs

Redis distingue deux types d'erreurs dans les transactions :

#### 1. Erreurs de syntaxe (avant EXEC)

```redis
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> SET key value
QUEUED
127.0.0.1:6379> INVALID_COMMAND
(error) ERR unknown command 'INVALID_COMMAND'
127.0.0.1:6379> INCR counter
QUEUED
127.0.0.1:6379> EXEC
(error) EXECABORT Transaction discarded because of previous errors.
```

**Comportement** :
- La transaction est complÃ¨tement abandonnÃ©e
- Aucune commande n'est exÃ©cutÃ©e
- Redis dÃ©tecte l'erreur immÃ©diatement

#### 2. Erreurs d'exÃ©cution (pendant EXEC)

```redis
127.0.0.1:6379> SET mykey "string_value"
OK
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> SET key1 "value1"
QUEUED
127.0.0.1:6379> INCR mykey
QUEUED  # Syntaxe valide, mais mykey n'est pas un nombre
127.0.0.1:6379> SET key2 "value2"
QUEUED
127.0.0.1:6379> EXEC
1) OK
2) (error) ERR value is not an integer or out of range
3) OK
```

**Comportement CRITIQUE** :
- âš ï¸ Les commandes avant l'erreur **SONT APPLIQUÃ‰ES**
- âš ï¸ Les commandes aprÃ¨s l'erreur **SONT AUSSI APPLIQUÃ‰ES**
- âš ï¸ **Pas de rollback automatique**

### Pattern de gestion des erreurs en Python

```python
def transaction_with_error_handling(r: redis.Redis):
    """
    DÃ©montre la gestion robuste des erreurs dans une transaction
    """
    pipe = r.pipeline(transaction=True)

    try:
        # Phase 1 : Mise en file d'attente
        pipe.set("user:1000:name", "Alice")
        pipe.incrby("user:1000:score", 10)
        pipe.lpush("user:1000:actions", "achievement_unlocked")

        # Phase 2 : ExÃ©cution
        results = pipe.execute()

        # Phase 3 : Validation des rÃ©sultats
        if not all(results):
            # Certaines commandes ont Ã©chouÃ©, mais dÃ©jÃ  appliquÃ©es !
            log_transaction_warning({
                'message': 'Partial transaction success',
                'results': results
            })
            # Compensation manuelle si nÃ©cessaire
            compensate_partial_transaction()

        return {"success": True, "results": results}

    except redis.exceptions.ResponseError as e:
        # Erreur de syntaxe dÃ©tectÃ©e avant EXEC
        log_error(f"Transaction aborted: {e}")
        return {"success": False, "error": "syntax_error"}

    except redis.exceptions.ConnectionError as e:
        # ProblÃ¨me rÃ©seau
        log_error(f"Connection error: {e}")
        return {"success": False, "error": "connection_error"}

    except Exception as e:
        # Autres erreurs
        log_error(f"Unexpected error: {e}")
        return {"success": False, "error": "unknown_error"}

def compensate_partial_transaction():
    """
    Logique de compensation manuelle en cas d'Ã©chec partiel
    """
    # Exemple : Enregistrer dans une queue pour traitement ultÃ©rieur
    r.lpush("failed_transactions", json.dumps({
        "timestamp": time.time(),
        "operation": "user_achievement",
        "status": "requires_manual_review"
    }))
```

## Cas d'usage optimaux pour MULTI/EXEC

### âœ… Cas 1 : Mise Ã  jour cohÃ©rente de plusieurs structures

```python
def update_user_profile(user_id: str, profile_data: dict):
    """
    Mise Ã  jour atomique d'un profil utilisateur rÃ©parti sur plusieurs structures
    """
    pipe = r.pipeline(transaction=True)

    # 1. Hash principal du profil
    pipe.hset(f"user:{user_id}:profile", mapping={
        "name": profile_data["name"],
        "email": profile_data["email"],
        "updated_at": int(time.time())
    })

    # 2. Index de recherche par email
    old_email = r.hget(f"user:{user_id}:profile", "email")
    if old_email and old_email != profile_data["email"]:
        pipe.srem("index:emails", old_email)
    pipe.sadd("index:emails", profile_data["email"])

    # 3. Statistiques de mise Ã  jour
    pipe.hincrby("stats:profile_updates", "total", 1)
    pipe.hincrby("stats:profile_updates", f"user:{user_id}", 1)

    # 4. Log d'audit
    pipe.zadd("audit:profile_updates", {
        f"{user_id}:{int(time.time())}": int(time.time())
    })

    pipe.execute()
```

### âœ… Cas 2 : IncrÃ©ments multiples atomiques

```python
def record_page_view(page_id: str, user_id: str, session_id: str):
    """
    Enregistrement atomique d'une vue de page dans plusieurs compteurs
    """
    timestamp = int(time.time())

    pipe = r.pipeline(transaction=True)

    # Compteurs globaux
    pipe.incr(f"page:{page_id}:views:total")
    pipe.incr(f"page:{page_id}:views:today:{time.strftime('%Y-%m-%d')}")
    pipe.incr(f"user:{user_id}:views:total")

    # HyperLogLog pour visiteurs uniques
    pipe.pfadd(f"page:{page_id}:unique_visitors", user_id)
    pipe.pfadd(f"page:{page_id}:unique_visitors:today", user_id)

    # Timeline de vues
    pipe.zadd(f"page:{page_id}:views:timeline", {session_id: timestamp})

    # Top pages de l'utilisateur
    pipe.zincrby(f"user:{user_id}:top_pages", 1, page_id)

    results = pipe.execute()

    return {
        "total_views": results[0],
        "views_today": results[1],
        "unique_visitors": results[3]
    }
```

### âœ… Cas 3 : OpÃ©rations de nettoyage groupÃ©es

```python
def cleanup_expired_sessions(max_age_seconds: int = 3600):
    """
    Nettoyage atomique des sessions expirÃ©es
    """
    current_time = int(time.time())
    cutoff_time = current_time - max_age_seconds

    # Trouver les sessions expirÃ©es
    expired = r.zrangebyscore("sessions:active", 0, cutoff_time)

    if not expired:
        return {"cleaned": 0}

    pipe = r.pipeline(transaction=True)

    for session_id in expired:
        # Supprimer la session
        pipe.delete(f"session:{session_id}")

        # Retirer de l'index actif
        pipe.zrem("sessions:active", session_id)

        # Ajouter Ã  l'index des sessions expirÃ©es (pour analyse)
        pipe.zadd("sessions:expired", {session_id: current_time})

    # Statistiques
    pipe.hincrby("stats:cleanup", "sessions_cleaned", len(expired))
    pipe.hset("stats:cleanup", "last_cleanup", current_time)

    pipe.execute()

    return {"cleaned": len(expired), "timestamp": current_time}
```

## âŒ Anti-patterns : Quand NE PAS utiliser MULTI/EXEC

### Anti-pattern 1 : Logique conditionnelle dans la transaction

```python
# âŒ NE FONCTIONNE PAS : Les conditions ne peuvent pas utiliser les rÃ©sultats
def bad_conditional_transaction(user_id: str):
    pipe = r.pipeline(transaction=True)

    pipe.get(f"user:{user_id}:balance")
    # âš ï¸ PROBLÃˆME : On ne peut pas lire le rÃ©sultat avant EXEC !

    # Cette condition ne fonctionnera PAS comme attendu
    # if balance > 100:  # On n'a pas encore le rÃ©sultat !
    #     pipe.decrby(f"user:{user_id}:balance", 50)

    pipe.execute()
    # Les rÃ©sultats ne sont disponibles qu'ici

# âœ… SOLUTION : Utiliser WATCH (voir section 7.2) ou Lua (section 7.3)
```

### Anti-pattern 2 : Transactions trop longues

```python
# âŒ MAUVAIS : Trop de commandes dans une transaction
def bad_bulk_operation():
    pipe = r.pipeline(transaction=True)

    # Danger : 10,000 commandes dans une seule transaction
    for i in range(10000):
        pipe.set(f"key:{i}", f"value:{i}")

    # âš ï¸ Bloque Redis pendant toute l'exÃ©cution
    # âš ï¸ Consomme beaucoup de mÃ©moire pour la file d'attente
    # âš ï¸ Augmente la latence pour tous les autres clients
    pipe.execute()

# âœ… MEILLEUR : Diviser en petits lots
def good_bulk_operation(batch_size: int = 1000):
    keys_values = [(f"key:{i}", f"value:{i}") for i in range(10000)]

    for i in range(0, len(keys_values), batch_size):
        batch = keys_values[i:i + batch_size]
        pipe = r.pipeline(transaction=True)

        for key, value in batch:
            pipe.set(key, value)

        pipe.execute()
        time.sleep(0.01)  # Pause entre les lots pour ne pas monopoliser Redis
```

### Anti-pattern 3 : Utiliser MULTI/EXEC pour une seule commande

```python
# âŒ INUTILE : Overhead sans bÃ©nÃ©fice
def bad_single_command():
    pipe = r.pipeline(transaction=True)
    pipe.incr("counter")
    result = pipe.execute()
    return result[0]

# âœ… BON : Commande directe (dÃ©jÃ  atomique)
def good_single_command():
    return r.incr("counter")
```

## Performance et optimisations

### Benchmark : Impact du pipelining

```python
import time
import redis

r = redis.Redis()

# Test 1 : Commandes individuelles
start = time.time()
for i in range(1000):
    r.set(f"key:{i}", f"value:{i}")
time_individual = time.time() - start

# Test 2 : Pipeline simple
start = time.time()
pipe = r.pipeline(transaction=False)
for i in range(1000):
    pipe.set(f"key:{i}", f"value:{i}")
pipe.execute()
time_pipeline = time.time() - start

# Test 3 : Transaction (MULTI/EXEC)
start = time.time()
pipe = r.pipeline(transaction=True)
for i in range(1000):
    pipe.set(f"key:{i}", f"value:{i}")
pipe.execute()
time_transaction = time.time() - start

print(f"Individuel    : {time_individual:.3f}s")
print(f"Pipeline      : {time_pipeline:.3f}s ({time_individual/time_pipeline:.1f}x plus rapide)")
print(f"Transaction   : {time_transaction:.3f}s ({time_individual/time_transaction:.1f}x plus rapide)")

# RÃ©sultats typiques (localhost) :
# Individuel    : 0.523s
# Pipeline      : 0.018s (29.1x plus rapide)
# Transaction   : 0.019s (27.5x plus rapide)
```

**Analyse** :
- Le pipeline Ã©limine la latence rÃ©seau (RTT) entre les commandes
- La diffÃ©rence entre pipeline et transaction est minime (overhead de MULTI/EXEC nÃ©gligeable)
- Sur un rÃ©seau distant (RTT Ã©levÃ©), le gain est encore plus spectaculaire

### Optimisation : Taille des lots (batch size)

```python
def optimal_batch_size_finder(total_operations: int):
    """
    Trouve la taille de lot optimale pour votre environnement
    """
    batch_sizes = [100, 500, 1000, 2000, 5000]
    results = {}

    for batch_size in batch_sizes:
        start = time.time()

        for i in range(0, total_operations, batch_size):
            pipe = r.pipeline(transaction=True)

            for j in range(min(batch_size, total_operations - i)):
                pipe.set(f"test:key:{i+j}", f"value:{i+j}")

            pipe.execute()

        duration = time.time() - start
        results[batch_size] = duration
        print(f"Batch size {batch_size:5d}: {duration:.3f}s")

    # Nettoyage
    r.flushdb()

    return results

# Utilisation
optimal_batch_size_finder(10000)

# RÃ©sultats typiques :
# Batch size   100: 0.892s
# Batch size   500: 0.234s  â† Bon compromis
# Batch size  1000: 0.189s  â† Meilleure performance
# Batch size  2000: 0.198s
# Batch size  5000: 0.312s  (trop grand, overhead mÃ©moire)
```

**Recommandation** :
- Pour la plupart des cas : **500-1000 commandes** par transaction
- OpÃ©rations complexes : **100-500**
- OpÃ©rations simples : **1000-2000**

## Transactions imbriquÃ©es et comportement spÃ©cial

### Transactions ne peuvent PAS Ãªtre imbriquÃ©es

```redis
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> SET key1 "value1"
QUEUED
127.0.0.1:6379> MULTI
(error) ERR MULTI calls can not be nested
```

**Explication** : Redis ne supporte pas les transactions imbriquÃ©es. Si vous avez besoin de logique complexe, utilisez Lua ou Redis Functions.

### Annulation d'une transaction avec DISCARD

```redis
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> SET key1 "value1"
QUEUED
127.0.0.1:6379> INCR counter
QUEUED
127.0.0.1:6379> DISCARD
OK
127.0.0.1:6379> GET key1
(nil)  # Rien n'a Ã©tÃ© exÃ©cutÃ©
```

**Usage en Python** :

```python
def transaction_with_validation(user_id: str, amount: int):
    """
    Transaction avec validation et possibilitÃ© d'annulation
    """
    pipe = r.pipeline(transaction=True)

    try:
        # Validation mÃ©tier
        current_balance = int(r.get(f"user:{user_id}:balance") or 0)
        if current_balance < amount:
            # Annuler la transaction (si elle Ã©tait dÃ©marrÃ©e)
            pipe.reset()  # Ã‰quivalent de DISCARD
            return {"error": "Insufficient funds"}

        # Transaction valide
        pipe.decrby(f"user:{user_id}:balance", amount)
        pipe.lpush(f"user:{user_id}:transactions", json.dumps({
            "amount": -amount,
            "timestamp": time.time()
        }))

        results = pipe.execute()
        return {"success": True, "new_balance": results[0]}

    except Exception as e:
        pipe.reset()  # Annulation en cas d'erreur
        raise
```

## Comparaison avec les alternatives

### MULTI/EXEC vs WATCH (Optimistic Locking)

```python
# MULTI/EXEC : Pas de vÃ©rification d'Ã©tat
def multi_exec_approach(user_id: str, amount: int):
    pipe = r.pipeline(transaction=True)
    pipe.decrby(f"user:{user_id}:balance", amount)
    pipe.execute()
    # âš ï¸ Pas de vÃ©rification si le solde est suffisant

# WATCH : VÃ©rification d'Ã©tat avec retry
def watch_approach(user_id: str, amount: int):
    with r.pipeline() as pipe:
        while True:
            try:
                pipe.watch(f"user:{user_id}:balance")
                balance = int(pipe.get(f"user:{user_id}:balance") or 0)

                if balance < amount:
                    pipe.unwatch()
                    return {"error": "Insufficient funds"}

                pipe.multi()
                pipe.decrby(f"user:{user_id}:balance", amount)
                pipe.execute()
                return {"success": True}

            except redis.WatchError:
                # Retry si la valeur a changÃ©
                continue
```

**Quand utiliser quoi** :
- **MULTI/EXEC** : OpÃ©rations simples sans conditions
- **WATCH** : OpÃ©rations conditionnelles, conflicts rares
- **Lua/Functions** : Logique complexe, conflicts frÃ©quents

### MULTI/EXEC vs Lua Script

```python
# MULTI/EXEC : LimitÃ© Ã  des sÃ©quences linÃ©aires
def multi_exec_limited():
    pipe = r.pipeline(transaction=True)
    pipe.get("key1")
    # âŒ On ne peut pas utiliser le rÃ©sultat dans la transaction
    pipe.set("key2", "fixed_value")
    pipe.execute()

# Lua : Logique complÃ¨te sur le serveur
lua_script = """
local value = redis.call('GET', KEYS[1])
if tonumber(value) > 10 then
    redis.call('SET', KEYS[2], 'high')
else
    redis.call('SET', KEYS[2], 'low')
end
return value
"""

result = r.eval(lua_script, 2, "key1", "key2")
```

## Debugging et monitoring des transactions

### Suivre les transactions en temps rÃ©el

```bash
# Monitorer toutes les commandes
redis-cli MONITOR

# Filtrer uniquement les transactions
redis-cli MONITOR | grep -E "MULTI|EXEC|DISCARD"
```

### Analyser les transactions lentes

```bash
# Voir les commandes lentes (inclut les transactions)
redis-cli SLOWLOG GET 10

# Configuration du seuil de slowlog (microsecondes)
redis-cli CONFIG SET slowlog-log-slower-than 10000  # 10ms
```

### MÃ©triques importantes

```python
def get_transaction_metrics(r: redis.Redis):
    """
    Collecte des mÃ©triques sur les transactions
    """
    info = r.info('stats')

    return {
        "total_commands": info['total_commands_processed'],
        "instantaneous_ops": info['instantaneous_ops_per_sec'],
        "rejected_connections": info['rejected_connections'],
        "sync_full": info.get('sync_full', 0),
        "sync_partial_ok": info.get('sync_partial_ok', 0)
    }
```

## RÃ©sumÃ© et bonnes pratiques

### âœ… Ã€ FAIRE

1. **Utiliser les transactions pour garantir l'atomicitÃ©** de sÃ©quences d'opÃ©rations liÃ©es
2. **Grouper les opÃ©rations** pour rÃ©duire la latence rÃ©seau
3. **Limiter la taille** des transactions (500-1000 commandes max)
4. **GÃ©rer les erreurs** explicitement et prÃ©voir la compensation
5. **Tester les cas limites** : erreurs, timeouts, failures partielles
6. **Monitorer les performances** avec SLOWLOG et mÃ©triques

### âŒ Ã€ Ã‰VITER

1. **Ne pas utiliser pour la logique conditionnelle** (prÃ©fÃ©rer WATCH ou Lua)
2. **Ne pas crÃ©er de transactions gÃ©antes** (milliers de commandes)
3. **Ne pas compter sur le rollback automatique** (n'existe pas)
4. **Ne pas imbriquer les MULTI** (non supportÃ©)
5. **Ne pas utiliser pour une seule commande** (overhead inutile)

### Checklist de dÃ©cision

```
Ai-je besoin d'atomicitÃ© ?
â”œâ”€ Non â†’ Commandes individuelles ou pipeline simple
â””â”€ Oui â†’ Continuer â†“

Ai-je besoin de logique conditionnelle ?
â”œâ”€ Oui â†’ Utiliser WATCH ou Lua/Functions
â””â”€ Non â†’ Continuer â†“

Les opÃ©rations sont-elles nombreuses (>1000) ?
â”œâ”€ Oui â†’ Diviser en lots + considÃ©rer Lua
â””â”€ Non â†’ Continuer â†“

                â†’ Utiliser MULTI/EXEC âœ…
```

## Conclusion

Les transactions MULTI/EXEC sont un outil puissant mais spÃ©cialisÃ© dans l'arsenal Redis. Elles excellent dans des scÃ©narios spÃ©cifiques :
- Mise Ã  jour cohÃ©rente de structures multiples
- Optimisation rÃ©seau via pipelining
- OpÃ©rations groupÃ©es sans logique conditionnelle

Cependant, elles ont des limitations importantes :
- Pas de rollback automatique
- Pas de logique conditionnelle pendant la transaction
- Ne conviennent pas aux opÃ©rations trÃ¨s longues

Pour des besoins plus complexes, les sections suivantes exploreront WATCH pour l'optimistic locking et Lua/Functions pour la logique mÃ©tier avancÃ©e.

---

**ğŸ“š Points clÃ©s Ã  retenir** :
- MULTI/EXEC garantit l'**atomicitÃ© d'exÃ©cution** mais **pas le rollback**
- Les erreurs d'exÃ©cution n'annulent **pas** les commandes prÃ©cÃ©dentes
- Pipeline transactionnel = optimisation rÃ©seau + atomicitÃ©
- Limiter les transactions Ã  500-1000 commandes pour des performances optimales
- Pour la logique conditionnelle, utiliser WATCH (section 7.2) ou Lua (section 7.3)

**ğŸ”œ Prochaine section** : [7.2 Optimistic Locking avec WATCH](./02-optimistic-locking-watch.md)

â­ï¸ [Optimistic Locking avec WATCH](/07-atomicite-programmabilite/02-optimistic-locking-watch.md)
