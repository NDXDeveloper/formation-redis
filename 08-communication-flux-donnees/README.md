üîù Retour au [Sommaire](/SOMMAIRE.md)

# Module 8 : Communication et Flux de Donn√©es

## Introduction au module

La communication asynchrone et le traitement de flux de donn√©es sont devenus des composants essentiels des architectures modernes distribu√©es. Redis offre plusieurs m√©canismes de messaging, chacun avec ses propres caract√©ristiques, garanties et cas d'usage optimaux.

Ce module explore en profondeur les trois principaux m√©canismes de communication dans Redis :
- **Pub/Sub** : Communication en temps r√©el avec mod√®le publisher-subscriber
- **Redis Streams** : Flux de donn√©es persistants avec consumer groups
- **Lists** : Files d'attente simples pour patterns producteur-consommateur

---

## Vue d'ensemble des m√©canismes de messaging

### Les trois paradigmes de Redis

Redis propose trois approches distinctes pour la communication inter-processus et le traitement de flux :

| M√©canisme | Paradigme | Persistance | Complexit√© | Cas d'usage principal |
|-----------|-----------|-------------|------------|----------------------|
| **Pub/Sub** | Fire-and-forget | ‚ùå Non | Faible | Notifications temps r√©el |
| **Streams** | Event sourcing | ‚úÖ Oui | Moyenne | Traitement fiable de flux |
| **Lists** | FIFO/LIFO Queue | ‚úÖ Oui | Faible | Job queues simples |

### Matrice d√©cisionnelle rapide

```
Besoin de garantie de livraison ?
    ‚îú‚îÄ NON ‚Üí Pub/Sub (performance maximale)
    ‚îî‚îÄ OUI ‚Üí
        ‚îú‚îÄ Traitement parall√®le avec consumer groups ?
        ‚îÇ   ‚îî‚îÄ OUI ‚Üí Redis Streams
        ‚îî‚îÄ NON ‚Üí
            ‚îî‚îÄ File d'attente simple ?
                ‚îî‚îÄ OUI ‚Üí Lists (LPUSH/BRPOP)
```

---

## Pub/Sub vs Streams : Comparaison d√©taill√©e

### 1. Garanties de livraison

#### Pub/Sub : "Fire and Forget"

```bash
# Publisher
PUBLISH notifications:users "User 123 logged in"
# Retourne : (integer) 2  # Nombre de subscribers actifs

# Subscriber (doit √™tre connect√© AVANT la publication)
SUBSCRIBE notifications:users
# Si d√©connect√© ‚Üí message perdu d√©finitivement
```

**Caract√©ristiques** :
- ‚ùå Aucune persistance
- ‚ùå Les messages non livr√©s sont perdus
- ‚úÖ Latence ultra-faible (microseconds)
- ‚úÖ Id√©al pour √©v√©nements non critiques

#### Streams : Persistance et rejouabilit√©

```bash
# Producer
XADD events:login * user_id 123 timestamp 1702234567
# Retourne : "1702234567000-0"  # ID du message stock√©

# Consumer - peut lire depuis le d√©but
XREAD COUNT 10 STREAMS events:login 0-0
# Messages persist√©s jusqu'√† suppression explicite
```

**Caract√©ristiques** :
- ‚úÖ Persistance compl√®te (RDB/AOF)
- ‚úÖ Rejouabilit√© illimit√©e
- ‚úÖ Lecture depuis n'importe quel point
- ‚ö†Ô∏è Latence l√©g√®rement sup√©rieure (millisecondes)

---

### 2. Mod√®le de consommation

#### Pub/Sub : Broadcast simple

```bash
# Sc√©nario : Notification temps r√©el √† plusieurs services

# Publisher
PUBLISH user:events '{"type":"login","user_id":123}'

# Subscriber 1 (Service Analytics)
SUBSCRIBE user:events
# Re√ßoit le message

# Subscriber 2 (Service Notifications)
SUBSCRIBE user:events
# Re√ßoit le M√äME message simultan√©ment

# Subscriber 3 (connect√© 1 seconde trop tard)
SUBSCRIBE user:events
# Ne recevra PAS les messages pr√©c√©dents
```

**Cas d'usage Pub/Sub** :
- Dashboard temps r√©el (WebSockets)
- Invalidation de cache distribu√©e
- Notifications push
- Live chat/messaging

#### Streams : Consumer Groups avec ACK

```bash
# Cr√©ation du consumer group
XGROUP CREATE orders:stream payment-processor $ MKSTREAM

# Consumer 1 dans le groupe
XREADGROUP GROUP payment-processor consumer-1 COUNT 1 STREAMS orders:stream >
# Re√ßoit : 1) ordre ID 1702234567000-0

# Consumer 2 dans le m√™me groupe
XREADGROUP GROUP payment-processor consumer-2 COUNT 1 STREAMS orders:stream >
# Re√ßoit : 2) ordre ID 1702234568000-0  (diff√©rent de consumer-1)

# Acknowledgement apr√®s traitement
XACK orders:stream payment-processor 1702234567000-0

# En cas d'√©chec, message r√©attribu√© automatiquement
XPENDING orders:stream payment-processor  # Voir messages non-ACK√©s
```

**Cas d'usage Streams** :
- Pipeline de traitement de donn√©es
- Event sourcing
- Syst√®mes de facturation/paiement
- Audit trail avec rejouabilit√©

---

### 3. Scalabilit√© horizontale

#### Pub/Sub : Scalabilit√© limit√©e

```python
# Probl√®me : Tous les subscribers re√ßoivent TOUS les messages
import redis

# 10 workers qui √©coutent le m√™me channel
for i in range(10):
    worker = redis.Redis()
    pubsub = worker.pubsub()
    pubsub.subscribe('tasks')
    # Probl√®me : Les 10 workers recevront chaque message
    # ‚Üí Travail dupliqu√© 10 fois !
```

**Solution Pub/Sub pour load balancing** :
```python
# Pattern Sharded Pub/Sub (Redis 7+)
# Distribue automatiquement entre subscribers

# Publisher
redis.spublish('tasks:{shard}', task_data)

# Les subscribers sont automatiquement r√©partis
pubsub.ssubscribe('tasks:{shard}')
```

#### Streams : Load balancing natif

```python
import redis

# Consumer Group : chaque message trait√© par UN SEUL consumer
r = redis.Redis()

# Worker 1
while True:
    messages = r.xreadgroup(
        groupname='workers',
        consumername='worker-1',
        streams={'tasks': '>'},
        count=10,
        block=5000
    )
    for message in messages:
        process(message)
        r.xack('tasks', 'workers', message[0])

# Worker 2, 3, 4... traiteront des messages DIFF√âRENTS
# ‚Üí Distribution automatique de la charge
```

---

### 4. Gestion des erreurs et retry

#### Pub/Sub : Aucune gestion native

```python
# Pub/Sub : Si le traitement √©choue, le message est perdu
pubsub = redis.pubsub()
pubsub.subscribe('tasks')

for message in pubsub.listen():
    try:
        process(message['data'])
    except Exception as e:
        # ‚ùå Impossible de rejouer le message
        # ‚ùå Doit impl√©menter sa propre logique de retry
        logger.error(f"Message perdu : {e}")
```

#### Streams : Retry et Dead Letter Queue

```python
import redis
from datetime import datetime, timedelta

r = redis.Redis()

# 1. Traitement avec retry automatique
def process_with_retry(stream_name, group_name, consumer_name):
    while True:
        # Lire nouveaux messages
        messages = r.xreadgroup(group_name, consumer_name, {stream_name: '>'}, count=10)

        for message in messages:
            msg_id, data = message[1][0]
            try:
                process(data)
                r.xack(stream_name, group_name, msg_id)
            except Exception as e:
                # Ne pas ACK ‚Üí sera retrait√©
                logger.error(f"Erreur: {e}, message sera retry√©")

        # 2. R√©cup√©rer les messages en timeout (non-ACK√©s > 5 min)
        pending = r.xpending_range(
            stream_name,
            group_name,
            '-', '+',
            count=100
        )

        now = datetime.now()
        for entry in pending:
            # entry: [msg_id, consumer, idle_time, delivery_count]
            if entry['time_since_delivered'] > 300000:  # 5 minutes
                # Claim le message pour le retraiter
                r.xclaim(
                    stream_name,
                    group_name,
                    consumer_name,
                    min_idle_time=300000,
                    message_ids=[entry['message_id']]
                )

# 3. Dead Letter Queue apr√®s N tentatives
def move_to_dlq(stream_name, group_name, max_retries=3):
    pending = r.xpending_range(stream_name, group_name, '-', '+', count=100)

    for entry in pending:
        if entry['times_delivered'] >= max_retries:
            # R√©cup√©rer le message complet
            msg = r.xrange(stream_name, entry['message_id'], entry['message_id'])

            # Copier vers DLQ
            r.xadd(f"{stream_name}:dlq", msg[0][1])

            # ACK l'original pour le retirer de pending
            r.xack(stream_name, group_name, entry['message_id'])
```

---

### 5. Observabilit√© et monitoring

#### Pub/Sub : Monitoring limit√©

```bash
# Informations disponibles
PUBSUB CHANNELS pattern*    # Liste des channels actifs
PUBSUB NUMSUB channel       # Nombre de subscribers par channel
PUBSUB NUMPAT              # Nombre de pattern subscriptions

# Exemple
PUBSUB NUMSUB notifications:users
# Retourne : 1) "notifications:users" 2) (integer) 5
```

**Limitations** :
- ‚ùå Pas d'historique des messages
- ‚ùå Pas de m√©triques de latence
- ‚ùå Impossible de tracer un message sp√©cifique

#### Streams : Observabilit√© compl√®te

```bash
# 1. Informations sur le stream
XINFO STREAM orders:stream
# Retourne : length, first-entry, last-entry, groups, etc.

# 2. √âtat des consumer groups
XINFO GROUPS orders:stream
# Retourne : name, consumers, pending, last-delivered-id

# 3. D√©tail par consumer
XINFO CONSUMERS orders:stream payment-processor
# Retourne : name, pending, idle time pour chaque consumer

# 4. Messages en attente (pending)
XPENDING orders:stream payment-processor
# Retourne : count, min-id, max-id, consumers avec leurs counts

# 5. D√©tail des messages pending
XPENDING orders:stream payment-processor - + 10
# Retourne : [id, consumer, idle_ms, delivery_count] pour chaque message
```

**Exemple de monitoring complet** :

```python
def monitor_stream_health(stream_name, group_name):
    r = redis.Redis()

    # M√©triques globales
    info = r.xinfo_stream(stream_name)
    stream_length = info['length']

    # M√©triques par consumer group
    groups = r.xinfo_groups(stream_name)
    for group in groups:
        pending_count = group['pending']
        lag = group['lag']  # Messages non-consomm√©s

        # M√©triques par consumer
        consumers = r.xinfo_consumers(stream_name, group['name'])
        for consumer in consumers:
            idle_time = consumer['idle']
            pending = consumer['pending']

            # Alerter si consumer inactif
            if idle_time > 60000 and pending > 0:
                alert(f"Consumer {consumer['name']} idle avec {pending} messages")

    # Analyser les messages probl√©matiques
    pending_details = r.xpending_range(stream_name, group_name, '-', '+', 100)
    for msg in pending_details:
        if msg['times_delivered'] > 5:
            alert(f"Message {msg['message_id']} failed {msg['times_delivered']} times")
```

---

## Tableau comparatif global

| Crit√®re | Pub/Sub | Streams | Lists |
|---------|---------|---------|-------|
| **Persistance** | ‚ùå Aucune | ‚úÖ Compl√®te (RDB/AOF) | ‚úÖ Compl√®te |
| **Garantie de livraison** | ‚ùå Best effort | ‚úÖ At-least-once | ‚úÖ Exactly-once possible |
| **Order preservation** | ‚úÖ Oui | ‚úÖ Oui (strict) | ‚úÖ Oui (FIFO) |
| **Multi-consumer** | ‚úÖ Broadcast | ‚úÖ Consumer groups | ‚ö†Ô∏è Manuel |
| **Load balancing** | ‚ùå Non natif | ‚úÖ Automatique | ‚ö†Ô∏è Pattern √† impl√©menter |
| **Rejouabilit√©** | ‚ùå Impossible | ‚úÖ Compl√®te | ‚ö†Ô∏è Une seule fois |
| **ACK/NACK** | ‚ùå Non | ‚úÖ Oui | ‚ö†Ô∏è Implicite (LPOP) |
| **Retry automatique** | ‚ùå Non | ‚úÖ Oui (pending) | ‚ùå Non |
| **Monitoring** | ‚ö†Ô∏è Limit√© | ‚úÖ Complet | ‚ö†Ô∏è Basique |
| **Latence** | ‚úÖ Ultra-faible (Œºs) | ‚ö†Ô∏è Faible (ms) | ‚ö†Ô∏è Faible (ms) |
| **Complexit√©** | ‚úÖ Tr√®s simple | ‚ö†Ô∏è Moyenne | ‚úÖ Simple |
| **Memory overhead** | ‚úÖ Minimal | ‚ö†Ô∏è Mod√©r√© | ‚úÖ Faible |
| **Message history** | ‚ùå Non | ‚úÖ Illimit√© | ‚ùå Non (consomm√© = supprim√©) |
| **Pattern matching** | ‚úÖ Oui (PSUBSCRIBE) | ‚ùå Non | ‚ùå Non |
| **Blocking operations** | ‚úÖ Oui | ‚úÖ Oui (XREAD BLOCK) | ‚úÖ Oui (BRPOP) |

---

## Cas d'usage d√©taill√©s

### Quand utiliser Pub/Sub ?

‚úÖ **Id√©al pour** :
```python
# 1. Invalidation de cache distribu√©e
redis.publish('cache:invalidate', 'user:123')

# 2. Live notifications WebSocket
redis.publish('notifications:user:456', json.dumps({
    'type': 'new_message',
    'from': 'user:789'
}))

# 3. Broadcast √† tous les serveurs d'application
redis.publish('config:reload', 'settings.json')

# 4. Dashboard temps r√©el (metrics)
redis.publish('metrics:live', json.dumps({
    'cpu': 45.2,
    'memory': 78.5,
    'timestamp': time.time()
}))
```

‚ùå **√Ä √©viter pour** :
- Traitement de commandes/transactions
- Syst√®mes de paiement
- Logs d'audit
- Tout ce qui n√©cessite une garantie de livraison

---

### Quand utiliser Streams ?

‚úÖ **Id√©al pour** :
```python
# 1. Pipeline de traitement de commandes
redis.xadd('orders:stream', {
    'order_id': '12345',
    'user_id': '789',
    'amount': 99.99,
    'status': 'pending'
})

# 2. Event sourcing
redis.xadd('events:user:123', {
    'event': 'profile_updated',
    'field': 'email',
    'old_value': 'old@example.com',
    'new_value': 'new@example.com',
    'timestamp': time.time()
})

# 3. Logs applicatifs centralis√©s
redis.xadd('logs:app', {
    'level': 'error',
    'service': 'payment-service',
    'message': 'Payment failed',
    'trace_id': 'abc-123'
})

# 4. Data pipeline avec transformations
# Stage 1: Raw data
redis.xadd('pipeline:raw', {'data': raw_data})
# Stage 2: Processed data
redis.xadd('pipeline:processed', {'data': processed_data})
# Stage 3: Enriched data
redis.xadd('pipeline:enriched', {'data': enriched_data})
```

‚úÖ **Parfait pour** :
- Syst√®mes n√©cessitant une garantie de traitement
- Architectures event-driven
- Audit trail et compliance
- Replay de sc√©narios pour debugging

---

### Quand utiliser Lists ?

‚úÖ **Id√©al pour** :
```python
# 1. Job queue simple
redis.lpush('jobs:email', json.dumps({
    'to': 'user@example.com',
    'subject': 'Welcome',
    'template': 'welcome.html'
}))

# Worker
job = redis.brpop('jobs:email', timeout=5)

# 2. Rate limiting avec window
redis.lpush(f'requests:{user_id}', timestamp)
redis.ltrim(f'requests:{user_id}', 0, 99)  # Garder 100 derni√®res

# 3. Recent items (feed)
redis.lpush('feed:user:123', post_id)
redis.ltrim('feed:user:123', 0, 49)  # Garder 50 posts
recent_posts = redis.lrange('feed:user:123', 0, 9)  # 10 plus r√©cents
```

‚ö†Ô∏è **Limitations** :
- Pas de consumer groups natifs
- Consommation = suppression (pas de rejouabilit√©)
- Pas d'ACK explicites

---

## Sc√©narios de migration

### De Pub/Sub vers Streams

**Sc√©nario** : Vous utilisez Pub/Sub mais perdez trop de messages.

```python
# AVANT (Pub/Sub)
import redis

r = redis.Redis()
pubsub = r.pubsub()
pubsub.subscribe('orders')

for message in pubsub.listen():
    try:
        process_order(message['data'])
    except Exception:
        # Message perdu si erreur !
        pass

# APR√àS (Streams)
import redis

r = redis.Redis()

# Setup
r.xgroup_create('orders:stream', 'order-processor', mkstream=True)

# Worker
while True:
    messages = r.xreadgroup(
        groupname='order-processor',
        consumername='worker-1',
        streams={'orders:stream': '>'},
        count=10,
        block=5000
    )

    for stream, entries in messages:
        for msg_id, data in entries:
            try:
                process_order(data)
                r.xack('orders:stream', 'order-processor', msg_id)
            except Exception as e:
                # Message reste en pending, sera retry√©
                logger.error(f"Will retry: {e}")
```

**B√©n√©fices** :
- ‚úÖ Z√©ro perte de message
- ‚úÖ Retry automatique
- ‚úÖ Monitoring complet
- ‚úÖ Scalabilit√© horizontale simple

---

### De Lists vers Streams

**Sc√©nario** : Vous avez besoin de consumer groups et de monitoring.

```python
# AVANT (Lists)
while True:
    job = redis.brpop('jobs', timeout=5)
    if job:
        process(job[1])
        # Probl√®me : Si crash pendant process(), job perdu

# APR√àS (Streams)
r.xgroup_create('jobs:stream', 'workers', mkstream=True)

while True:
    messages = r.xreadgroup(
        groupname='workers',
        consumername='worker-1',
        streams={'jobs:stream': '>'},
        count=1,
        block=5000
    )

    if messages:
        msg_id = messages[0][1][0][0]
        data = messages[0][1][0][1]

        try:
            process(data)
            r.xack('jobs:stream', 'workers', msg_id)
        except Exception:
            # Message reste en pending pour retry
            pass
```

---

## Patterns hybrides

### Combinaison Pub/Sub + Streams

**Use case** : Notifications temps r√©el + audit trail

```python
import redis
import json

r = redis.Redis()

def send_notification(user_id, notification):
    data = json.dumps(notification)

    # 1. Pub/Sub pour livraison imm√©diate (si online)
    r.publish(f'notifications:user:{user_id}', data)

    # 2. Streams pour persistance (si offline)
    r.xadd(f'notifications:user:{user_id}:history', {
        'type': notification['type'],
        'message': notification['message'],
        'timestamp': notification['timestamp']
    })

    # 3. Trimmer pour √©viter croissance infinie
    r.xtrim(f'notifications:user:{user_id}:history', maxlen=1000)

# Consumer online (Pub/Sub)
pubsub = r.pubsub()
pubsub.subscribe('notifications:user:123')

# Consumer offline recovery (Streams)
last_seen = r.get('user:123:last_notification_id') or '0-0'
history = r.xread({'notifications:user:123:history': last_seen}, count=100)
```

---

## Checklist de d√©cision

Utilisez cette checklist pour choisir le bon m√©canisme :

### Questions √† se poser

1. **Puis-je perdre des messages ?**
   - ‚úÖ Oui ‚Üí Pub/Sub
   - ‚ùå Non ‚Üí Streams ou Lists

2. **Ai-je besoin de rejouer des messages ?**
   - ‚úÖ Oui ‚Üí Streams uniquement
   - ‚ùå Non ‚Üí Pub/Sub ou Lists

3. **Combien de consumers ?**
   - Un seul ‚Üí Lists suffisent
   - Plusieurs (m√™me message) ‚Üí Pub/Sub
   - Plusieurs (charge distribu√©e) ‚Üí Streams

4. **Latence critique < 1ms ?**
   - ‚úÖ Oui ‚Üí Pub/Sub
   - ‚ùå Non ‚Üí Streams ou Lists acceptable

5. **Besoin d'ACK explicites ?**
   - ‚úÖ Oui ‚Üí Streams uniquement
   - ‚ùå Non ‚Üí Pub/Sub ou Lists

6. **Besoin de monitoring d√©taill√© ?**
   - ‚úÖ Oui ‚Üí Streams
   - ‚ùå Non ‚Üí Pub/Sub ou Lists

7. **Ordre de traitement important ?**
   - ‚úÖ Critique ‚Üí Streams (garantie stricte)
   - ‚ö†Ô∏è Important ‚Üí Lists (FIFO simple)
   - ‚ùå Peu important ‚Üí Pub/Sub

---

## Performance et overhead

### Benchmarks comparatifs

```bash
# Pub/Sub
redis-benchmark -t publish -c 50 -n 100000
# ~100,000 ops/sec avec latence < 1ms

# Streams (sans consumer groups)
redis-benchmark -c 50 -n 100000 XADD mystream * field value
# ~80,000 ops/sec avec latence ~1-2ms

# Streams (avec consumer groups et ACK)
# ~40,000-60,000 ops/sec avec latence ~2-5ms

# Lists
redis-benchmark -t lpush,rpop -c 50 -n 100000
# ~90,000 ops/sec
```

### Consommation m√©moire

```python
import redis
import sys

r = redis.Redis()

# Pub/Sub : Aucune persistance
# Memory overhead : ~0 bytes (juste connexions actives)

# Streams : Par message
message = {'field1': 'value1', 'field2': 'value2', 'field3': 'value3'}
r.xadd('test:stream', message)
# Memory : ~150-200 bytes par message + overhead structure

# Lists : Par √©l√©ment
r.lpush('test:list', 'value')
# Memory : ~80-100 bytes par √©l√©ment + overhead structure
```

---

## Conclusion et recommandations

### R√®gles d'or

1. **Par d√©faut, commencez simple** :
   - Notifications non-critiques ‚Üí Pub/Sub
   - Job queues simples ‚Üí Lists
   - Tout le reste ‚Üí Streams

2. **√âvoluez selon vos besoins** :
   - Pub/Sub perd des messages ‚Üí Migrez vers Streams
   - Lists deviennent complexes ‚Üí Migrez vers Streams
   - Latence critique < 1ms ‚Üí Restez sur Pub/Sub

3. **Ne sur-complexifiez pas** :
   - Pas besoin de Streams si Lists + retry manuel suffisent
   - Pas besoin de Streams si les messages peuvent √™tre perdus

4. **Pensez observabilit√© d√®s le d√©part** :
   - Si debugging important ‚Üí Streams
   - Si "fire and forget" acceptable ‚Üí Pub/Sub

### Pour aller plus loin

Les sections suivantes du module d√©taillent :
- **8.1** : Pub/Sub classique en profondeur
- **8.2** : Sharded Pub/Sub pour le scaling
- **8.3-8.5** : Redis Streams (concepts, consumer groups, patterns avanc√©s)
- **8.6** : Comparaison avec Kafka et autres solutions

---

**Points cl√©s √† retenir** :
- üöÄ Pub/Sub = Vitesse maximale, z√©ro garantie
- üîí Streams = Garanties fortes, observabilit√© compl√®te
- üì¶ Lists = Simplicit√©, cas d'usage limit√©s
- üéØ Le choix d√©pend de vos contraintes m√©tier, pas de pr√©f√©rences techniques


‚è≠Ô∏è [Pub/Sub classique : Le "Fire and Forget"](/08-communication-flux-donnees/01-pubsub-classique-fire-and-forget.md)
