ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 10.2 Topologie de rÃ©plication (chaÃ®nÃ©e, en Ã©toile)

## Introduction

La topologie de rÃ©plication dÃ©finit comment les instances Redis sont organisÃ©es et interconnectÃ©es pour former un systÃ¨me de haute disponibilitÃ©. Le choix de la topologie impacte directement la latence, la scalabilitÃ©, la rÃ©silience et la complexitÃ© opÃ©rationnelle de votre infrastructure Redis.

Cette section explore les diffÃ©rentes topologies possibles, leurs avantages, inconvÃ©nients et cas d'usage appropriÃ©s.

---

## ğŸŒŸ Topologie 1 : Ã‰toile (Star / Fan-out)

### Architecture

La topologie en Ã©toile est la plus simple et la plus courante : un master central rÃ©plique vers plusieurs replicas de mÃªme niveau.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TOPOLOGIE EN Ã‰TOILE (STAR)                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                     â”‚                â”‚                          â”‚
â”‚                     â”‚  MASTER (M)    â”‚                          â”‚
â”‚                     â”‚  10.0.1.10     â”‚                          â”‚
â”‚                     â”‚  Zone A        â”‚                          â”‚
â”‚                     â”‚                â”‚                          â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â”‚ Replication                      â”‚
â”‚                              â”‚ (tous au mÃªme niveau)            â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚              â”‚               â”‚               â”‚                  â”‚
â”‚              â–¼               â–¼               â–¼                  â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚        â”‚REPLICA 1 â”‚    â”‚REPLICA 2 â”‚    â”‚REPLICA 3 â”‚             â”‚
â”‚        â”‚10.0.1.11 â”‚    â”‚10.0.1.12 â”‚    â”‚10.0.1.13 â”‚             â”‚
â”‚        â”‚ Zone A   â”‚    â”‚ Zone B   â”‚    â”‚ Zone C   â”‚             â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚             â”‚               â”‚               â”‚                   â”‚
â”‚             â”‚               â”‚               â”‚                   â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                            â”‚                                    â”‚
â”‚                     Read Operations                             â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚                    â”‚Load Balancer â”‚                             â”‚
â”‚                    â”‚  (Optional)  â”‚                             â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                                                                 â”‚
â”‚  CaractÃ©ristiques:                                              â”‚
â”‚  â€¢ Latence uniforme: tous les replicas ont la mÃªme latence      â”‚
â”‚  â€¢ ScalabilitÃ© reads: ajout de replicas = plus de capacitÃ©      â”‚
â”‚  â€¢ Bande passante: N replicas = N Ã— bandwidth master            â”‚
â”‚  â€¢ SPOF: Le master est un point de dÃ©faillance unique           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration

**Master (10.0.1.10)** :

```ini
# redis-master-star.conf

################################# NETWORK ####################################
bind 0.0.0.0
port 6379
protected-mode yes
requirepass "MasterPass2024!"
masterauth "MasterPass2024!"

################################ REPLICATION #################################
# Configuration pour supporter N replicas
repl-diskless-sync yes
repl-diskless-sync-delay 5  # Attendre pour batcher les syncs
repl-diskless-sync-max-replicas 0  # Pas de limite

# Backlog dimensionnÃ© pour gÃ©rer dÃ©connexions
repl-backlog-size 256mb
repl-backlog-ttl 3600

# Protection: Minimum 2 replicas connectÃ©s
min-replicas-to-write 2
min-replicas-max-lag 10

# Client output buffer: CRITIQUE pour topologie Ã©toile
# Avec N replicas, le buffer doit supporter N Ã— traffic
client-output-buffer-limit replica 1gb 256mb 60
# Format: <hard> <soft> <soft_seconds>
# Hard: 1GB â†’ dÃ©connexion immÃ©diate si dÃ©passÃ©
# Soft: 256MB pendant 60s â†’ dÃ©connexion

################################ PERSISTENCE #################################
appendonly yes
appendfsync everysec
save ""  # DÃ©sactiver RDB auto-save

################################# MEMORY #####################################
maxmemory 8gb
maxmemory-policy allkeys-lru

################################### LOGS #####################################
loglevel notice
logfile "/var/log/redis/master-star.log"

# Monitoring des replicas
# Ajouter dans monitoring:
# - connected_slaves (doit Ãªtre 3)
# - Lag de chaque replica (<10s)
```

**Replica 1, 2, 3** (configurations identiques sauf IPs) :

```ini
# redis-replica-star.conf

################################# NETWORK ####################################
bind 0.0.0.0
port 6379
protected-mode yes
requirepass "ReplicaPass2024!"
masterauth "MasterPass2024!"

################################ REPLICATION #################################
# Pointer vers le master
replicaof 10.0.1.10 6379

replica-read-only yes
replica-priority 100  # Ajuster pour chaque replica (100, 90, 80)

# Timeouts adaptÃ©s Ã  la topologie
repl-timeout 60
repl-ping-replica-period 10

# Servir donnÃ©es obsolÃ¨tes si master down?
replica-serve-stale-data yes  # "no" si cohÃ©rence stricte nÃ©cessaire

# Pour Docker/NAT (optionnel)
replica-announce-ip 10.0.1.11  # IP publique de ce replica
replica-announce-port 6379

################################ PERSISTENCE #################################
appendonly yes
appendfsync everysec

################################# MEMORY #####################################
maxmemory 8gb
maxmemory-policy allkeys-lru

################################### LOGS #####################################
loglevel notice
logfile "/var/log/redis/replica1-star.log"
```

### Analyse de performance

**Bande passante master** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CONSOMMATION BANDE PASSANTE - TOPOLOGIE Ã‰TOILE                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Formule: Bandwidth_total = Write_throughput Ã— N_replicas       â”‚
â”‚                                                                 â”‚
â”‚  Exemple:                                                       â”‚
â”‚  â€¢ Write throughput: 100 MB/s                                   â”‚
â”‚  â€¢ Nombre de replicas: 3                                        â”‚
â”‚  â€¢ Bandwidth nÃ©cessaire: 100 Ã— 3 = 300 MB/s                     â”‚
â”‚                                                                 â”‚
â”‚  Network saturation check:                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Master                                      â”‚                â”‚
â”‚  â”‚                                             â”‚                â”‚
â”‚  â”‚  NIC: 1 Gbps (125 MB/s)                     â”‚                â”‚
â”‚  â”‚                                             â”‚                â”‚
â”‚  â”‚  Traffic:                                   â”‚                â”‚
â”‚  â”‚  â”œâ”€ Client writes: 100 MB/s                 â”‚                â”‚
â”‚  â”‚  â”œâ”€ Replica 1: 100 MB/s                     â”‚                â”‚
â”‚  â”‚  â”œâ”€ Replica 2: 100 MB/s                     â”‚                â”‚
â”‚  â”‚  â””â”€ Replica 3: 100 MB/s                     â”‚                â”‚
â”‚  â”‚                                             â”‚                â”‚
â”‚  â”‚  Total: 400 MB/s  âŒ SATURATION!            â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                 â”‚
â”‚  Solution:                                                      â”‚
â”‚  â€¢ Upgrade NIC Ã  10 Gbps                                        â”‚
â”‚  â€¢ RÃ©duire nombre de replicas                                   â”‚
â”‚  â€¢ Utiliser topologie en cascade                                â”‚
â”‚  â€¢ Compression (Redis Enterprise)                               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Avantages et inconvÃ©nients

**âœ… Avantages** :

1. **SimplicitÃ© opÃ©rationnelle** : Configuration et maintenance aisÃ©es
2. **Latence uniforme** : Tous les replicas ont la mÃªme latence depuis master
3. **Promotion rapide** : N'importe quel replica peut devenir master
4. **Debugging facile** : Flux de donnÃ©es linÃ©aire et prÃ©visible

**âŒ InconvÃ©nients** :

1. **ScalabilitÃ© limitÃ©e** : Bande passante master = goulot d'Ã©tranglement
2. **SPOF** : Master est un point de dÃ©faillance unique
3. **CoÃ»t rÃ©seau** : N replicas = N Ã— bande passante
4. **Pas de gÃ©o-distribution optimale** : Tous les replicas subissent la mÃªme latence WAN

### Cas d'usage recommandÃ©s

```yaml
ScÃ©narios adaptÃ©s:
  - Nombre de replicas: 2-5 replicas maximum
  - MÃªme datacenter / rÃ©gion: Latence <10ms
  - Write throughput: <50 MB/s
  - Read scaling: ModÃ©rÃ© (quelques replicas suffisent)

Exemples:
  - Application web standard avec 2-3 replicas
  - Service API avec load balancing lecture
  - Cache distribuÃ© avec HA basique
```

---

## ğŸ”— Topologie 2 : ChaÃ®nÃ©e (Cascading / Chain)

### Architecture

La topologie chaÃ®nÃ©e organise les replicas en plusieurs niveaux hiÃ©rarchiques, rÃ©duisant la charge sur le master.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TOPOLOGIE CHAÃNÃ‰E (CASCADING)                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Level 0 (Master):                                              â”‚
â”‚                                                                 â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                     â”‚   MASTER (M)   â”‚                          â”‚
â”‚                     â”‚   10.0.1.10    â”‚                          â”‚
â”‚                     â”‚   Write: 100%  â”‚                          â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                              â”‚                                  â”‚
â”‚                              â”‚ Bandwidth: 100 MB/s              â”‚
â”‚                              â”‚                                  â”‚
â”‚  Level 1 (Primary Replicas): â”‚                                  â”‚
â”‚                              â”‚                                  â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚              â”‚                               â”‚                  â”‚
â”‚              â–¼                               â–¼                  â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚        â”‚REPLICA L1â”‚                    â”‚REPLICA L1â”‚             â”‚
â”‚        â”‚   (R1)   â”‚                    â”‚   (R2)   â”‚             â”‚
â”‚        â”‚10.0.1.11 â”‚                    â”‚10.0.1.12 â”‚             â”‚
â”‚        â”‚Zone A    â”‚                    â”‚Zone B    â”‚             â”‚
â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜             â”‚
â”‚             â”‚                               â”‚                   â”‚
â”‚             â”‚ Bandwidth: 100 MB/s           â”‚ Bandwidth: 100MB  â”‚
â”‚             â”‚                               â”‚                   â”‚
â”‚  Level 2:   â”‚                               â”‚                   â”‚
â”‚             â”‚                               â”‚                   â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚      â”‚             â”‚                 â”‚             â”‚            â”‚
â”‚      â–¼             â–¼                 â–¼             â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚R L2-A1â”‚    â”‚R L2-A2â”‚         â”‚R L2-B1â”‚    â”‚R L2-B2â”‚          â”‚
â”‚  â”‚.13    â”‚    â”‚.14    â”‚         â”‚.15    â”‚    â”‚.16    â”‚          â”‚
â”‚  â”‚Zone A â”‚    â”‚Zone A'â”‚         â”‚Zone B â”‚    â”‚Zone B'â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                 â”‚
â”‚  CaractÃ©ristiques:                                              â”‚
â”‚  â€¢ Master bandwidth: RÃ©duit de 50% (2 replicas vs 6)            â”‚
â”‚  â€¢ Latence cumulÃ©e: L0â†’L1 (~5ms) + L1â†’L2 (~5ms) = ~10ms         â”‚
â”‚  â€¢ ScalabilitÃ©: Meilleure qu'Ã©toile (ajout Level 3 possible)    â”‚
â”‚  â€¢ ComplexitÃ©: Plus Ã©levÃ©e (gestion multi-niveaux)              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration

**Master (Level 0)** :

```ini
# redis-master-cascade.conf

################################# NETWORK ####################################
bind 0.0.0.0
port 6379
protected-mode yes
requirepass "MasterPass2024!"
masterauth "MasterPass2024!"

################################ REPLICATION #################################
# Seulement 2 replicas directs (L1)
repl-diskless-sync yes
repl-diskless-sync-delay 5

# Backlog standard (charge rÃ©duite)
repl-backlog-size 128mb
repl-backlog-ttl 3600

# Protection: Minimum 1 replica L1
min-replicas-to-write 1
min-replicas-max-lag 10

# Output buffer adaptÃ© (seulement 2 connexions)
client-output-buffer-limit replica 512mb 128mb 60

################################ PERSISTENCE #################################
appendonly yes
appendfsync everysec

################################# MEMORY #####################################
maxmemory 8gb
maxmemory-policy allkeys-lru

################################### LOGS #####################################
loglevel notice
logfile "/var/log/redis/master-cascade.log"
```

**Replica Level 1 (R1, R2)** :

```ini
# redis-replica-l1.conf

################################# NETWORK ####################################
bind 0.0.0.0
port 6379
protected-mode yes
requirepass "ReplicaL1Pass2024!"
masterauth "MasterPass2024!"

################################ REPLICATION #################################
# Connexion au Master
replicaof 10.0.1.10 6379

replica-read-only yes
replica-priority 90  # Plus prioritaire que L2 pour promotion

# IMPORTANT: Accepter connexions de replicas L2
# (pas de config spÃ©ciale, juste s'assurer que bind 0.0.0.0)

repl-timeout 60
repl-ping-replica-period 10

# Servir donnÃ©es mÃªme si master down (pour L2)
replica-serve-stale-data yes

################################ PERSISTENCE #################################
appendonly yes
appendfsync everysec

################################# MEMORY #####################################
maxmemory 8gb
maxmemory-policy allkeys-lru

# Output buffer pour replicas L2 connectÃ©s
client-output-buffer-limit replica 512mb 128mb 60

################################### LOGS #####################################
loglevel notice
logfile "/var/log/redis/replica-l1-r1.log"

# NOTE CRITIQUE:
# Ce replica L1 agit Ã  la fois comme:
# - Replica du Master (L0)
# - Master pour replicas L2
# Monitoring: VÃ©rifier connected_slaves sur cette instance
```

**Replica Level 2 (R L2-A1, R L2-A2, etc.)** :

```ini
# redis-replica-l2.conf

################################# NETWORK ####################################
bind 0.0.0.0
port 6379
protected-mode yes
requirepass "ReplicaL2Pass2024!"
masterauth "ReplicaL1Pass2024!"  # Password du replica L1!

################################ REPLICATION #################################
# IMPORTANT: Pointer vers Replica L1, pas Master!
replicaof 10.0.1.11 6379  # IP du Replica L1 (R1)

replica-read-only yes
replica-priority 80  # Moins prioritaire que L1 pour promotion

repl-timeout 90  # Plus long (cumul latence L0â†’L1â†’L2)
repl-ping-replica-period 10

replica-serve-stale-data yes

################################ PERSISTENCE #################################
appendonly yes
appendfsync everysec

################################# MEMORY #####################################
maxmemory 8gb
maxmemory-policy allkeys-lru

################################### LOGS #####################################
loglevel notice
logfile "/var/log/redis/replica-l2-a1.log"

# ATTENTION:
# - Latence cumulÃ©e: lag(Mâ†’L1) + lag(L1â†’L2)
# - Si L1 down, L2 devient orphelin
# - Monitoring: VÃ©rifier master_link_status ET upstream health
```

### Calcul de latence cumulÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LATENCE CUMULÃ‰E - TOPOLOGIE CHAÃNÃ‰E                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Latence_L2 = Latence(Mâ†’L1) + Latence(L1â†’L2)                    â”‚
â”‚                                                                 â”‚
â”‚  ScÃ©nario 1: MÃªme datacenter                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ M â†’ L1: 2ms (Same AZ)                 â”‚                      â”‚
â”‚  â”‚ L1 â†’ L2: 3ms (Different AZ)           â”‚                      â”‚
â”‚  â”‚ Total L2: 5ms                         â”‚  âœ… Acceptable       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                 â”‚
â”‚  ScÃ©nario 2: Multi-rÃ©gion                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ M (Paris) â†’ L1 (Frankfurt): 20ms      â”‚                      â”‚
â”‚  â”‚ L1 (Frankfurt) â†’ L2 (London): 15ms    â”‚                      â”‚
â”‚  â”‚ Total L2: 35ms                        â”‚  âš ï¸  Ã‰levÃ©           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                 â”‚
â”‚  ScÃ©nario 3: Multi-niveau profond (3 niveaux)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ M â†’ L1: 5ms                           â”‚                      â”‚
â”‚  â”‚ L1 â†’ L2: 5ms                          â”‚                      â”‚
â”‚  â”‚ L2 â†’ L3: 5ms                          â”‚                      â”‚
â”‚  â”‚ Total L3: 15ms                        â”‚  âš ï¸  Limite          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                 â”‚
â”‚  Recommandation:                                                â”‚
â”‚  â€¢ Max 2 niveaux de cascade (L1, L2)                            â”‚
â”‚  â€¢ Total latency < 50ms                                         â”‚
â”‚  â€¢ Au-delÃ : considÃ©rer topologie Ã©toile ou cluster              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Gestion des pannes en cascade

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SCÃ‰NARIOS DE PANNE - TOPOLOGIE CHAÃNÃ‰E                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ScÃ©nario 1: Panne Master (M)                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚                                                                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”                                                    â”‚
â”‚      â”‚  M  â”‚ âœ— DOWN                                             â”‚
â”‚      â””â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚         â”‚                                                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                                  â”‚
â”‚    â–¼         â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”     â”Œâ”€â”€â”€â”                                                â”‚
â”‚  â”‚ L1â”‚     â”‚ L1â”‚  â† Sentinel promeut L1 comme master            â”‚
â”‚  â”‚ R1â”‚     â”‚ R2â”‚                                                â”‚
â”‚  â””â”€â”¬â”€â”˜     â””â”€â”¬â”€â”˜                                                â”‚
â”‚    â”‚         â”‚                                                  â”‚
â”‚    â–¼         â–¼                                                  â”‚
â”‚   L2 OK    L2 OK  â† L2 restent connectÃ©s                        â”‚
â”‚                                                                 â”‚
â”‚  Impact: Minimal (failover standard)                            â”‚
â”‚  Action: Sentinel gÃ¨re automatiquement                          â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                 â”‚
â”‚  ScÃ©nario 2: Panne Replica L1 (R1)                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚                                                                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”                                                    â”‚
â”‚      â”‚  M  â”‚ OK                                                 â”‚
â”‚      â””â”€â”€â”¬â”€â”€â”˜                                                    â”‚
â”‚         â”‚                                                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                                  â”‚
â”‚    â”‚         â–¼                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”     â”Œâ”€â”€â”€â”                                                â”‚
â”‚  â”‚ L1â”‚âœ—    â”‚ L1â”‚ OK                                             â”‚
â”‚  â”‚ R1â”‚     â”‚ R2â”‚                                                â”‚
â”‚  â””â”€â”¬â”€â”˜     â””â”€â”¬â”€â”˜                                                â”‚
â”‚    â”‚         â”‚                                                  â”‚
â”‚    â–¼         â–¼                                                  â”‚
â”‚ L2 (R1)    L2 (R2) OK                                           â”‚
â”‚ ORPHELINS!                                                      â”‚
â”‚                                                                 â”‚
â”‚  Impact: Replicas L2 de R1 deviennent orphelins                 â”‚
â”‚  Action:                                                        â”‚
â”‚  1. Sentinel dÃ©tecte panne R1                                   â”‚
â”‚  2. Replicas L2 de R1 doivent Ãªtre reconfigurÃ©s:                â”‚
â”‚     redis-cli -h L2-A1 REPLICAOF 10.0.1.12 6379  (pointer R2)   â”‚
â”‚  3. Ou attendre que R1 revienne                                 â”‚
â”‚                                                                 â”‚
â”‚  âš ï¸  Automation recommandÃ©e (script monitoring)                 â”‚
â”‚                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                 â”‚
â”‚  ScÃ©nario 3: Partition rÃ©seau Mâ†”L1                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”‚
â”‚                                                                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”                                                    â”‚
â”‚      â”‚  M  â”‚ Isolated                                           â”‚
â”‚      â””â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚         âœ— Network partition                                     â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                                  â”‚
â”‚    â”‚         â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”     â”Œâ”€â”€â”€â”                                                â”‚
â”‚  â”‚ L1â”‚     â”‚ L1â”‚  â† Peuvent encore communiquer entre eux        â”‚
â”‚  â”‚ R1â”‚â—„â”€â”€â”€â–¶â”‚ R2â”‚                                                â”‚
â”‚  â””â”€â”¬â”€â”˜     â””â”€â”¬â”€â”˜                                                â”‚
â”‚    â”‚         â”‚                                                  â”‚
â”‚    â–¼         â–¼                                                  â”‚
â”‚   L2        L2  â† Continuent Ã  rÃ©pliquer depuis L1              â”‚
â”‚                                                                 â”‚
â”‚  Impact: Split-brain possible                                   â”‚
â”‚  Protection: min-replicas-to-write sur Master                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Script d'auto-healing pour replicas L2 orphelins** :

```bash
#!/bin/bash
# auto-heal-l2-replicas.sh
# Ã€ exÃ©cuter sur un serveur de monitoring

MASTER="10.0.1.10"
L1_R1="10.0.1.11"
L1_R2="10.0.1.12"
L2_REPLICAS=("10.0.1.13" "10.0.1.14" "10.0.1.15" "10.0.1.16")

# VÃ©rifier santÃ© L1
check_l1_health() {
    local l1_host=$1
    redis-cli -h $l1_host PING >/dev/null 2>&1
    return $?
}

# VÃ©rifier connexion d'un L2
check_l2_connection() {
    local l2_host=$1
    local status=$(redis-cli -h $l2_host INFO replication | grep master_link_status | cut -d: -f2 | tr -d '\r\n')
    [[ "$status" == "up" ]]
    return $?
}

# Reconfigurer un L2 vers un nouveau L1
repoint_l2() {
    local l2_host=$1
    local new_l1=$2
    echo "Reconfiguring $l2_host to point to $new_l1"
    redis-cli -h $l2_host REPLICAOF $new_l1 6379
}

# Boucle de monitoring
while true; do
    # Check L1 health
    L1_R1_UP=$(check_l1_health $L1_R1 && echo "yes" || echo "no")
    L1_R2_UP=$(check_l1_health $L1_R2 && echo "yes" || echo "no")

    echo "$(date): L1-R1=$L1_R1_UP, L1-R2=$L1_R2_UP"

    # Si L1-R1 down, pointer ses L2 vers L1-R2
    if [[ "$L1_R1_UP" == "no" && "$L1_R2_UP" == "yes" ]]; then
        for l2 in "${L2_REPLICAS[@]:0:2}"; do  # Premier 2 L2 appartiennent Ã  R1
            if ! check_l2_connection $l2; then
                echo "âš ï¸  $l2 disconnected, repointing to $L1_R2"
                repoint_l2 $l2 $L1_R2
            fi
        done
    fi

    # Si L1-R2 down, pointer ses L2 vers L1-R1
    if [[ "$L1_R2_UP" == "no" && "$L1_R1_UP" == "yes" ]]; then
        for l2 in "${L2_REPLICAS[@]:2:2}"; do  # Dernier 2 L2 appartiennent Ã  R2
            if ! check_l2_connection $l2; then
                echo "âš ï¸  $l2 disconnected, repointing to $L1_R1"
                repoint_l2 $l2 $L1_R1
            fi
        done
    fi

    sleep 10
done
```

### Avantages et inconvÃ©nients

**âœ… Avantages** :

1. **ScalabilitÃ© amÃ©liorÃ©e** : Bande passante master rÃ©duite (N/2 si 2 branches)
2. **RÃ©partition de charge** : Replicas L1 distribuent la charge
3. **GÃ©o-distribution** : L1 dans rÃ©gions principales, L2 dans zones secondaires
4. **CoÃ»t rÃ©seau optimisÃ©** : RÃ©plication locale dans chaque rÃ©gion

**âŒ InconvÃ©nients** :

1. **Latence cumulÃ©e** : L2+ subissent latence additionnelle
2. **ComplexitÃ© accrue** : Configuration et monitoring plus complexes
3. **Orphelins potentiels** : L2 deviennent orphelins si L1 down
4. **Promotion compliquÃ©e** : HiÃ©rarchie doit Ãªtre reconfigurÃ©e lors failover

### Cas d'usage recommandÃ©s

```yaml
ScÃ©narios adaptÃ©s:
  - Nombre de replicas: >5 replicas
  - GÃ©o-distribution: Multi-rÃ©gions avec rÃ©plication locale
  - Write throughput Ã©levÃ©: >50 MB/s
  - Bande passante limitÃ©e: Optimisation des coÃ»ts rÃ©seau

Exemples:
  - Application globale avec L1 par continent
  - CDN-like architecture avec edge replicas (L2)
  - Multi-datacenter avec hiÃ©rarchie rÃ©gionale

Ã€ Ã©viter:
  - Applications nÃ©cessitant latence uniforme
  - Petites dÃ©ploiements (<5 replicas)
  - Ã‰quipe sans expertise DevOps avancÃ©e
```

---

## ğŸŒ Topologie 3 : Hybride (Ã‰toile + ChaÃ®ne)

### Architecture

Combinaison des deux topologies pour optimiser diffÃ©rents cas d'usage.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TOPOLOGIE HYBRIDE                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                     â”‚   MASTER (M)   â”‚                         â”‚
â”‚                     â”‚   Paris        â”‚                         â”‚
â”‚                     â”‚   10.0.1.10    â”‚                         â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                              â”‚                                 â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚          â”‚                   â”‚                   â”‚             â”‚
â”‚          â”‚                   â”‚                   â”‚             â”‚
â”‚  Ã‰toile  â”‚            Ã‰toile â”‚            Cascadeâ”‚             â”‚
â”‚  (local) â”‚           (backup)â”‚          (distant)â”‚             â”‚
â”‚          â”‚                   â”‚                   â”‚             â”‚
â”‚          â–¼                   â–¼                   â–¼             â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚REPLICA L1â”‚        â”‚REPLICA L1â”‚        â”‚REPLICA L1â”‚        â”‚
â”‚    â”‚  (Local) â”‚        â”‚ (Backup) â”‚        â”‚(Regional)â”‚        â”‚
â”‚    â”‚  Paris   â”‚        â”‚  Paris   â”‚        â”‚Frankfurt â”‚        â”‚
â”‚    â”‚ 10.0.1.11â”‚        â”‚ 10.0.1.12â”‚        â”‚10.0.2.10 â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                    â”‚                  â”‚              â”‚
â”‚         â”‚                    â”‚                  â”‚ Cascade      â”‚
â”‚    Read traffic         Read traffic            â”‚ (local)      â”‚
â”‚     (Local)             (Backup)                â”‚              â”‚
â”‚                                          â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚                                          â”‚             â”‚       â”‚
â”‚                                          â–¼             â–¼       â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                    â”‚REPLICA L2â”‚ â”‚REPLICA L2â”‚   â”‚
â”‚                                    â”‚Frankfurt â”‚ â”‚Frankfurt â”‚   â”‚
â”‚                                    â”‚10.0.2.11 â”‚ â”‚10.0.2.12 â”‚   â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                          â”‚             â”‚       â”‚
â”‚                                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                 â”‚              â”‚
â”‚                                          Read traffic          â”‚
â”‚                                         (Regional)             â”‚
â”‚                                                                â”‚
â”‚  CaractÃ©ristiques:                                             â”‚
â”‚  â€¢ Paris: 2 replicas Ã©toile (latence minimale)                 â”‚
â”‚  â€¢ Frankfurt: 1 L1 + 2 L2 cascade (optimisation bandwidth)     â”‚
â”‚  â€¢ Best of both worlds                                         â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration

La configuration hybride utilise les mÃªmes fichiers que prÃ©cÃ©demment, avec une planification rÃ©seau appropriÃ©e :

**Planification des connexions** :

```yaml
# topology-map.yaml

master:
  host: 10.0.1.10
  location: Paris
  role: master
  direct_replicas:
    - 10.0.1.11  # L1 Local Paris (Ã©toile)
    - 10.0.1.12  # L1 Backup Paris (Ã©toile)
    - 10.0.2.10  # L1 Regional Frankfurt (tÃªte de cascade)

replicas_l1:
  - host: 10.0.1.11
    location: Paris
    type: star  # Connexion directe au master
    purpose: Local read traffic

  - host: 10.0.1.12
    location: Paris
    type: star
    purpose: Backup / DR

  - host: 10.0.2.10
    location: Frankfurt
    type: cascade_head  # TÃªte de cascade pour rÃ©gion
    purpose: Regional distribution
    sub_replicas:
      - 10.0.2.11  # L2 Frankfurt 1
      - 10.0.2.12  # L2 Frankfurt 2

replicas_l2:
  - host: 10.0.2.11
    location: Frankfurt
    master: 10.0.2.10  # Pointe vers L1 rÃ©gional

  - host: 10.0.2.12
    location: Frankfurt
    master: 10.0.2.10
```

### Cas d'usage recommandÃ©s

```yaml
ScÃ©narios adaptÃ©s:
  - Multi-rÃ©gion avec asymÃ©trie:
      â€¢ RÃ©gion principale: Ã‰toile (latence minimale)
      â€¢ RÃ©gions secondaires: Cascade (Ã©conomie bandwidth)

  - Besoins mixtes:
      â€¢ Production: Ã‰toile pour performance
      â€¢ Analytics: Cascade pour isolation
      â€¢ DR: Ã‰toile pour failover rapide

  - Optimisation coÃ»ts:
      â€¢ Replicas locaux: Ã‰toile (faible coÃ»t rÃ©seau)
      â€¢ Replicas WAN: Cascade (rÃ©duction 50% bandwidth)

Exemples:
  - E-commerce global: EU (Ã©toile) + US/ASIA (cascade)
  - SaaS multi-tenant: Tenant principal (Ã©toile) + autres (cascade)
  - Media streaming: CDN architecture hybride
```

---

## ğŸŒ Topologie 4 : GÃ©o-distribuÃ©e

### Architecture

Optimisation pour applications globales avec latence locale.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TOPOLOGIE GÃ‰O-DISTRIBUÃ‰E                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    MASTER (Active)                         â”‚ â”‚
â”‚  â”‚                      EU-WEST-1                             â”‚ â”‚
â”‚  â”‚                      Paris                                 â”‚ â”‚
â”‚  â”‚                      10.1.0.10                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â”‚                                       â”‚
â”‚                         â”‚ WAN Replication                       â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚         â”‚               â”‚               â”‚                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚   EU-WEST   â”‚ â”‚  US-EAST    â”‚ â”‚  ASIA-PAC  â”‚                 â”‚
â”‚  â”‚  (Regional) â”‚ â”‚ (Regional)  â”‚ â”‚ (Regional) â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                                 â”‚
â”‚  RÃ©gion 1: EU-WEST                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Master: 10.1.0.10 (Paris)               â”‚                   â”‚
â”‚  â”‚    â†“                                     â”‚                   â”‚
â”‚  â”‚  Replica L1: 10.1.0.11 (Paris AZ-B)      â”‚ ~2ms              â”‚
â”‚  â”‚  Replica L1: 10.1.0.12 (London)          â”‚ ~10ms             â”‚
â”‚  â”‚    â†“                                     â”‚                   â”‚
â”‚  â”‚  Replica L2: 10.1.0.13 (Amsterdam)       â”‚ ~5ms              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                 â”‚
â”‚  RÃ©gion 2: US-EAST                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Replica L1: 10.2.0.10 (Virginia)        â”‚ ~80ms from M      â”‚
â”‚  â”‚    â†“                                     â”‚                   â”‚
â”‚  â”‚  Replica L2: 10.2.0.11 (Virginia AZ-B)   â”‚ ~2ms from L1      â”‚
â”‚  â”‚  Replica L2: 10.2.0.12 (Ohio)            â”‚ ~5ms from L1      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                 â”‚
â”‚  RÃ©gion 3: ASIA-PAC                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Replica L1: 10.3.0.10 (Singapore)       â”‚ ~150ms from M     â”‚
â”‚  â”‚    â†“                                     â”‚                   â”‚
â”‚  â”‚  Replica L2: 10.3.0.11 (Tokyo)           â”‚ ~60ms from L1     â”‚
â”‚  â”‚  Replica L2: 10.3.0.12 (Sydney)          â”‚ ~80ms from L1     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                                                                 â”‚
â”‚  CaractÃ©ristiques:                                              â”‚
â”‚  â€¢ Read locality: <10ms dans chaque rÃ©gion                      â”‚
â”‚  â€¢ Write latency: Variable selon rÃ©gion client                  â”‚
â”‚  â€¢ Failover rÃ©gional possible (L1 â†’ Master)                     â”‚
â”‚  â€¢ Bandwidth optimisÃ© (1 connexion WAN par rÃ©gion)              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration avancÃ©e avec DNS

**StratÃ©gie de connexion client** :

```yaml
# dns-routing.yaml

# GeoDNS ou Latency-based routing (AWS Route53, Cloudflare)

endpoints:
  # Endpoint global (write-through)
  write:
    domain: redis-master.global.company.com
    target: 10.1.0.10  # Master Paris

  # Endpoints rÃ©gionaux (read-local)
  read:
    eu-west:
      domain: redis-read.eu.company.com
      targets:
        - 10.1.0.11  # Paris AZ-B
        - 10.1.0.12  # London
      routing: round-robin

    us-east:
      domain: redis-read.us.company.com
      targets:
        - 10.2.0.11  # Virginia AZ-B
        - 10.2.0.12  # Ohio
      routing: round-robin

    asia-pac:
      domain: redis-read.asia.company.com
      targets:
        - 10.3.0.11  # Tokyo
        - 10.3.0.12  # Sydney
      routing: round-robin

# Application configuration
client_config:
  write_endpoint: redis-master.global.company.com:6379
  read_endpoint: redis-read.${AWS_REGION}.company.com:6379
  # Automatiquement rÃ©solu selon la rÃ©gion du client
```

**Code application (exemple Node.js)** :

```javascript
// redis-geo-client.js

const Redis = require('ioredis');

// Configuration gÃ©o-distribuÃ©e
const REGION = process.env.AWS_REGION || 'eu-west';
const WRITE_ENDPOINT = 'redis-master.global.company.com';
const READ_ENDPOINT = `redis-read.${REGION}.company.com`;

// Client pour writes (toujours vers master)
const writeClient = new Redis({
  host: WRITE_ENDPOINT,
  port: 6379,
  password: process.env.REDIS_PASSWORD,
  retryStrategy: (times) => Math.min(times * 50, 2000),
});

// Client pour reads (local Ã  la rÃ©gion)
const readClient = new Redis({
  host: READ_ENDPOINT,
  port: 6379,
  password: process.env.REDIS_PASSWORD,
  retryStrategy: (times) => Math.min(times * 50, 2000),
});

// Helper functions
async function write(key, value, ttl = null) {
  if (ttl) {
    await writeClient.setex(key, ttl, value);
  } else {
    await writeClient.set(key, value);
  }
}

async function read(key) {
  return await readClient.get(key);
}

// Usage
(async () => {
  // Write to master (Paris)
  await write('user:1000', JSON.stringify({ name: 'Alice' }), 3600);

  // Read from local replica (fast!)
  const userData = await read('user:1000');
  console.log('User data:', userData);

  // Latence typique:
  // EU: read ~2ms, write ~5ms
  // US: read ~2ms, write ~85ms (WAN to Paris)
  // ASIA: read ~5ms, write ~155ms (WAN to Paris)
})();
```

### Monitoring gÃ©o-distribuÃ©

```bash
#!/bin/bash
# monitor-geo-replication.sh

MASTER="10.1.0.10"
declare -A REGIONS=(
  ["eu"]="10.1.0.11 10.1.0.12 10.1.0.13"
  ["us"]="10.2.0.10 10.2.0.11 10.2.0.12"
  ["asia"]="10.3.0.10 10.3.0.11 10.3.0.12"
)

echo "=== Geo-Distributed Replication Status ==="
echo "Master: $MASTER"
echo ""

# Get master offset
MASTER_OFFSET=$(redis-cli -h $MASTER INFO replication | grep master_repl_offset | cut -d: -f2 | tr -d '\r')
echo "Master offset: $MASTER_OFFSET"
echo ""

# Check each region
for region in "${!REGIONS[@]}"; do
  echo "Region: ${region^^}"
  echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

  for replica in ${REGIONS[$region]}; do
    # Get replica info
    ROLE=$(redis-cli -h $replica INFO replication 2>/dev/null | grep "role:" | cut -d: -f2 | tr -d '\r')

    if [[ "$ROLE" == "slave" ]]; then
      OFFSET=$(redis-cli -h $replica INFO replication | grep master_repl_offset | cut -d: -f2 | tr -d '\r')
      LINK_STATUS=$(redis-cli -h $replica INFO replication | grep master_link_status | cut -d: -f2 | tr -d '\r')
      LAG_BYTES=$((MASTER_OFFSET - OFFSET))

      printf "  %-15s: offset=%d lag=%d bytes status=%s\n" $replica $OFFSET $LAG_BYTES $LINK_STATUS

      # Alert if lag > 10MB
      if [ $LAG_BYTES -gt 10485760 ]; then
        echo "    âš ï¸  WARNING: High lag!"
      fi
    else
      echo "  $replica: UNREACHABLE or WRONG ROLE"
    fi
  done
  echo ""
done
```

---

## ğŸ“Š Matrice comparative des topologies

| CritÃ¨re | Ã‰toile | ChaÃ®nÃ©e | Hybride | GÃ©o-distribuÃ©e |
|---------|--------|---------|---------|----------------|
| **ComplexitÃ©** | â­ Simple | â­â­â­ Ã‰levÃ©e | â­â­â­ Ã‰levÃ©e | â­â­â­â­ TrÃ¨s Ã©levÃ©e |
| **Latence max** | 5-10ms | 10-50ms | 5-50ms | 5-200ms |
| **ScalabilitÃ© reads** | Moyenne | Ã‰levÃ©e | Ã‰levÃ©e | TrÃ¨s Ã©levÃ©e |
| **Bandwidth master** | Ã‰levÃ© (NÃ—) | Faible (2Ã—) | Moyen | Faible (3Ã—) |
| **RÃ©silience panne** | Bonne | Moyenne | Bonne | Excellente |
| **CoÃ»t rÃ©seau** | Moyen-Ã‰levÃ© | Faible | Moyen | Faible (WAN) |
| **Failover** | Simple | Complexe | Moyen | Complexe |
| **Nombre replicas** | 2-5 | 5-20+ | 5-15 | 10-50+ |
| **Cas d'usage** | Standard | High-scale | Production | Global |

---

## ğŸ¯ Recommandations de dÃ©ploiement

### RÃ¨gles de dÃ©cision

```yaml
Choisir Ã‰TOILE si:
  - Replicas: â‰¤ 5
  - Localisation: MÃªme datacenter/rÃ©gion
  - Latence critique: <10ms uniform
  - Ã‰quipe: DevOps junior
  - Exemple: Startup, PME, application rÃ©gionale

Choisir CHAÃNÃ‰E si:
  - Replicas: > 5
  - Write throughput: Ã‰levÃ© (>50 MB/s)
  - Bandwidth: LimitÃ© ou coÃ»teux
  - Latency tolerance: 10-50ms acceptable
  - Exemple: High-traffic app, analytics replicas

Choisir HYBRIDE si:
  - Besoins mixtes: Performance + Scale
  - Multi-objectifs: Production + DR + Analytics
  - Budget: Moyen-Ã©levÃ©
  - Ã‰quipe: DevOps expÃ©rimentÃ©
  - Exemple: E-commerce mature, SaaS B2B

Choisir GÃ‰O-DISTRIBUÃ‰E si:
  - Global: Multi-continents
  - Read locality: Critique (<10ms local)
  - Write latency: TolÃ©rÃ© (50-200ms acceptable)
  - Budget: Ã‰levÃ©
  - Ã‰quipe: SRE team
  - Exemple: CDN, social media, global SaaS
```

### Checklist de dÃ©ploiement

**Avant dÃ©ploiement** :

- [ ] **Topologie documentÃ©e** : SchÃ©ma avec IPs, ports, rÃ´les
- [ ] **Calcul latence** : MesurÃ© entre chaque hop
- [ ] **Calcul bandwidth** : DimensionnÃ© selon throughput
- [ ] **Monitoring configurÃ©** : MÃ©triques par niveau
- [ ] **Runbook crÃ©Ã©** : ProcÃ©dures failover et healing
- [ ] **Tests rÃ©alisÃ©s** : Simulation pannes sur chaque niveau
- [ ] **DNS/Load balancing** : ConfigurÃ© pour read routing
- [ ] **Alerting** : Seuils dÃ©finis (lag, disconnect)
- [ ] **Backup strategy** : RDB/AOF sur replicas appropriÃ©s
- [ ] **Disaster Recovery** : Plan de restauration documentÃ©

---

## ğŸ”§ Outils de gestion de topologie

### Outil 1 : Visualisation automatique

```python
#!/usr/bin/env python3
# redis-topology-visualizer.py

import redis
import graphviz
from typing import Dict, List

def get_replication_info(host: str, port: int = 6379, password: str = None) -> Dict:
    """RÃ©cupÃ¨re les infos de rÃ©plication d'une instance"""
    r = redis.Redis(host=host, port=port, password=password, decode_responses=True)
    info = r.info('replication')
    return info

def build_topology_graph(master_host: str, password: str = None) -> graphviz.Digraph:
    """Construit le graphe de la topologie"""
    dot = graphviz.Digraph(comment='Redis Topology')
    dot.attr(rankdir='TB')

    visited = set()

    def visit_node(host: str, level: int = 0, parent: str = None):
        if host in visited:
            return
        visited.add(host)

        try:
            info = get_replication_info(host, password=password)
            role = info['role']

            # Node styling
            if role == 'master':
                dot.node(host, f"MASTER\n{host}", shape='box', style='filled', fillcolor='lightblue')
            else:
                dot.node(host, f"REPLICA L{level}\n{host}", shape='ellipse', style='filled', fillcolor='lightgreen')

            # Edge from parent
            if parent:
                lag = info.get('master_last_io_seconds_ago', 'N/A')
                dot.edge(parent, host, label=f"{lag}s lag")

            # Visit slaves
            connected_slaves = info.get('connected_slaves', 0)
            for i in range(connected_slaves):
                slave_info = info[f'slave{i}']
                slave_ip = slave_info.split(',')[0].split('=')[1]
                visit_node(slave_ip, level + 1, host)

        except Exception as e:
            dot.node(host, f"ERROR\n{host}", shape='box', style='filled', fillcolor='red')
            print(f"Error visiting {host}: {e}")

    visit_node(master_host)
    return dot

# Usage
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python redis-topology-visualizer.py <master_ip> [password]")
        sys.exit(1)

    master_ip = sys.argv[1]
    password = sys.argv[2] if len(sys.argv) > 2 else None

    graph = build_topology_graph(master_ip, password)
    graph.render('redis-topology', view=True, format='png')
    print("Topology graph saved to redis-topology.png")
```

### Outil 2 : Validation de configuration

```python
#!/usr/bin/env python3
# validate-redis-topology.py

import redis
from typing import List, Tuple
import sys

class TopologyValidator:
    def __init__(self, nodes: List[Tuple[str, int, str]]):
        """
        nodes: List of (host, port, role) tuples
        role: 'master', 'l1', 'l2', etc.
        """
        self.nodes = nodes
        self.results = []

    def validate_connectivity(self):
        """VÃ©rifie la connectivitÃ© de chaque nÅ“ud"""
        print("\n=== Connectivity Validation ===")
        for host, port, role in self.nodes:
            try:
                r = redis.Redis(host=host, port=port, socket_connect_timeout=5)
                r.ping()
                print(f"âœ… {role:8s} {host}:{port} - REACHABLE")
            except Exception as e:
                print(f"âŒ {role:8s} {host}:{port} - UNREACHABLE: {e}")
                self.results.append(('CONNECTIVITY', False, host, str(e)))

    def validate_replication(self):
        """VÃ©rifie l'Ã©tat de rÃ©plication"""
        print("\n=== Replication Validation ===")
        for host, port, role in self.nodes:
            try:
                r = redis.Redis(host=host, port=port, decode_responses=True)
                info = r.info('replication')

                actual_role = info['role']
                link_status = info.get('master_link_status', 'N/A')

                if role == 'master' and actual_role != 'master':
                    print(f"âŒ {host}:{port} - Expected master, got {actual_role}")
                    self.results.append(('ROLE', False, host, f"Expected master, got {actual_role}"))
                elif role.startswith('l') and actual_role != 'slave':
                    print(f"âŒ {host}:{port} - Expected slave, got {actual_role}")
                    self.results.append(('ROLE', False, host, f"Expected slave, got {actual_role}"))
                elif actual_role == 'slave' and link_status != 'up':
                    print(f"âš ï¸  {host}:{port} - Link status: {link_status}")
                    self.results.append(('LINK', False, host, f"Link status: {link_status}"))
                else:
                    print(f"âœ… {role:8s} {host}:{port} - OK (role={actual_role}, link={link_status})")

            except Exception as e:
                print(f"âŒ {host}:{port} - Error: {e}")
                self.results.append(('REPLICATION', False, host, str(e)))

    def validate_lag(self, max_lag: int = 10):
        """VÃ©rifie le lag de rÃ©plication"""
        print(f"\n=== Lag Validation (max: {max_lag}s) ===")
        for host, port, role in self.nodes:
            if role == 'master':
                continue

            try:
                r = redis.Redis(host=host, port=port, decode_responses=True)
                info = r.info('replication')

                if info['role'] == 'slave':
                    lag = info.get('master_last_io_seconds_ago', 999)
                    if lag > max_lag:
                        print(f"âš ï¸  {host}:{port} - High lag: {lag}s")
                        self.results.append(('LAG', False, host, f"Lag: {lag}s"))
                    else:
                        print(f"âœ… {host}:{port} - Lag: {lag}s")

            except Exception as e:
                print(f"âŒ {host}:{port} - Error: {e}")

    def report(self):
        """Affiche le rapport final"""
        print("\n" + "="*60)
        print("VALIDATION REPORT")
        print("="*60)

        errors = [r for r in self.results if not r[1]]
        if not errors:
            print("âœ… All validations passed!")
            return 0
        else:
            print(f"âŒ {len(errors)} error(s) found:")
            for check_type, _, host, message in errors:
                print(f"  [{check_type}] {host}: {message}")
            return 1

# Usage example
if __name__ == "__main__":
    # DÃ©finir la topologie attendue
    topology = [
        ("10.0.1.10", 6379, "master"),
        ("10.0.1.11", 6379, "l1"),
        ("10.0.1.12", 6379, "l1"),
        ("10.0.1.13", 6379, "l2"),
        ("10.0.1.14", 6379, "l2"),
    ]

    validator = TopologyValidator(topology)
    validator.validate_connectivity()
    validator.validate_replication()
    validator.validate_lag(max_lag=10)

    exit_code = validator.report()
    sys.exit(exit_code)
```

---

## ğŸ“ Points clÃ©s Ã  retenir

1. **Ã‰toile = SimplicitÃ©** : Default choice pour <5 replicas, mÃªme rÃ©gion
2. **ChaÃ®ne = ScalabilitÃ©** : Optimal pour >5 replicas, rÃ©duction bandwidth
3. **Hybride = FlexibilitÃ©** : Best of both worlds, production rÃ©elle
4. **GÃ©o = Global** : Lecture locale, Ã©criture centrale, complexe
5. **Latence cumulÃ©e** : Chaque niveau ajoute 5-20ms
6. **Bandwidth master** : Ã‰toile coÃ»te NÃ—, chaÃ®ne coÃ»te 2-3Ã—
7. **Orphelins** : Surveiller et auto-heal replicas L2 si L1 down
8. **Testing essentiel** : Simuler pannes Ã  chaque niveau
9. **Documentation** : SchÃ©mas et runbooks impÃ©ratifs
10. **Monitoring granulaire** : MÃ©triques par niveau et par rÃ©gion

---

## ğŸ”— RÃ©fÃ©rences

- [Redis Replication Documentation](https://redis.io/docs/management/replication/)
- [Architecting for Scale (Redis Patterns)](https://redis.io/topics/patterns)
- [Multi-DC Replication Best Practices](https://redis.com/redis-best-practices/communication-patterns/multi-dc-replication/)

---

**Section suivante** : [10.3 Redis Sentinel : Monitoring et Failover automatique](./03-redis-sentinel-monitoring-failover.md)

â­ï¸ [Redis Sentinel : Monitoring et Failover automatique](/10-architecture-haute-disponibilite/03-redis-sentinel-monitoring-failover.md)
