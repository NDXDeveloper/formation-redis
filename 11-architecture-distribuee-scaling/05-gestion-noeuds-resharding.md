ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 11.5 Gestion des nÅ“uds (ajout, suppression, resharding)

## Introduction

La gestion dynamique des nÅ“uds constitue l'une des fonctionnalitÃ©s clÃ©s de Redis Cluster, permettant l'adaptation du cluster aux besoins Ã©volutifs de capacitÃ© et de performance. Contrairement aux systÃ¨mes distribuÃ©s traditionnels nÃ©cessitant un arrÃªt complet pour modification de topologie, Redis Cluster permet d'ajouter, de supprimer et de redistribuer les donnÃ©es entre nÅ“uds sans interruption de service.

Cette section dÃ©taille les opÃ©rations de gestion du cycle de vie des nÅ“uds, du resharding stratÃ©gique, et des procÃ©dures de maintenance permettant d'assurer la disponibilitÃ© continue du cluster tout en optimisant la distribution des donnÃ©es.

## Concepts prÃ©liminaires

### Ã‰tat d'un nÅ“ud dans le cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Cycle de vie d'un nÅ“ud                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   ISOLÃ‰     â”‚  NÅ“ud dÃ©marrÃ© mais pas dans le cluster
    â”‚ (isolated)  â”‚  cluster_known_nodes: 1 (lui-mÃªme)
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ CLUSTER MEET <ip> <port>
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   MEMBRE    â”‚  NÅ“ud intÃ©grÃ©, mais sans slot
    â”‚  (member)   â”‚  cluster_known_nodes: N
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  cluster_slots_assigned: 0
           â”‚
           â”‚ Assignation de slots (ADDSLOTS/SETSLOT)
           â”‚ ou Failover (si replica)
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   ACTIF     â”‚  Master avec slots ou Replica fonctionnelle
    â”‚  (active)   â”‚  Sert des requÃªtes
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ DÃ©tection de panne ou CLUSTER FORGET
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    FAIL     â”‚  NÅ“ud dÃ©tectÃ© comme en panne
    â”‚   (failed)  â”‚  Plus de communication possible
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ NÅ“ud redÃ©marre ou est retirÃ©
           â”‚
           â–¼
    [Retour Ã  ISOLÃ‰ ou SUPPRIMÃ‰]
```

### RÃ´les des nÅ“uds

```
MASTER (MaÃ®tre)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ PossÃ¨de des hash slots (portion du keyspace)
â€¢ Accepte les lectures et Ã©critures
â€¢ RÃ©plique vers ses replicas
â€¢ Peut participer au vote lors d'Ã©lections
â€¢ Doit avoir au moins 1 replica pour HA

REPLICA (Esclave)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Ne possÃ¨de pas de slots directement
â€¢ RÃ©plique de faÃ§on asynchrone un master
â€¢ Lecture seule (sauf si cluster-replica-no-failover no)
â€¢ Peut devenir master lors d'un failover
â€¢ Participe au protocole Gossip

ORPHAN MASTER (MaÃ®tre orphelin)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Master sans replica
â€¢ Point de dÃ©faillance unique pour ses slots
â€¢ Ã‰tat Ã  Ã©viter en production
â€¢ Redis peut migrer des replicas automatiquement

ORPHAN REPLICA (Replica orpheline)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Replica dont le master est tombÃ© dÃ©finitivement
â€¢ Ne sert Ã  rien tant qu'elle n'est pas promue ou rÃ©assignÃ©e
â€¢ Ã€ rÃ©assigner manuellement Ã  un nouveau master
```

## Ajout de nÅ“uds au cluster

### Ajout d'un master (avec redistribution de slots)

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROCÃ‰DURE COMPLÃˆTE : AJOUT D'UN MASTER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# CONTEXTE INITIAL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Cluster existant : 3 masters (A, B, C) + 3 replicas
# Objectif : Ajouter un 4Ã¨me master (D) et redistribuer les slots

# Topologie initiale :
# Master A: slots 0-5460     (33.3%)
# Master B: slots 5461-10922 (33.3%)
# Master C: slots 10923-16383 (33.4%)
# Total: 16384 slots

# Topologie cible :
# Master A: slots 0-4095     (25%)
# Master B: slots 4096-8191  (25%)
# Master C: slots 8192-12287 (25%)
# Master D: slots 12288-16383 (25%) â† Nouveau
# Total: 16384 slots


# Ã‰TAPE 1 : PrÃ©parer le nouveau nÅ“ud D
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Sur le serveur du nÅ“ud D (192.168.1.16)
ssh 192.168.1.16

# Installer et configurer Redis (si pas dÃ©jÃ  fait)
sudo apt install redis-server

# Configuration minimale
cat <<EOF | sudo tee /etc/redis/redis.conf
port 6379
bind 192.168.1.16
cluster-enabled yes
cluster-config-file /var/lib/redis/nodes.conf
cluster-node-timeout 15000
appendonly yes
dir /var/lib/redis
EOF

# DÃ©marrer Redis
sudo systemctl restart redis
sudo systemctl enable redis

# VÃ©rifier que le nÅ“ud est isolÃ©
redis-cli -h 192.168.1.16 CLUSTER INFO
# cluster_state:fail (normal, pas encore dans le cluster)
# cluster_known_nodes:1


# Ã‰TAPE 2 : Ajouter le nÅ“ud au cluster (MEET)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Depuis n'importe quelle machine (ou un nÅ“ud existant)
redis-cli --cluster add-node 192.168.1.16:6379 192.168.1.10:6379

# Syntaxe : add-node <new-node> <existing-node>
# Le nouveau nÅ“ud contacte le nÅ“ud existant et rejoint le cluster

# Output attendu :
# >>> Adding node 192.168.1.16:6379 to cluster 192.168.1.10:6379
# >>> Performing Cluster Check
# [OK] All nodes agree about slots configuration.
# >>> Send CLUSTER MEET to node 192.168.1.16:6379
# [OK] New node added correctly.


# Ã‰TAPE 3 : VÃ©rifier l'intÃ©gration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli -h 192.168.1.16 CLUSTER INFO
# cluster_state:ok (maintenant dans le cluster)
# cluster_known_nodes:4 (A, B, C, D)
# cluster_slots_assigned:16384 (tous assignÃ©s aux autres)

redis-cli -h 192.168.1.16 CLUSTER NODES
# Devrait lister les 4 nÅ“uds
# Node D apparaÃ®t comme "master" mais avec 0 slots

redis-cli --cluster check 192.168.1.10:6379
# 192.168.1.10:6379 -> 5461 slots
# 192.168.1.11:6379 -> 5462 slots
# 192.168.1.12:6379 -> 5461 slots
# 192.168.1.16:6379 -> 0 slots      â† Nouveau nÅ“ud sans slots


# Ã‰TAPE 4 : Calculer la nouvelle distribution
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Objectif : Distribution Ã©quitable Ã  25% chacun (4096 slots)
#
# Transferts nÃ©cessaires :
# - De A (5461 slots) â†’ A garde 4096, transfÃ¨re 1365 Ã  D
# - De B (5462 slots) â†’ B garde 4096, transfÃ¨re 1366 Ã  D
# - De C (5461 slots) â†’ C garde 4096, transfÃ¨re 1365 Ã  D
#
# Total vers D : 1365 + 1366 + 1365 = 4096 slots âœ“


# Ã‰TAPE 5 : Resharding automatique
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Option A : Redistribution automatique Ã©quilibrÃ©e
redis-cli --cluster rebalance 192.168.1.10:6379 \
    --cluster-threshold 1 \
    --cluster-use-empty-masters

# Cette commande :
# 1. Calcule la distribution optimale
# 2. Identifie les transferts nÃ©cessaires
# 3. ExÃ©cute le resharding automatiquement
# 4. Ã‰quilibre pour que chaque nÅ“ud ait ~25% des slots

# Output :
# >>> Performing Cluster Check
# >>> Rebalancing across 4 nodes.
# Moving 1365 slots from 192.168.1.10:6379 to 192.168.1.16:6379
# Moving 1366 slots from 192.168.1.11:6379 to 192.168.1.16:6379
# Moving 1365 slots from 192.168.1.12:6379 to 192.168.1.16:6379


# Option B : Resharding manuel avec contrÃ´le fin
redis-cli --cluster reshard 192.168.1.10:6379 \
    --cluster-from <node-a-id>,<node-b-id>,<node-c-id> \
    --cluster-to <node-d-id> \
    --cluster-slots 4096 \
    --cluster-yes \
    --cluster-pipeline 10

# ParamÃ¨tres :
# --cluster-from : Liste des nÅ“uds sources (sÃ©parÃ©s par virgule)
# --cluster-to : NÅ“ud destination
# --cluster-slots : Nombre total de slots Ã  transfÃ©rer
# --cluster-yes : Pas de confirmation interactive
# --cluster-pipeline : Nombre de clÃ©s migrÃ©es en parallÃ¨le


# Ã‰TAPE 6 : Monitoring du resharding
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Dans un terminal sÃ©parÃ©, surveiller la progression
watch -n 2 'redis-cli --cluster check 192.168.1.10:6379'

# MÃ©triques Ã  surveiller :
# - Nombre de slots par nÅ“ud
# - Nombre de clÃ©s en migration
# - Ã‰tat du cluster (cluster_state:ok)

# VÃ©rifier les redirections pendant le resharding
redis-cli -h 192.168.1.10 -c GET some:key
# Peut retourner des -MOVED pendant la migration


# Ã‰TAPE 7 : Validation post-resharding
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# VÃ©rifier la distribution finale
redis-cli --cluster check 192.168.1.10:6379

# Output attendu :
# 192.168.1.10:6379 -> 4096 slots (25%)
# 192.168.1.11:6379 -> 4096 slots (25%)
# 192.168.1.12:6379 -> 4096 slots (25%)
# 192.168.1.16:6379 -> 4096 slots (25%)
# [OK] All 16384 slots covered.

# VÃ©rifier l'Ã©tat du cluster
redis-cli -h 192.168.1.16 CLUSTER INFO | grep cluster_state
# cluster_state:ok

# Tester l'accÃ¨s aux donnÃ©es
redis-cli -c -h 192.168.1.16 GET test:key
# Devrait fonctionner avec redirection automatique si nÃ©cessaire


# Ã‰TAPE 8 : Ajouter une replica pour le nouveau master
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# PrÃ©parer le nÅ“ud replica (192.168.1.17)
ssh 192.168.1.17
# [Configuration identique Ã  l'Ã©tape 1]

# Ajouter comme replica du nouveau master D
redis-cli --cluster add-node 192.168.1.17:6379 192.168.1.10:6379 \
    --cluster-slave \
    --cluster-master-id <node-d-id>

# RÃ©cupÃ©rer le node-d-id :
NODE_D_ID=$(redis-cli -h 192.168.1.16 CLUSTER MYID)
echo $NODE_D_ID

redis-cli --cluster add-node 192.168.1.17:6379 192.168.1.10:6379 \
    --cluster-slave \
    --cluster-master-id $NODE_D_ID

# Output :
# >>> Adding node 192.168.1.17:6379 to cluster 192.168.1.10:6379
# >>> Performing Cluster Check
# >>> Check if node 192.168.1.16:6379 is a master...
# >>> Configure node as replica of 192.168.1.16:6379
# [OK] New node added correctly.


# Ã‰TAPE 9 : Validation finale
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster check 192.168.1.10:6379

# Output final attendu :
# Master A (192.168.1.10) -> 4096 slots | 1 replica
# Master B (192.168.1.11) -> 4096 slots | 1 replica
# Master C (192.168.1.12) -> 4096 slots | 1 replica
# Master D (192.168.1.16) -> 4096 slots | 1 replica â† Nouveau
# [OK] All 16384 slots covered.
```

### SchÃ©ma du processus d'ajout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Processus d'ajout d'un master avec slots            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰tat initial (3 masters)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A        Master B        Master C
    [0-5460]       [5461-10922]   [10923-16383]
       â”‚               â”‚               â”‚
    Replica A1     Replica B1      Replica C1


Ã‰tape 1 : Ajout du nÅ“ud D
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A        Master B        Master C      Master D
    [0-5460]       [5461-10922]   [10923-16383]    [VIDE]
       â”‚               â”‚               â”‚              â”‚
    Replica A1     Replica B1      Replica C1        X


Ã‰tape 2 : Resharding (migration de slots)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A        Master B        Master C      Master D
    [0-5460]       [5461-10922]   [10923-16383]    [VIDE]
       â”‚               â”‚               â”‚              â”‚
       â”‚               â”‚               â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€> 1365 slots â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
       â”‚               â””â”€â”€â”€â”€â”€â”€â”€> 1366 slots â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
       â”‚               â”‚               â””â”€â”€â”€> 1365 â”€â”€â”€>â”‚


Ã‰tape 3 : Ã‰tat aprÃ¨s resharding
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A        Master B        Master C      Master D
    [0-4095]       [4096-8191]    [8192-12287]  [12288-16383]
       â”‚               â”‚               â”‚              â”‚
    Replica A1     Replica B1      Replica C1     Replica D1


Distribution : 4 Ã— 4096 = 16384 slots (25% chacun) âœ“
```

### Ajout d'une replica (sans resharding)

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AJOUT D'UNE REPLICA Ã€ UN MASTER EXISTANT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Contexte : Master sans replica ou ajout d'une 2Ã¨me replica
# Pas de resharding nÃ©cessaire (les replicas ne possÃ¨dent pas de slots)


# Ã‰TAPE 1 : PrÃ©parer le nÅ“ud replica
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Configuration identique aux masters (cluster-enabled yes)
ssh 192.168.1.20
sudo systemctl start redis


# Ã‰TAPE 2 : Identifier le master cible
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Lister les masters
redis-cli -h 192.168.1.10 CLUSTER NODES | grep master

# Output :
# a1b2c3d4... 192.168.1.10:6379 master - 0 1234567890 1 connected 0-5460
# e5f6g7h8... 192.168.1.11:6379 master - 0 1234567891 2 connected 5461-10922
# ...

# Choisir le master (ex: 192.168.1.10)
# RÃ©cupÃ©rer son Node ID
MASTER_ID=$(redis-cli -h 192.168.1.10 CLUSTER MYID)
echo "Master ID: $MASTER_ID"


# Ã‰TAPE 3 : Ajouter la replica
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster add-node 192.168.1.20:6379 192.168.1.10:6379 \
    --cluster-slave \
    --cluster-master-id $MASTER_ID

# Alternative : Laisser Redis choisir automatiquement le master le moins rÃ©pliquÃ©
redis-cli --cluster add-node 192.168.1.20:6379 192.168.1.10:6379 \
    --cluster-slave
# Redis assignera la replica au master ayant le moins de replicas


# Ã‰TAPE 4 : VÃ©rification
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# VÃ©rifier le rÃ´le
redis-cli -h 192.168.1.20 INFO replication
# role:slave
# master_host:192.168.1.10
# master_port:6379
# master_link_status:up

# VÃ©rifier depuis le cluster
redis-cli -h 192.168.1.10 CLUSTER NODES | grep 192.168.1.20
# Devrait montrer : slave, master_id = $MASTER_ID

# VÃ©rifier la rÃ©plication
redis-cli -h 192.168.1.10 INFO replication
# connected_slaves:2 (si c'Ã©tait la 2Ã¨me replica)
```

## Suppression de nÅ“uds du cluster

### Suppression d'une replica (simple)

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SUPPRESSION D'UNE REPLICA (PAS DE RESHARDING)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Les replicas ne possÃ¨dent pas de slots, donc suppression simple


# Ã‰TAPE 1 : Identifier la replica Ã  supprimer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli -h 192.168.1.10 CLUSTER NODES | grep slave

# Output :
# r1s2t3u4... 192.168.1.13:6379 slave a1b2c3d4... 0 1234567890 1 connected
# r5s6t7u8... 192.168.1.20:6379 slave a1b2c3d4... 0 1234567891 1 connected

# DÃ©cision : Supprimer la replica 192.168.1.20
REPLICA_ID=$(redis-cli -h 192.168.1.20 CLUSTER MYID)
echo "Replica ID to remove: $REPLICA_ID"


# Ã‰TAPE 2 : Supprimer du cluster
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster del-node 192.168.1.10:6379 $REPLICA_ID

# Syntaxe : del-node <any-cluster-node> <node-id-to-remove>

# Output :
# >>> Removing node r5s6t7u8... from cluster 192.168.1.10:6379
# >>> Sending CLUSTER FORGET messages to the cluster...
# >>> SHUTDOWN the node.


# Ã‰TAPE 3 : ArrÃªter le service Redis sur le nÅ“ud supprimÃ©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ssh 192.168.1.20
sudo systemctl stop redis
sudo systemctl disable redis

# Optionnel : Nettoyer les donnÃ©es
sudo rm -rf /var/lib/redis/*


# Ã‰TAPE 4 : Validation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli -h 192.168.1.10 CLUSTER NODES | grep 192.168.1.20
# Ne devrait rien retourner (nÅ“ud absent)

redis-cli --cluster check 192.168.1.10:6379
# [OK] All 16384 slots covered.
# Replica 192.168.1.20 ne devrait plus apparaÃ®tre
```

### Suppression d'un master (avec redistribution)

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SUPPRESSION D'UN MASTER (RESHARDING OBLIGATOIRE)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Contexte : Retirer Master D et redistribuer ses slots
# Topologie actuelle : 4 masters (A, B, C, D) avec 4096 slots chacun
# Topologie cible : 3 masters (A, B, C) avec ~5461 slots chacun


# Ã‰TAPE 1 : VÃ©rifier l'Ã©tat du master Ã  supprimer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli -h 192.168.1.16 CLUSTER INFO
# cluster_slots_assigned: devrait Ãªtre > 0

redis-cli --cluster check 192.168.1.10:6379 | grep 192.168.1.16
# 192.168.1.16:6379 -> 4096 slots | 1 replica

MASTER_D_ID=$(redis-cli -h 192.168.1.16 CLUSTER MYID)
echo "Master D ID: $MASTER_D_ID"


# Ã‰TAPE 2 : Supprimer d'abord la replica du master D
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Identifier la replica de D
redis-cli -h 192.168.1.10 CLUSTER NODES | grep "slave $MASTER_D_ID"
# r9s0t1u2... 192.168.1.17:6379 slave <master-d-id>...

REPLICA_D_ID=$(redis-cli -h 192.168.1.17 CLUSTER MYID)

# Supprimer la replica
redis-cli --cluster del-node 192.168.1.10:6379 $REPLICA_D_ID

# ArrÃªter le service
ssh 192.168.1.17
sudo systemctl stop redis


# Ã‰TAPE 3 : TransfÃ©rer TOUS les slots du master D
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Option A : Redistribuer vers tous les autres masters
redis-cli --cluster reshard 192.168.1.10:6379 \
    --cluster-from $MASTER_D_ID \
    --cluster-to all \
    --cluster-slots 4096 \
    --cluster-yes \
    --cluster-pipeline 10

# Cette commande va :
# 1. Distribuer les 4096 slots de D vers A, B, C
# 2. A, B, C recevront chacun ~1365 slots
# 3. Nouvelle rÃ©partition : A=5461, B=5461, C=5462 slots

# Option B : Redistribuer vers un master spÃ©cifique
# NODE_A_ID=$(redis-cli -h 192.168.1.10 CLUSTER MYID)
# redis-cli --cluster reshard 192.168.1.10:6379 \
#     --cluster-from $MASTER_D_ID \
#     --cluster-to $NODE_A_ID \
#     --cluster-slots 4096 \
#     --cluster-yes


# Ã‰TAPE 4 : VÃ©rifier que le master D n'a plus de slots
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster check 192.168.1.10:6379 | grep 192.168.1.16
# 192.168.1.16:6379 -> 0 keys | 0 slots | 0 replicas

# VÃ©rifier localement
redis-cli -h 192.168.1.16 CLUSTER INFO | grep cluster_slots_assigned
# cluster_slots_assigned:0 âœ“


# Ã‰TAPE 5 : Supprimer le master D du cluster
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster del-node 192.168.1.10:6379 $MASTER_D_ID

# Output :
# >>> Removing node <master-d-id> from cluster 192.168.1.10:6379
# >>> Sending CLUSTER FORGET messages to the cluster...
# >>> SHUTDOWN the node.


# Ã‰TAPE 6 : ArrÃªter le service
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ssh 192.168.1.16
sudo systemctl stop redis
sudo systemctl disable redis

# Optionnel : Nettoyer
sudo rm -rf /var/lib/redis/*


# Ã‰TAPE 7 : Validation finale
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster check 192.168.1.10:6379

# Output attendu :
# 192.168.1.10:6379 -> 5461 slots (33.3%)
# 192.168.1.11:6379 -> 5461 slots (33.3%)
# 192.168.1.12:6379 -> 5462 slots (33.4%)
# [OK] All 16384 slots covered.
# â† Master D absent

# Tester l'accÃ¨s aux donnÃ©es
redis-cli -c -h 192.168.1.10 GET test:key
# Devrait fonctionner normalement
```

### SchÃ©ma du processus de suppression

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Processus de suppression d'un master                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰tat initial (4 masters)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A      Master B      Master C      Master D
    [0-4095]     [4096-8191]   [8192-12287]  [12288-16383]
       â”‚             â”‚             â”‚              â”‚
    Replica A1   Replica B1    Replica C1     Replica D1


Ã‰tape 1 : Supprimer Replica D1
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A      Master B      Master C      Master D
    [0-4095]     [4096-8191]   [8192-12287]  [12288-16383]
       â”‚             â”‚             â”‚              â”‚
    Replica A1   Replica B1    Replica C1        X (supprimÃ©e)


Ã‰tape 2 : TransfÃ©rer les slots de D
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A      Master B      Master C      Master D
    [0-4095]     [4096-8191]   [8192-12287]  [12288-16383]
       â”‚             â”‚             â”‚              â”‚
       â”‚<â”€â”€â”€â”€â”€â”€ 1365 slots â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚<â”€â”€â”€â”€â”€â”€ 1366 slots â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚             â”‚             â”‚<â”€ 1365 slots â”˜


Ã‰tape 3 : Master D vidÃ©, prÃªt Ã  Ãªtre supprimÃ©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A      Master B      Master C      Master D
    [0-5460]     [5461-10922]  [10923-16383]   [VIDE]
       â”‚             â”‚             â”‚              X
    Replica A1   Replica B1    Replica C1


Ã‰tape 4 : Suppression de Master D
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Master A      Master B      Master C
    [0-5460]     [5461-10922]  [10923-16383]
       â”‚             â”‚             â”‚
    Replica A1   Replica B1    Replica C1

Retour Ã  3 masters (33.3% chacun) âœ“
```

## Resharding avancÃ©

### StratÃ©gies de resharding

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            StratÃ©gies de Resharding                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 1. RESHARDING Ã‰QUILIBRÃ‰ (Rebalance)                         â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                         â”‚
â”‚    Objectif : Distribution uniforme sur tous les nÅ“uds      â”‚
â”‚    Cas d'usage : AprÃ¨s ajout/suppression de nÅ“uds           â”‚
â”‚                                                             â”‚
â”‚    redis-cli --cluster rebalance <node>                     â”‚
â”‚        --cluster-threshold 2                                â”‚
â”‚        --cluster-use-empty-masters                          â”‚
â”‚                                                             â”‚
â”‚    RÃ©sultat : Chaque master a ~(16384 / N) slots            â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 2. RESHARDING CIBLÃ‰ (Targeted)                              â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                              â”‚
â”‚    Objectif : DÃ©placer des slots spÃ©cifiques                â”‚
â”‚    Cas d'usage : Corriger un hot spot, dÃ©charger un nÅ“ud    â”‚
â”‚                                                             â”‚
â”‚    redis-cli --cluster reshard <node>                       â”‚
â”‚        --cluster-from <source-node-id>                      â”‚
â”‚        --cluster-to <target-node-id>                        â”‚
â”‚        --cluster-slots <number>                             â”‚
â”‚                                                             â”‚
â”‚    RÃ©sultat : Transfert prÃ©cis d'un nombre de slots         â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 3. RESHARDING PAR HOT SPOTS                                 â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                             â”‚
â”‚    Objectif : Redistribuer les slots les plus chargÃ©s       â”‚
â”‚    Cas d'usage : NÅ“ud saturÃ© par quelques slots             â”‚
â”‚                                                             â”‚
â”‚    Analyse prÃ©alable :                                      â”‚
â”‚    for i in {0..16383}; do                                  â”‚
â”‚        count=$(redis-cli CLUSTER COUNTKEYSINSLOT $i)        â”‚
â”‚        echo "$i:$count"                                     â”‚
â”‚    done | sort -t: -k2 -n -r | head -20                     â”‚
â”‚                                                             â”‚
â”‚    Puis resharding manuel des slots identifiÃ©s              â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 4. RESHARDING PROGRESSIF (Incremental)                      â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â”‚
â”‚    Objectif : Migration par petits lots pour limiter impact â”‚
â”‚    Cas d'usage : Production avec charge Ã©levÃ©e              â”‚
â”‚                                                             â”‚
â”‚    for batch in {1..10}; do                                 â”‚
â”‚        redis-cli --cluster reshard <node>                   â”‚
â”‚            --cluster-slots 100                              â”‚
â”‚            --cluster-pipeline 5                             â”‚
â”‚        sleep 60  # Pause entre les lots                     â”‚
â”‚    done                                                     â”‚
â”‚                                                             â”‚
â”‚    RÃ©sultat : Migration de 1000 slots en 10 lots de 100     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Resharding manuel avancÃ©

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESHARDING MANUEL AVEC CONTRÃ”LE TOTAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ScÃ©nario : DÃ©placer les slots 8000-8099 de Node B vers Node A


# Ã‰TAPE 1 : Identifier les nÅ“uds source et destination
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SOURCE_NODE="192.168.1.11"  # Node B
TARGET_NODE="192.168.1.10"  # Node A

SOURCE_ID=$(redis-cli -h $SOURCE_NODE CLUSTER MYID)
TARGET_ID=$(redis-cli -h $TARGET_NODE CLUSTER MYID)

echo "Source: $SOURCE_NODE ($SOURCE_ID)"
echo "Target: $TARGET_NODE ($TARGET_ID)"


# Ã‰TAPE 2 : Marquer les slots en migration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Pour chaque slot Ã  migrer
for slot in {8000..8099}; do
    # Sur le nÅ“ud source : marquer comme MIGRATING
    redis-cli -h $SOURCE_NODE CLUSTER SETSLOT $slot MIGRATING $TARGET_ID

    # Sur le nÅ“ud destination : marquer comme IMPORTING
    redis-cli -h $TARGET_NODE CLUSTER SETSLOT $slot IMPORTING $SOURCE_ID
done

echo "Slots 8000-8099 marked for migration"


# Ã‰TAPE 3 : Migrer les clÃ©s slot par slot
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

for slot in {8000..8099}; do
    echo "Migrating slot $slot..."

    # Obtenir toutes les clÃ©s du slot
    keys=$(redis-cli -h $SOURCE_NODE CLUSTER GETKEYSINSLOT $slot 1000)

    # Si le slot contient des clÃ©s, les migrer
    if [ ! -z "$keys" ]; then
        for key in $keys; do
            redis-cli -h $SOURCE_NODE MIGRATE \
                $TARGET_NODE 6379 "$key" 0 5000
        done
    fi

    echo "Slot $slot migrated (or was empty)"
done


# Ã‰TAPE 4 : Finaliser la migration (changer ownership)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

for slot in {8000..8099}; do
    # Sur TOUS les nÅ“uds du cluster, dÃ©clarer le nouveau propriÃ©taire
    redis-cli -h $SOURCE_NODE CLUSTER SETSLOT $slot NODE $TARGET_ID
    redis-cli -h $TARGET_NODE CLUSTER SETSLOT $slot NODE $TARGET_ID

    # Optionnel : sur les autres nÅ“uds aussi
    redis-cli -h 192.168.1.12 CLUSTER SETSLOT $slot NODE $TARGET_ID
done

echo "Migration finalized"


# Ã‰TAPE 5 : VÃ©rification
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster check 192.168.1.10:6379 | grep -E "192.168.1.10|192.168.1.11"

# VÃ©rifier que les slots ont changÃ© de propriÃ©taire
redis-cli -h 192.168.1.10 CLUSTER NODES | grep "myself" | grep "8000-8099"
# Devrait montrer que Node A possÃ¨de maintenant 8000-8099
```

### Optimisation du resharding

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TECHNIQUES D'OPTIMISATION DU RESHARDING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


# 1. PIPELINE : Migrer plusieurs clÃ©s en parallÃ¨le
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Sans pipeline (lent)
redis-cli --cluster reshard 192.168.1.10:6379 \
    --cluster-slots 1000

# Avec pipeline (plus rapide)
redis-cli --cluster reshard 192.168.1.10:6379 \
    --cluster-slots 1000 \
    --cluster-pipeline 20  # Migrer 20 clÃ©s en parallÃ¨le

# Impact :
# - Sans pipeline : ~10 clÃ©s/sec (RTT Ã— nombre de clÃ©s)
# - Avec pipeline=20 : ~200 clÃ©s/sec (RTT amortisÃ©)


# 2. TIMEOUT : Ajuster le timeout de migration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster reshard 192.168.1.10:6379 \
    --cluster-timeout 60000  # 60 secondes (dÃ©faut: 15s)

# Utiliser un timeout plus long pour :
# - Grosses clÃ©s (>1MB)
# - RÃ©seau lent ou latence Ã©levÃ©e
# - Charge du cluster Ã©levÃ©e


# 3. REPLACE : Ã‰craser les clÃ©s existantes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster reshard 192.168.1.10:6379 \
    --cluster-slots 1000 \
    --cluster-replace  # Remplacer si clÃ© existe dÃ©jÃ 

# Attention : Peut causer des pertes de donnÃ©es si utilisÃ© incorrectement


# 4. COPY : Mode non-destructif (Redis 7+)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# MIGRATE avec option COPY
redis-cli -h 192.168.1.10 MIGRATE 192.168.1.11 6379 "mykey" 0 5000 COPY

# La clÃ© est copiÃ©e mais pas supprimÃ©e de la source
# Utile pour tester avant de finaliser


# 5. Resharding par lots avec monitoring
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

#!/bin/bash
# reshard-progressive.sh

TOTAL_SLOTS=1000
BATCH_SIZE=100
PAUSE_SECONDS=30

for ((i=0; i<$TOTAL_SLOTS; i+=$BATCH_SIZE)); do
    echo "Batch $((i/$BATCH_SIZE + 1)): Migrating $BATCH_SIZE slots..."

    # Migrer un lot
    redis-cli --cluster reshard 192.168.1.10:6379 \
        --cluster-from <source-id> \
        --cluster-to <target-id> \
        --cluster-slots $BATCH_SIZE \
        --cluster-yes \
        --cluster-pipeline 10

    # Pause pour laisser le cluster se stabiliser
    echo "Pausing for $PAUSE_SECONDS seconds..."
    sleep $PAUSE_SECONDS

    # VÃ©rifier l'Ã©tat
    redis-cli -h 192.168.1.10 CLUSTER INFO | grep cluster_state

    echo "Batch completed. Progress: $((i+BATCH_SIZE))/$TOTAL_SLOTS slots"
    echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
done

echo "Resharding completed!"
```

## OpÃ©rations de maintenance avancÃ©es

### RÃ©assignation de replicas

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CHANGER LE MASTER D'UNE REPLICA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ScÃ©nario : Replica R1 rÃ©plique Master A
#            Objectif : R1 doit rÃ©pliquer Master B


# Ã‰TAPE 1 : Identifier la replica et les masters
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

REPLICA_NODE="192.168.1.13"
OLD_MASTER="192.168.1.10"  # Master A
NEW_MASTER="192.168.1.11"  # Master B

NEW_MASTER_ID=$(redis-cli -h $NEW_MASTER CLUSTER MYID)


# Ã‰TAPE 2 : Changer le master de la replica
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli -h $REPLICA_NODE CLUSTER REPLICATE $NEW_MASTER_ID

# Cette commande :
# 1. ArrÃªte la rÃ©plication avec l'ancien master
# 2. Vide les donnÃ©es actuelles de la replica
# 3. DÃ©marre la rÃ©plication complÃ¨te avec le nouveau master
# 4. Synchronise toutes les donnÃ©es du nouveau master


# Ã‰TAPE 3 : VÃ©rification
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli -h $REPLICA_NODE INFO replication
# role:slave
# master_host:192.168.1.11  â† Nouveau master
# master_port:6379
# master_link_status:up

redis-cli -h $NEW_MASTER INFO replication
# connected_slaves:2  â† +1 replica

redis-cli -h $OLD_MASTER INFO replication
# connected_slaves:0  â† -1 replica


# Ã‰TAPE 4 : VÃ©rifier la santÃ© du cluster
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster check 192.168.1.10:6379
# Devrait montrer la nouvelle topologie
```

### Ã‰quilibrage automatique des replicas

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REDISTRIBUTION AUTOMATIQUE DES REPLICAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Redis peut automatiquement migrer des replicas vers masters orphelins


# Configuration (redis.conf)
cluster-migration-barrier 1
# Minimum de replicas Ã  garder avant migration automatique

cluster-allow-replica-migration yes
# Autoriser la migration automatique (dÃ©faut: yes)


# ScÃ©nario dÃ©clenchant la migration automatique :
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#
# Ã‰tat initial :
# Master A : 2 replicas (R1, R2)
# Master B : 0 replicas (orphan)
# Master C : 1 replica (R3)
#
# Action automatique de Redis :
# Master A : 1 replica (R1) â† R2 migrÃ©e automatiquement
# Master B : 1 replica (R2) â† RÃ©cupÃ¨re une replica
# Master C : 1 replica (R3)


# Forcer une migration manuelle de replica
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Identifier une replica "en trop"
redis-cli -h 192.168.1.10 INFO replication
# connected_slaves:2 (R1, R2)

# Identifier un master orphelin
redis-cli --cluster check 192.168.1.10:6379 | grep "0 slaves"
# Master B : 0 slaves

# DÃ©placer R2 vers Master B
MASTER_B_ID=$(redis-cli -h 192.168.1.11 CLUSTER MYID)
redis-cli -h 192.168.1.14 CLUSTER REPLICATE $MASTER_B_ID
```

### Maintenance d'un nÅ“ud sans downtime

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAINTENANCE D'UN MASTER SANS INTERRUPTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Objectif : Mettre Ã  jour/rÃ©parer un master sans impacter le service


# Ã‰TAPE 1 : Identifier le master Ã  maintenir
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MASTER_TO_MAINTAIN="192.168.1.10"
MASTER_ID=$(redis-cli -h $MASTER_TO_MAINTAIN CLUSTER MYID)


# Ã‰TAPE 2 : VÃ©rifier qu'il a une replica
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli -h $MASTER_TO_MAINTAIN INFO replication | grep connected_slaves
# connected_slaves:1 âœ“

# Identifier la replica
REPLICA=$(redis-cli -h 192.168.1.10 CLUSTER NODES | grep "slave $MASTER_ID" | awk '{print $2}')
REPLICA_HOST=$(echo $REPLICA | cut -d: -f1)
echo "Replica: $REPLICA_HOST"


# Ã‰TAPE 3 : Failover manuel PLANIFIÃ‰ (pas d'attente)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Sur la replica, dÃ©clencher un failover sans attendre
redis-cli -h $REPLICA_HOST CLUSTER FAILOVER TAKEOVER

# Cette commande :
# 1. La replica devient immÃ©diatement master
# 2. L'ancien master devient replica automatiquement
# 3. Pas d'interruption de service (basculement instantanÃ©)
# 4. Pas d'attente du cluster-node-timeout


# Ã‰TAPE 4 : VÃ©rifier le basculement
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

sleep 5  # Laisser le temps au basculement

redis-cli -h $REPLICA_HOST CLUSTER NODES | grep myself
# Devrait montrer : myself,master

redis-cli -h $MASTER_TO_MAINTAIN CLUSTER NODES | grep myself
# Devrait montrer : myself,slave


# Ã‰TAPE 5 : Maintenance sur l'ancien master (maintenant replica)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ssh $MASTER_TO_MAINTAIN

# ArrÃªter Redis
sudo systemctl stop redis

# Effectuer la maintenance
# - Mise Ã  jour OS : apt upgrade / yum update
# - Upgrade Redis : installer nouvelle version
# - RÃ©paration disque
# - Changement de configuration
# - etc.

# RedÃ©marrer Redis
sudo systemctl start redis

# VÃ©rifier que la rÃ©plication reprend
redis-cli -h $MASTER_TO_MAINTAIN INFO replication
# role:slave
# master_link_status:up


# Ã‰TAPE 6 : Optionnel - Restaurer la topologie initiale
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Si souhaitÃ©, refaire basculer pour remettre comme master
redis-cli -h $MASTER_TO_MAINTAIN CLUSTER FAILOVER TAKEOVER

# RÃ©sultat : Topologie restaurÃ©e, maintenance terminÃ©e


# DOWNTIME TOTAL : 0 secondes âœ“
```

### Remplacement d'un nÅ“ud dÃ©faillant

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REMPLACER UN NÅ’UD MATÃ‰RIELLEMENT DÃ‰FAILLANT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ScÃ©nario : Un serveur physique est mort et ne redÃ©marrera pas
# Objectif : Remplacer par un nouveau serveur


# CONTEXTE :
# Master A (192.168.1.10) : MORT (hardware failure)
# Replica A1 (192.168.1.13) : UP et promue en master automatiquement


# Ã‰TAPE 1 : VÃ©rifier l'Ã©tat aprÃ¨s failover automatique
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli -h 192.168.1.11 CLUSTER NODES

# Output :
# a1b2c3d4... 192.168.1.10:6379 master,fail - 1234567890 ...
# r1s2t3u4... 192.168.1.13:6379 master - 1234567900 ...  â† Promue

# L'ancien master A est marquÃ© comme "fail"
# La replica A1 est devenue master


# Ã‰TAPE 2 : Retirer dÃ©finitivement l'ancien nÅ“ud dÃ©faillant
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

FAILED_NODE_ID="a1b2c3d4..."  # ID de l'ancien master

# Depuis n'importe quel nÅ“ud actif
redis-cli -h 192.168.1.11 CLUSTER FORGET $FAILED_NODE_ID

# RÃ©pÃ©ter sur tous les nÅ“uds pour propager
for node in 192.168.1.11 192.168.1.12 192.168.1.13 192.168.1.14 192.168.1.15; do
    redis-cli -h $node CLUSTER FORGET $FAILED_NODE_ID
done

# AprÃ¨s 60 secondes, le nÅ“ud sera complÃ¨tement oubliÃ© du cluster


# Ã‰TAPE 3 : PrÃ©parer le nouveau serveur de remplacement
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

NEW_SERVER="192.168.1.20"  # Nouveau serveur physique

ssh $NEW_SERVER
# Installer et configurer Redis (mÃªme config que l'ancien)
sudo apt install redis-server
# ... configuration ...
sudo systemctl start redis


# Ã‰TAPE 4 : Ajouter le nouveau nÅ“ud comme replica
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Le nouveau master (ex-replica A1) n'a plus de replica
# On ajoute le nouveau serveur comme replica de ce master

NEW_MASTER_ID=$(redis-cli -h 192.168.1.13 CLUSTER MYID)

redis-cli --cluster add-node $NEW_SERVER:6379 192.168.1.11:6379 \
    --cluster-slave \
    --cluster-master-id $NEW_MASTER_ID


# Ã‰TAPE 5 : Validation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli --cluster check 192.168.1.11:6379

# Devrait montrer :
# Master A1 (192.168.1.13) : X slots | 1 replica (192.168.1.20)
# â† Nouveau serveur opÃ©rationnel


# RÃ‰SULTAT :
# Ancien serveur mort â†’ OubliÃ©
# Nouveau serveur â†’ IntÃ©grÃ© comme replica
# Haute disponibilitÃ© restaurÃ©e âœ“
```

## Monitoring et troubleshooting des opÃ©rations

### Scripts de monitoring pendant les opÃ©rations

```bash
#!/bin/bash
# monitor-cluster-operations.sh
# Monitoring en temps rÃ©el des opÃ©rations de gestion de nÅ“uds

CLUSTER_NODE="192.168.1.10:6379"
REFRESH_INTERVAL=2

while true; do
    clear
    echo "=========================================="
    echo "Redis Cluster Operation Monitor"
    echo "Time: $(date +'%Y-%m-%d %H:%M:%S')"
    echo "=========================================="
    echo ""

    # Ã‰tat global du cluster
    echo "=== Cluster State ==="
    redis-cli -h ${CLUSTER_NODE%:*} CLUSTER INFO | grep -E "cluster_state|cluster_slots_assigned|cluster_slots_ok|cluster_known_nodes|cluster_size"
    echo ""

    # Distribution des slots par nÅ“ud
    echo "=== Slots Distribution ==="
    redis-cli --cluster check $CLUSTER_NODE | grep -E "slots|OK"
    echo ""

    # Slots en migration
    echo "=== Migrations in Progress ==="
    migrations=$(redis-cli -h ${CLUSTER_NODE%:*} CLUSTER NODES | grep -E "MIGRATING|IMPORTING")
    if [ -z "$migrations" ]; then
        echo "No migrations in progress"
    else
        echo "$migrations"
    fi
    echo ""

    # NÅ“uds en Ã©chec
    echo "=== Failed Nodes ==="
    failed=$(redis-cli -h ${CLUSTER_NODE%:*} CLUSTER NODES | grep fail)
    if [ -z "$failed" ]; then
        echo "No failed nodes"
    else
        echo "$failed"
    fi
    echo ""

    # MÃ©triques de performance
    echo "=== Performance Metrics ==="
    redis-cli -h ${CLUSTER_NODE%:*} INFO stats | grep -E "instantaneous_ops_per_sec|total_commands_processed"
    echo ""

    sleep $REFRESH_INTERVAL
done
```

### Commandes de diagnostic

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DIAGNOSTIC COMPLET D'OPÃ‰RATIONS DE GESTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


# 1. VÃ©rifier l'Ã©tat des migrations
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Voir tous les slots en cours de migration
redis-cli -h 192.168.1.10 CLUSTER NODES | grep -E "importing|migrating"

# Compter les slots en migration
redis-cli -h 192.168.1.10 CLUSTER NODES | grep -c migrating

# DÃ©tail d'un slot spÃ©cifique
redis-cli -h 192.168.1.10 CLUSTER SLOTS | grep -A 2 "8000"


# 2. Analyser la performance pendant resharding
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Latence en temps rÃ©el
redis-cli -h 192.168.1.10 --latency-history

# Taux de redirections
redis-cli -h 192.168.1.10 INFO stats | grep keyspace_misses

# Charge du serveur
redis-cli -h 192.168.1.10 INFO cpu


# 3. VÃ©rifier la cohÃ©rence du cluster
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Check complet avec dÃ©tails
redis-cli --cluster check 192.168.1.10:6379 --cluster-search-multiple-owners

# Fix automatique si problÃ¨mes dÃ©tectÃ©s
redis-cli --cluster fix 192.168.1.10:6379


# 4. Analyser les logs pendant les opÃ©rations
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Suivre les logs en temps rÃ©el
tail -f /var/log/redis/redis.log | grep -E "CLUSTER|MIGRATE|SLOT"

# Rechercher les erreurs
grep -i error /var/log/redis/redis.log | tail -20


# 5. Tester l'accÃ¨s aux donnÃ©es pendant migration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Ã‰crire et lire continuellement
while true; do
    redis-cli -c -h 192.168.1.10 SET test:$(date +%s) "$(date)"
    redis-cli -c -h 192.168.1.10 GET test:$(date +%s)
    sleep 1
done


# 6. VÃ©rifier la distribution des clÃ©s aprÃ¨s resharding
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

for node in 192.168.1.10 192.168.1.11 192.168.1.12; do
    keys=$(redis-cli -h $node DBSIZE)
    echo "$node: $keys keys"
done


# 7. Analyser les clÃ©s par slot
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

#!/bin/bash
# count-keys-per-slot.sh

for slot in {0..16383}; do
    count=$(redis-cli -h 192.168.1.10 CLUSTER COUNTKEYSINSLOT $slot)
    if [ $count -gt 0 ]; then
        echo "Slot $slot: $count keys"
    fi
done | sort -t: -k2 -n -r | head -50


# 8. VÃ©rifier la santÃ© de la rÃ©plication
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

for node in 192.168.1.10 192.168.1.11 192.168.1.12; do
    echo "=== $node ==="
    redis-cli -h $node INFO replication | grep -E "role|connected_slaves|master_link_status"
    echo ""
done
```

### Troubleshooting des problÃ¨mes courants

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ProblÃ¨mes courants lors de la gestion de nÅ“uds      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ PROBLÃˆME 1 : Resharding bloquÃ©                              â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                 â”‚
â”‚ SymptÃ´me : Migration ne progresse pas                       â”‚
â”‚                                                             â”‚
â”‚ Causes :                                                    â”‚
â”‚ â”œâ”€ Slots en Ã©tat MIGRATING/IMPORTING non finalisÃ©s          â”‚
â”‚ â”œâ”€ ClÃ© trÃ¨s volumineuse bloque la migration                 â”‚
â”‚ â””â”€ Timeout rÃ©seau trop court                                â”‚
â”‚                                                             â”‚
â”‚ Diagnostic :                                                â”‚
â”‚ redis-cli CLUSTER NODES | grep -E "importing|migrating"     â”‚
â”‚ redis-cli CLUSTER SLOTS                                     â”‚
â”‚                                                             â”‚
â”‚ Solutions :                                                 â”‚
â”‚ â”œâ”€ RÃ©initialiser l'Ã©tat : CLUSTER SETSLOT <slot> STABLE     â”‚
â”‚ â”œâ”€ Augmenter timeout : --cluster-timeout 60000              â”‚
â”‚ â””â”€ Migration manuelle des grosses clÃ©s                      â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ PROBLÃˆME 2 : Impossible de supprimer un nÅ“ud                â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                 â”‚
â”‚ SymptÃ´me : del-node Ã©choue                                  â”‚
â”‚                                                             â”‚
â”‚ Causes :                                                    â”‚
â”‚ â”œâ”€ Le nÅ“ud possÃ¨de encore des slots                         â”‚
â”‚ â”œâ”€ Le nÅ“ud est un master avec replicas                      â”‚
â”‚ â””â”€ Le nÅ“ud n'est pas dans le cluster                        â”‚
â”‚                                                             â”‚
â”‚ Solutions :                                                 â”‚
â”‚ â”œâ”€ VÃ©rifier : redis-cli CLUSTER INFO                        â”‚
â”‚ â”œâ”€ TransfÃ©rer tous les slots avant suppression              â”‚
â”‚ â”œâ”€ Supprimer les replicas d'abord                           â”‚
â”‚ â””â”€ Utiliser CLUSTER FORGET si dÃ©finitivement mort           â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ PROBLÃˆME 3 : Slots orphelins aprÃ¨s opÃ©ration                â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•               â”‚
â”‚ SymptÃ´me : cluster_slots_ok < 16384                         â”‚
â”‚                                                             â”‚
â”‚ Causes :                                                    â”‚
â”‚ â”œâ”€ OpÃ©ration interrompue brutalement                        â”‚
â”‚ â”œâ”€ NÅ“ud crash pendant migration                             â”‚
â”‚ â””â”€ Erreur rÃ©seau pendant resharding                         â”‚
â”‚                                                             â”‚
â”‚ Solutions :                                                 â”‚
â”‚ redis-cli --cluster fix 192.168.1.10:6379                   â”‚
â”‚                                                             â”‚
â”‚ Ou manuellement :                                           â”‚
â”‚ redis-cli CLUSTER SETSLOT <slot> STABLE                     â”‚
â”‚ redis-cli CLUSTER SETSLOT <slot> NODE <node-id>             â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ PROBLÃˆME 4 : Performance dÃ©gradÃ©e pendant resharding        â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•            â”‚
â”‚ SymptÃ´me : Latence Ã©levÃ©e, timeouts                         â”‚
â”‚                                                             â”‚
â”‚ Causes :                                                    â”‚
â”‚ â”œâ”€ Trop de clÃ©s migrÃ©es simultanÃ©ment                       â”‚
â”‚ â”œâ”€ Grosses clÃ©s (>1MB)                                      â”‚
â”‚ â””â”€ Charge CPU/rÃ©seau Ã©levÃ©e                                 â”‚
â”‚                                                             â”‚
â”‚ Solutions :                                                 â”‚
â”‚ â”œâ”€ RÃ©duire pipeline : --cluster-pipeline 5                  â”‚
â”‚ â”œâ”€ Migration par petits lots (100 slots Ã  la fois)          â”‚
â”‚ â”œâ”€ Pause entre les lots : sleep 60                          â”‚
â”‚ â””â”€ Planifier pendant heures creuses                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Best practices opÃ©rationnelles

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Best Practices pour la gestion de nÅ“uds              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ âœ“ PLANIFICATION                                             â”‚
â”‚   â”œâ”€ Documenter l'architecture avant et aprÃ¨s               â”‚
â”‚   â”œâ”€ Calculer la nouvelle distribution de slots             â”‚
â”‚   â”œâ”€ Estimer la durÃ©e de resharding                         â”‚
â”‚   â”œâ”€ Planifier pendant pÃ©riode de faible charge             â”‚
â”‚   â””â”€ PrÃ©voir un rollback si possible                        â”‚
â”‚                                                             â”‚
â”‚ âœ“ EXÃ‰CUTION                                                 â”‚
â”‚   â”œâ”€ Toujours traiter les replicas avant les masters        â”‚
â”‚   â”œâ”€ Utiliser --cluster-yes pour Ã©viter prompts             â”‚
â”‚   â”œâ”€ Monitorer en temps rÃ©el (latence, slots, erreurs)      â”‚
â”‚   â”œâ”€ Migration progressive (petits lots)                    â”‚
â”‚   â””â”€ Garder les logs de toutes les opÃ©rations               â”‚
â”‚                                                             â”‚
â”‚ âœ“ VALIDATION                                                â”‚
â”‚   â”œâ”€ VÃ©rifier : cluster_state:ok                            â”‚
â”‚   â”œâ”€ VÃ©rifier : cluster_slots_ok:16384                      â”‚
â”‚   â”œâ”€ Tester lecture/Ã©criture sur tous les nÅ“uds             â”‚
â”‚   â”œâ”€ Comparer nombre de clÃ©s avant/aprÃ¨s                    â”‚
â”‚   â””â”€ Valider la distribution (rebalance)                    â”‚
â”‚                                                             â”‚
â”‚ âœ“ SÃ‰CURITÃ‰                                                  â”‚
â”‚   â”œâ”€ Backup complet avant opÃ©rations majeures               â”‚
â”‚   â”œâ”€ Tester en staging d'abord                              â”‚
â”‚   â”œâ”€ Avoir un plan de rollback                              â”‚
â”‚   â”œâ”€ Communication avec l'Ã©quipe                            â”‚
â”‚   â””â”€ Monitoring des alertes                                 â”‚
â”‚                                                             â”‚
â”‚ âœ“ PERFORMANCE                                               â”‚
â”‚   â”œâ”€ Utiliser --cluster-pipeline (10-20)                    â”‚
â”‚   â”œâ”€ Ã‰viter les opÃ©rations pendant pics de charge           â”‚
â”‚   â”œâ”€ Surveiller la latence rÃ©seau                           â”‚
â”‚   â”œâ”€ Pause entre lots si charge Ã©levÃ©e                      â”‚
â”‚   â””â”€ Optimiser TCP (buffer size, keepalive)                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Conclusion

La gestion dynamique des nÅ“uds est une capacitÃ© fondamentale de Redis Cluster qui permet l'adaptation continue aux besoins Ã©volutifs. Les opÃ©rations d'ajout, de suppression et de resharding, bien que complexes, peuvent Ãªtre exÃ©cutÃ©es sans interruption de service lorsqu'elles sont planifiÃ©es et exÃ©cutÃ©es mÃ©thodiquement.

Les points essentiels Ã  retenir :

1. **Ordre des opÃ©rations** : Toujours traiter replicas avant masters
2. **Resharding progressif** : PrivilÃ©gier petits lots avec monitoring
3. **Validation rigoureuse** : VÃ©rifier l'Ã©tat aprÃ¨s chaque opÃ©ration majeure
4. **Monitoring continu** : Surveiller mÃ©triques pendant toute l'opÃ©ration
5. **Documentation** : Tracer toutes les modifications d'architecture

Une maÃ®trise approfondie de ces opÃ©rations est indispensable pour maintenir un cluster Redis performant, Ã©quilibrÃ© et hautement disponible en production.

---

**Points clÃ©s Ã  retenir :**

- **Ajout de master** : MEET â†’ Rebalance â†’ Ajouter replica
- **Suppression de master** : Supprimer replica â†’ Vider slots â†’ del-node
- **Resharding** : Utiliser pipeline, lots progressifs, monitoring continu
- **Failover manuel** : CLUSTER FAILOVER TAKEOVER pour maintenance sans downtime
- **Validation** : cluster_state:ok + cluster_slots_ok:16384 obligatoire
- **Troubleshooting** : CLUSTER FIX pour corriger slots orphelins
- **Performance** : --cluster-pipeline pour optimiser migrations
- **SÃ©curitÃ©** : Backup avant opÃ©rations, test en staging

La section suivante (11.6) explorera les limitations du cluster et les contraintes architecturales Ã  prendre en compte.

â­ï¸ [Limitations du Cluster (multi-key operations, transactions)](/11-architecture-distribuee-scaling/06-limitations-cluster.md)
