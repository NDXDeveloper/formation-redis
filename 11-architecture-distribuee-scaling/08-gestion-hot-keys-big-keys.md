ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 11.8 Gestion des Hot Keys et Big Keys dans un cluster

## Introduction

Les Hot Keys et Big Keys constituent deux catÃ©gories de problÃ¨mes de performance particuliÃ¨rement critiques dans Redis Cluster. Alors qu'ils peuvent dÃ©jÃ  causer des problÃ¨mes dans une instance Redis standalone, leur impact est amplifiÃ© dans un environnement distribuÃ© oÃ¹ ils peuvent crÃ©er des dÃ©sÃ©quilibres sÃ©vÃ¨res, saturer des nÅ“uds spÃ©cifiques, et compromettre la disponibilitÃ© globale du cluster.

Ces problÃ¨mes sont insidieux car ils peuvent apparaÃ®tre progressivement, passer inaperÃ§us dans les environnements de dÃ©veloppement avec des charges limitÃ©es, puis causer des pannes catastrophiques en production lors de pics de trafic. Leur gestion nÃ©cessite une comprÃ©hension approfondie de l'architecture distribuÃ©e de Redis Cluster et une approche proactive de monitoring et d'optimisation.

Cette section explore en dÃ©tail la nature de ces problÃ¨mes, leurs impacts spÃ©cifiques dans un cluster distribuÃ©, les mÃ©thodes de dÃ©tection, et les stratÃ©gies d'attÃ©nuation et de rÃ©solution.

## Hot Keys : DÃ©finition et problÃ©matique

### Qu'est-ce qu'une Hot Key ?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DÃ©finition : Hot Key                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Hot Key = ClÃ© accÃ©dÃ©e de maniÃ¨re disproportionnÃ©e par rapport
          aux autres clÃ©s du cluster

CaractÃ©ristiques :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ Taux d'accÃ¨s trÃ¨s Ã©levÃ© (10x-1000x la moyenne)
â€¢ Concentration du trafic sur un seul slot/nÅ“ud
â€¢ Pattern typique : lecture intensive
â€¢ Peut Ãªtre temporaire (trending topic) ou permanent (config globale)


Exemples typiques de Hot Keys :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Configuration globale
   â””â”€> "config:app:version" lue par chaque requÃªte

2. Trending topic (rÃ©seau social)
   â””â”€> "post:viral:12345" avec millions de vues

3. Compteur global
   â””â”€> "stats:global:visitors" incrÃ©mentÃ© en continu

4. Session d'utilisateur populaire
   â””â”€> "session:celebrity:user" accÃ©dÃ©e massivement

5. Cache d'API externe
   â””â”€> "cache:weather:paris" lu par tous les utilisateurs


DiffÃ©rence avec charge uniforme :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Charge UNIFORME (saine) :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Node A      Node B      Node C
    1000 r/s    1000 r/s    1000 r/s
    â•â•â•â•â•â•â•â•    â•â•â•â•â•â•â•â•    â•â•â•â•â•â•â•â•
    Ã‰quilibrÃ© âœ“


Charge avec HOT KEY :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Node A      Node B      Node C
    10000 r/s   1000 r/s    1000 r/s
    â•â•â•â•â•â•â•â•â•   â•â•â•â•â•â•â•â•    â•â•â•â•â•â•â•â•
    DÃ©sÃ©quilibrÃ© âœ—

    Node A saturÃ© par hot key sur ses slots
```

### Impact dans Redis Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Impact des Hot Keys en Cluster                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. SATURATION D'UN NÅ’UD SPÃ‰CIFIQUE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Hot key "trending:post:viral" â†’ Slot 8754 â†’ Node B

    Client 1 â”€â”
    Client 2 â”€â”¤
    Client 3 â”€â”¤
    Client 4 â”€â”¼â”€â”€> GET trending:post:viral â”€â”€> Node B âš ï¸ SATURÃ‰
    Client 5 â”€â”¤                                 â”‚
    ...       â”€â”¤                                 â”œâ”€ CPU: 95%
    Client N â”€â”˜                                  â”œâ”€ Bandwidth: MAX
                                                 â””â”€ Latency: 100ms+

    Node A: 10% CPU (idle)
    Node C: 10% CPU (idle)

ConsÃ©quence : Gaspillage de ressources (A, C sous-utilisÃ©s)


2. AUGMENTATION DE LA LATENCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Sans hot key :
    GET regular:key â†’ 0.5ms (temps de rÃ©ponse)

Avec hot key sur mÃªme nÅ“ud :
    GET regular:key â†’ 50ms (Ã—100 !)

Cause : File d'attente (queuing) des requÃªtes
        Node B traite d'abord les milliers de GET sur hot key


3. RISQUE DE TIMEOUTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Clients configurÃ©s avec timeout 1s
    â”‚
    â””â”€> Node B saturÃ©, rÃ©pond aprÃ¨s 2s
        â”‚
        â””â”€> Client timeout âœ—
            â””â”€> Retry
                â””â”€> Aggrave la charge (retry storm)


4. DÃ‰SÃ‰QUILIBRE DE LA CHARGE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Distribution thÃ©orique : 33% / 33% / 33%
Distribution rÃ©elle avec hot key : 85% / 7.5% / 7.5%

Impossible d'ajouter plus de nÅ“uds pour rÃ©soudre
(hot key restera sur le mÃªme nÅ“ud)


5. IMPACT SUR LE FAILOVER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Si Node B (avec hot key) tombe :
    â”‚
    â”œâ”€> Failover vers replica
    â”œâ”€> Replica devient master
    â””â”€> Replica AUSSI saturÃ©e par hot key âœ—

Cycle vicieux : Master crash â†’ Replica promue â†’ Replica crash


6. EFFET CASCADE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Node B saturÃ©
    â”‚
    â”œâ”€> Clients timeout et retry
    â”œâ”€> Augmentation connexions
    â”œâ”€> OOM sur Node B
    â””â”€> Node B crash
        â”‚
        â””â”€> Failover vers replica
            â””â”€> Replica crash (mÃªme problÃ¨me)
                â””â”€> Slot 8754 non disponible
                    â””â”€> Application down âœ—âœ—âœ—
```

### Pattern de Hot Keys par cas d'usage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Patterns typiques de Hot Keys                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 1. CONFIGURATION GLOBALE (Permanent)                        â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                              â”‚
â”‚    Pattern : config:global:*                                â”‚
â”‚    AccÃ¨s : Lecture Ã  chaque requÃªte                         â”‚
â”‚    Volume : 10k-100k req/sec                                â”‚
â”‚    Solution : RÃ©plication cÃ´tÃ© client, cache local          â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 2. TRENDING CONTENT (Temporaire)                            â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                               â”‚
â”‚    Pattern : post:trending:*, video:viral:*                 â”‚
â”‚    AccÃ¨s : Burst intense pendant quelques heures/jours      â”‚
â”‚    Volume : 100k-1M req/sec au pic                          â”‚
â”‚    Solution : CDN, rÃ©plication, Ã©clatement                  â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 3. RATE LIMITING GLOBAL (Semi-permanent)                    â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                               â”‚
â”‚    Pattern : ratelimit:global:api                           â”‚
â”‚    AccÃ¨s : IncrÃ©mentation Ã  chaque appel API                â”‚
â”‚    Volume : Suit le trafic global                           â”‚
â”‚    Solution : Rate limiting local, agrÃ©gation diffÃ©rÃ©e      â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 4. LOCK DISTRIBUÃ‰ (Intermittent)                            â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                  â”‚
â”‚    Pattern : lock:resource:shared                           â”‚
â”‚    AccÃ¨s : Contention Ã©levÃ©e sur ressource partagÃ©e         â”‚
â”‚    Volume : Pics lors de contention                         â”‚
â”‚    Solution : Redesign (Ã©liminer bottleneck)                â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ 5. COMPTEUR PARTAGÃ‰ (Continu)                               â”‚
â”‚    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                 â”‚
â”‚    Pattern : counter:global:views                           â”‚
â”‚    AccÃ¨s : INCR continu                                     â”‚
â”‚    Volume : Proportionnel au trafic                         â”‚
â”‚    Solution : Sharding du compteur, agrÃ©gation batch        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Big Keys : DÃ©finition et problÃ©matique

### Qu'est-ce qu'une Big Key ?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DÃ©finition : Big Key                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Big Key = ClÃ© dont la valeur consomme une quantitÃ© excessive
          de mÃ©moire ou dont l'opÃ©ration prend un temps significatif

CritÃ¨res de taille :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Type            Seuil "Big"         Impact critique
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
String          > 10 MB             > 100 MB
List            > 10,000 Ã©lÃ©ments   > 100,000 Ã©lÃ©ments
Set             > 10,000 membres    > 100,000 membres
Sorted Set      > 10,000 membres    > 100,000 membres
Hash            > 10,000 champs     > 100,000 champs

Note : Ces seuils sont indicatifs et dÃ©pendent du contexte


Exemples typiques de Big Keys :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Liste de tous les utilisateurs
   â””â”€> "users:all" LIST avec millions d'Ã©lÃ©ments

2. Session utilisateur surchargÃ©e
   â””â”€> "session:user:123" HASH avec milliers de champs

3. Cache d'une page HTML complÃ¨te
   â””â”€> "cache:page:homepage" STRING de 50 MB

4. Historique complet d'Ã©vÃ©nements
   â””â”€> "events:user:123:history" LIST sans limite

5. Leaderboard gÃ©ant
   â””â”€> "leaderboard:global" ZSET avec millions de joueurs


DiffÃ©rence avec clÃ©s normales :
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ClÃ© normale :
    GET user:1000:profile (1 KB)
    â””â”€> Temps : 0.1ms
    â””â”€> RÃ©seau : nÃ©gligeable
    â””â”€> MÃ©moire : nÃ©gligeable


Big Key :
    GET cache:homepage (50 MB)
    â””â”€> Temps : 100ms (blocking)
    â””â”€> RÃ©seau : saturÃ© (400 Mbps pour transfÃ©rer)
    â””â”€> MÃ©moire : 50 MB par rÃ©plication
```

### Impact dans Redis Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Impact des Big Keys en Cluster                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. BLOCAGE DU THREAD PRINCIPAL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Redis est single-threaded (par nÅ“ud)

GET big_key (50 MB)
    â”‚
    â”œâ”€> SÃ©rialisation : 50ms
    â”œâ”€> Transfert rÃ©seau : 100ms
    â””â”€> Total : 150ms de blocage âš ï¸

Pendant ces 150ms :
    â”œâ”€ Aucune autre commande n'est traitÃ©e
    â”œâ”€ Toutes les requÃªtes vers ce nÅ“ud sont en attente
    â””â”€> Timeouts gÃ©nÃ©ralisÃ©s sur les clients


2. SATURATION RÃ‰SEAU
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Transfert d'une big key de 100 MB :
    â””â”€> Sur lien 1 Gbps = 800ms
    â””â”€> Bande passante monopolisÃ©e

Impact sur autres clÃ©s du mÃªme nÅ“ud :
    â””â”€> Latence rÃ©seau dÃ©gradÃ©e
    â””â”€> Paquets perdus
    â””â”€> Retransmissions TCP


3. PROBLÃˆMES DE RÃ‰PLICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Big key sur Master A
    â”‚
    â”œâ”€> RÃ©plication vers Replica A1
    â”‚   â””â”€> Transfert de 100 MB
    â”‚       â”œâ”€> RÃ©seau saturÃ©
    â”‚       â”œâ”€> Replica en retard (lag)
    â”‚       â””â”€> Risque de resync complet
    â”‚
    â””â”€> Lors d'une Ã©criture :
        â”œâ”€> Master envoie Ã  replica
        â”œâ”€> Replica met 5s Ã  appliquer (big SET/LIST/HASH)
        â””â”€> Lag de 5s entre master et replica


4. MIGRATION LORS DU RESHARDING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Resharding du slot contenant une big key :

MIGRATE host port key 0 timeout
    â”‚
    â”œâ”€> SÃ©rialisation de 500 MB
    â”œâ”€> Transfert rÃ©seau de 500 MB
    â”œâ”€> Timeout par dÃ©faut : 5s
    â””â”€> Big key : 60s âœ—
        â””â”€> Migration Ã©choue
            â””â”€> Slot reste en MIGRATING
                â””â”€> Cluster instable


5. IMPACT MÃ‰MOIRE DISPROPORTIONNÃ‰
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Cluster 3 nÅ“uds, 16384 slots
Chaque nÅ“ud devrait avoir : ~33% de la mÃ©moire

Avec une big key de 5 GB sur Node A :
    Node A : 8 GB (47% du total)  â† DÃ©sÃ©quilibrÃ©
    Node B : 4.5 GB (26%)
    Node C : 4.5 GB (27%)

ConsÃ©quences :
    â”œâ”€> Node A proche de maxmemory
    â”œâ”€> Ã‰victions prÃ©coces sur Node A
    â””â”€> Autres nÅ“uds sous-utilisÃ©s


6. PROBLÃˆMES DE PERSISTENCE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RDB (snapshot) :
    â””â”€> Ã‰criture de la big key bloque fork()
    â””â”€> Copy-on-write penalty Ã©levÃ©

AOF (append only) :
    â””â”€> Ã‰criture de 100 MB dans l'AOF
    â””â”€> fsync bloque pendant l'Ã©criture
    â””â”€> Latence spike gÃ©nÃ©ralisÃ©e


7. OPÃ‰RATIONS DANGEREUSES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DEL big_key
    â””â”€> Redis doit libÃ©rer toute la mÃ©moire
    â””â”€> Si big key = 1 GB
        â””â”€> DEL bloque pendant 1-2 secondes âš ï¸
        â””â”€> Toutes les requÃªtes en attente

EXPIRE big_key 0
    â””â”€> MÃªme problÃ¨me que DEL

Solution : UNLINK (non-blocking depuis Redis 4.0)
    â””â”€> Marque pour suppression asynchrone
    â””â”€> Thread background libÃ¨re la mÃ©moire
    â””â”€> Pas de blocage âœ“
```

### Types de structures et leur comportement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Comportement des Big Keys par type                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ STRING (blob)                                               â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•                                               â”‚
â”‚ ProblÃ¨me principal : Transfert rÃ©seau                       â”‚
â”‚                                                             â”‚
â”‚ GET bigstring (100 MB)                                      â”‚
â”‚ â””â”€> Temps O(1) mais transfert long                          â”‚
â”‚ â””â”€> Monopolise bande passante                               â”‚
â”‚                                                             â”‚
â”‚ SET bigstring (100 MB)                                      â”‚
â”‚ â””â”€> Allocation mÃ©moire instantanÃ©e                          â”‚
â”‚ â””â”€> RÃ©plication coÃ»teuse                                    â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ LIST                                                        â”‚
â”‚ â•â•â•â•                                                        â”‚
â”‚ ProblÃ¨me : OpÃ©rations sur tous les Ã©lÃ©ments                 â”‚
â”‚                                                             â”‚
â”‚ LRANGE biglist 0 -1  (1M Ã©lÃ©ments)                          â”‚
â”‚ â””â”€> O(N) = trÃ¨s lent                                        â”‚
â”‚ â””â”€> Bloque le serveur                                       â”‚
â”‚                                                             â”‚
â”‚ LPUSH biglist value  (ajout)                                â”‚
â”‚ â””â”€> O(1) = rapide âœ“                                         â”‚
â”‚                                                             â”‚
â”‚ DEL biglist                                                 â”‚
â”‚ â””â”€> O(N) = libÃ©ration de 1M Ã©lÃ©ments                        â”‚
â”‚ â””â”€> Bloque pendant plusieurs secondes                       â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ SET / HASH / SORTED SET                                     â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                     â”‚
â”‚ ProblÃ¨me : ComplexitÃ© O(N) sur opÃ©rations complÃ¨tes         â”‚
â”‚                                                             â”‚
â”‚ SMEMBERS bigset  (1M membres)                               â”‚
â”‚ â””â”€> O(N) = retourne tous les membres                        â”‚
â”‚ â””â”€> Transfert de millions de valeurs                        â”‚
â”‚                                                             â”‚
â”‚ HGETALL bighash  (1M champs)                                â”‚
â”‚ â””â”€> O(N) = retourne tous les champs                         â”‚
â”‚ â””â”€> SÃ©rialisation trÃ¨s coÃ»teuse                             â”‚
â”‚                                                             â”‚
â”‚ ZRANGE bigsortedset 0 -1  (1M Ã©lÃ©ments)                     â”‚
â”‚ â””â”€> O(log(N)+M) mais M=1M                                   â”‚
â”‚ â””â”€> TrÃ¨s lent                                               â”‚
â”‚                                                             â”‚
â”‚ Alternative : Utiliser SCAN, HSCAN, SSCAN, ZSCAN            â”‚
â”‚ â””â”€> ItÃ©ration par curseur                                   â”‚
â”‚ â””â”€> Batches de 100-1000 Ã©lÃ©ments                            â”‚
â”‚ â””â”€> N'affecte pas les autres clients                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## DÃ©tection et monitoring

### DÃ©tection des Hot Keys

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ‰THODES DE DÃ‰TECTION DES HOT KEYS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


# MÃ‰THODE 1 : --hotkeys (Redis 4.0+)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Analyse statistique avec sampling
redis-cli --hotkeys -h 192.168.1.10

# Output :
# Sampled 10000 keys in the keyspace
# hot key found with frequency: 8765 keyname: trending:post:viral
# hot key found with frequency: 5432 keyname: config:app:version
# hot key found with frequency: 3210 keyname: counter:global:hits

# Fonctionnement :
# â”œâ”€ Sample alÃ©atoire de clÃ©s
# â”œâ”€ Mesure de la frÃ©quence d'accÃ¨s via LFU (Least Frequently Used)
# â””â”€ NÃ©cessite maxmemory-policy allkeys-lfu ou volatile-lfu

# Configuration requise dans redis.conf :
maxmemory-policy allkeys-lfu
lfu-log-factor 10
lfu-decay-time 1


# MÃ‰THODE 2 : MONITOR (temps rÃ©el, attention Ã  l'impact)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# MONITOR retourne TOUTES les commandes en temps rÃ©el
redis-cli -h 192.168.1.10 MONITOR | head -1000 > commands.log

# Analyser les logs
cat commands.log | grep -oP '"[^"]+"' | sort | uniq -c | sort -nr | head -20

# Output :
# 8765 "trending:post:viral"
# 5432 "config:app:version"
# 3210 "counter:global:hits"

# âš ï¸ ATTENTION : MONITOR est TRÃˆS coÃ»teux
# â”œâ”€ Duplique toutes les commandes vers le client
# â”œâ”€ Impacte significativement les performances
# â””â”€ Ã€ utiliser UNIQUEMENT en debug court terme (<1 minute)


# MÃ‰THODE 3 : Analyse des logs avec pattern matching
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Activer slowlog pour capturer commandes lentes
redis-cli CONFIG SET slowlog-log-slower-than 10000  # 10ms

# RÃ©cupÃ©rer slowlog
redis-cli SLOWLOG GET 100

# Analyser les clÃ©s frÃ©quentes dans slowlog
redis-cli SLOWLOG GET 1000 | grep '"GET"' | grep -oP 'key:[^ ]+' | sort | uniq -c | sort -nr


# MÃ‰THODE 4 : Client-side instrumentation
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Instrumenter l'application pour tracker les clÃ©s accÃ©dÃ©es
# Exemple avec Python :

from collections import Counter
import redis

class InstrumentedRedis:
    def __init__(self, *args, **kwargs):
        self.client = redis.Redis(*args, **kwargs)
        self.key_counter = Counter()

    def get(self, key):
        self.key_counter[key] += 1
        return self.client.get(key)

    def get_hot_keys(self, top_n=10):
        return self.key_counter.most_common(top_n)

# Utilisation
r = InstrumentedRedis(host='localhost')
# ... utiliser r.get() dans l'application ...

# PÃ©riodiquement, logger les hot keys
print(r.get_hot_keys(10))


# MÃ‰THODE 5 : Monitoring externe (Prometheus + Exporter)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Utiliser redis_exporter avec key sampling
# https://github.com/oliver006/redis_exporter

# redis_exporter avec option -check-keys
redis_exporter \
    -redis.addr redis://192.168.1.10:6379 \
    -check-keys "trending:*,config:*,counter:*"

# MÃ©triques exportÃ©es :
# redis_key_size{key="trending:post:viral"} 1234
# redis_key_access_count{key="trending:post:viral"} 89765

# Alertes Prometheus pour hot keys :
# RÃ¨gle d'alerte si une clÃ© dÃ©passe 10k req/min
groups:
  - name: redis_hotkeys
    rules:
      - alert: HotKeyDetected
        expr: rate(redis_key_access_count[1m]) > 10000
        annotations:
          summary: "Hot key detected: {{ $labels.key }}"


# MÃ‰THODE 6 : Script Lua pour Ã©chantillonnage
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Script qui sample les clÃ©s et retourne statistiques
local cursor = "0"
local keys_sampled = {}
local sample_size = 10000

repeat
    local result = redis.call("SCAN", cursor, "COUNT", 100)
    cursor = result[1]
    local keys = result[2]

    for _, key in ipairs(keys) do
        local freq = redis.call("OBJECT", "FREQ", key)
        if freq then
            table.insert(keys_sampled, {key, freq})
        end
    end
until cursor == "0" or #keys_sampled >= sample_size

-- Trier par frÃ©quence
table.sort(keys_sampled, function(a, b) return a[2] > b[2] end)

-- Retourner top 10
local result = {}
for i = 1, math.min(10, #keys_sampled) do
    table.insert(result, keys_sampled[i])
end

return result
```

### DÃ©tection des Big Keys

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ‰THODES DE DÃ‰TECTION DES BIG KEYS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


# MÃ‰THODE 1 : --bigkeys (natif Redis)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Scan toutes les clÃ©s et identifie les plus grandes par type
redis-cli --bigkeys -h 192.168.1.10

# Output :
# -------- summary -------
#
# Biggest string found: cache:homepage (50.2 MB)
# Biggest list found: events:user:123:history (1,234,567 items)
# Biggest set found: users:all (500,000 members)
# Biggest hash found: session:user:456 (100,000 fields)
# Biggest zset found: leaderboard:global (2,000,000 members)
#
# 12345678 keys scanned
# 150 big keys found

# Options utiles :
redis-cli --bigkeys -i 0.01  # Pause 10ms entre clÃ©s (moins impactant)


# MÃ‰THODE 2 : MEMORY USAGE (Redis 4.0+)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Obtenir taille exacte d'une clÃ© spÃ©cifique
redis-cli MEMORY USAGE cache:homepage
# (integer) 52428800  # 50 MB

redis-cli MEMORY USAGE events:user:123:history
# (integer) 10485760  # 10 MB

# Script pour scanner toutes les clÃ©s et mesurer taille
redis-cli --scan | while read key; do
    size=$(redis-cli MEMORY USAGE "$key")
    echo "$size $key"
done | sort -rn | head -20

# Top 20 biggest keys avec leur taille


# MÃ‰THODE 3 : Script d'analyse complet
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

#!/bin/bash
# find-big-keys.sh
# Analyse complÃ¨te des big keys avec dÃ©tails

REDIS_HOST="192.168.1.10"
REDIS_PORT="6379"
THRESHOLD_MB=10

echo "Scanning for big keys (threshold: ${THRESHOLD_MB} MB)..."

redis-cli -h $REDIS_HOST -p $REDIS_PORT --scan | while read key; do
    # Obtenir le type
    type=$(redis-cli -h $REDIS_HOST -p $REDIS_PORT TYPE "$key")

    # Obtenir la taille en mÃ©moire
    size=$(redis-cli -h $REDIS_HOST -p $REDIS_PORT MEMORY USAGE "$key")
    size_mb=$(awk "BEGIN {print $size/1024/1024}")

    # Si > threshold, afficher dÃ©tails
    if (( $(echo "$size_mb > $THRESHOLD_MB" | bc -l) )); then

        # DÃ©tails selon le type
        case $type in
            "string")
                strlen=$(redis-cli -h $REDIS_HOST -p $REDIS_PORT STRLEN "$key")
                echo "BIG KEY: $key | Type: $type | Size: ${size_mb} MB | Length: $strlen bytes"
                ;;
            "list")
                llen=$(redis-cli -h $REDIS_HOST -p $REDIS_PORT LLEN "$key")
                echo "BIG KEY: $key | Type: $type | Size: ${size_mb} MB | Elements: $llen"
                ;;
            "set")
                scard=$(redis-cli -h $REDIS_HOST -p $REDIS_PORT SCARD "$key")
                echo "BIG KEY: $key | Type: $type | Size: ${size_mb} MB | Members: $scard"
                ;;
            "zset")
                zcard=$(redis-cli -h $REDIS_HOST -p $REDIS_PORT ZCARD "$key")
                echo "BIG KEY: $key | Type: $type | Size: ${size_mb} MB | Members: $zcard"
                ;;
            "hash")
                hlen=$(redis-cli -h $REDIS_HOST -p $REDIS_PORT HLEN "$key")
                echo "BIG KEY: $key | Type: $type | Size: ${size_mb} MB | Fields: $hlen"
                ;;
        esac
    fi
done


# MÃ‰THODE 4 : Analyse via RDB Tools
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Installer rdb-tools (Python)
pip install rdbtools python-lzf

# Analyser un dump RDB
rdb --command memory dump.rdb > memory-report.csv

# Format CSV :
# database,type,key,size_in_bytes,encoding,num_elements,len_largest_element

# Filtrer les big keys (> 10 MB)
awk -F',' '$4 > 10485760 {print $3,$4/1024/1024 " MB"}' memory-report.csv | sort -k2 -rn

# GÃ©nÃ©rer rapport HTML
rdb --command memory dump.rdb --bytes 10485760 --largest 100 > big-keys.html


# MÃ‰THODE 5 : Monitoring continu (Python script)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import redis
import time
from collections import defaultdict

BIG_KEY_THRESHOLD_MB = 10
SCAN_INTERVAL_SECONDS = 300  # Toutes les 5 minutes

def scan_big_keys(host, port):
    r = redis.Redis(host=host, port=port, decode_responses=True)
    big_keys = []

    cursor = '0'
    while True:
        cursor, keys = r.scan(cursor=cursor, count=100)

        for key in keys:
            try:
                # Obtenir taille en bytes
                size_bytes = r.memory_usage(key)

                if size_bytes and size_bytes > (BIG_KEY_THRESHOLD_MB * 1024 * 1024):
                    key_type = r.type(key)
                    size_mb = size_bytes / 1024 / 1024

                    big_keys.append({
                        'key': key,
                        'type': key_type,
                        'size_mb': round(size_mb, 2)
                    })
            except Exception as e:
                print(f"Error checking key {key}: {e}")

        if cursor == '0':
            break

    return big_keys

def monitor_big_keys():
    while True:
        print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Scanning for big keys...")

        big_keys = scan_big_keys('192.168.1.10', 6379)

        if big_keys:
            print(f"Found {len(big_keys)} big keys:")
            for bk in sorted(big_keys, key=lambda x: x['size_mb'], reverse=True):
                print(f"  - {bk['key']} ({bk['type']}): {bk['size_mb']} MB")

            # Envoyer alerte si nÃ©cessaire
            # send_alert(big_keys)
        else:
            print("No big keys found")

        time.sleep(SCAN_INTERVAL_SECONDS)

if __name__ == "__main__":
    monitor_big_keys()


# MÃ‰THODE 6 : INFO MEMORY pour vue globale
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli INFO MEMORY

# MÃ©triques importantes :
# used_memory_human:15.23G
# used_memory_peak_human:18.45G
# mem_fragmentation_ratio:1.15

# Si ratio > 1.5 : fragmentation importante
# Peut indiquer prÃ©sence de big keys supprimÃ©es/modifiÃ©es


# MÃ‰THODE 7 : DEBUG OBJECT (dÃ©tails d'une clÃ©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

redis-cli DEBUG OBJECT cache:homepage

# Output :
# Value at:0x7f8a9c000000 refcount:1 encoding:raw serializedlength:52428800 lru:12345678 lru_seconds_idle:42

# serializedlength = taille sÃ©rialisÃ©e (approximative de la mÃ©moire)
```

### Monitoring en continu

```yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION PROMETHEUS + GRAFANA POUR HOT/BIG KEYS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# prometheus.yml
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

scrape_configs:
  - job_name: 'redis'
    static_configs:
      - targets:
          - '192.168.1.10:9121'  # redis_exporter
          - '192.168.1.11:9121'
          - '192.168.1.12:9121'

# Alertes Prometheus
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# prometheus-alerts.yml

groups:
  - name: redis_keys
    rules:
      # Alerte : Hot Key dÃ©tectÃ©e
      - alert: RedisHotKeyDetected
        expr: |
          rate(redis_command_calls_total{cmd="get"}[1m])
          / on(instance)
          redis_commands_processed_total > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Potential hot key on {{ $labels.instance }}"
          description: "GET commands represent >50% of traffic"

      # Alerte : Big Key dÃ©tectÃ©e
      - alert: RedisBigKeyDetected
        expr: redis_key_size > 10485760  # 10 MB
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Big key detected: {{ $labels.key }}"
          description: "Key size: {{ $value | humanize }}B"

      # Alerte : DÃ©sÃ©quilibre de charge
      - alert: RedisNodeImbalance
        expr: |
          max(rate(redis_commands_processed_total[5m]))
          / min(rate(redis_commands_processed_total[5m])) > 3
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Redis cluster load imbalance"
          description: "One node handling 3x more traffic than others"


# Dashboard Grafana
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# grafana-dashboard.json (extrait)
{
  "panels": [
    {
      "title": "Commands per Second by Node",
      "targets": [
        {
          "expr": "rate(redis_commands_processed_total[1m])"
        }
      ]
    },
    {
      "title": "Top Keys by Size",
      "targets": [
        {
          "expr": "topk(10, redis_key_size)"
        }
      ]
    },
    {
      "title": "Memory Usage per Node",
      "targets": [
        {
          "expr": "redis_memory_used_bytes"
        }
      ]
    },
    {
      "title": "Network I/O per Node",
      "targets": [
        {
          "expr": "rate(redis_net_input_bytes_total[1m])"
        }
      ]
    }
  ]
}
```

## Solutions et stratÃ©gies d'attÃ©nuation

### Solutions pour Hot Keys

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              StratÃ©gies pour attÃ©nuer Hot Keys              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


STRATÃ‰GIE 1 : RÃ‰PLICATION DE LA HOT KEY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Principe : Dupliquer la hot key sur plusieurs slots


Avant :
    trending:post:viral â†’ Slot 8754 â†’ Node B (saturÃ©)


AprÃ¨s :
    trending:post:viral:1 â†’ Slot 1234 â†’ Node A
    trending:post:viral:2 â†’ Slot 5678 â†’ Node B
    trending:post:viral:3 â†’ Slot 9012 â†’ Node C

Client choisit alÃ©atoirement : trending:post:viral:{1,2,3}


ImplÃ©mentation (Python) :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import random
import redis

def get_hot_key_replicated(key, num_replicas=3):
    """Lire hot key avec load balancing"""
    replica_id = random.randint(1, num_replicas)
    replicated_key = f"{key}:{replica_id}"
    return redis_client.get(replicated_key)

def set_hot_key_replicated(key, value, num_replicas=3):
    """Ã‰crire hot key sur toutes les replicas"""
    for i in range(1, num_replicas + 1):
        replicated_key = f"{key}:{i}"
        redis_client.set(replicated_key, value)

# Utilisation
set_hot_key_replicated("trending:post:viral", post_data, num_replicas=5)
data = get_hot_key_replicated("trending:post:viral", num_replicas=5)


Avantages :
â”œâ”€ Distribution de la charge sur plusieurs nÅ“uds
â”œâ”€ Simple Ã  implÃ©menter
â””â”€ Transparent pour la logique mÃ©tier

InconvÃ©nients :
â”œâ”€ CohÃ©rence Ã©ventuelle entre replicas
â”œâ”€ Consommation mÃ©moire Ã— N
â””â”€ ComplexitÃ© de mise Ã  jour (Ã©crire sur toutes les replicas)


STRATÃ‰GIE 2 : CACHE LOCAL CÃ”TÃ‰ CLIENT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Principe : Cache en mÃ©moire de l'application


Application
    â”‚
    â”œâ”€> Cache local (in-memory)
    â”‚   â”œâ”€ config:app:version â†’ cached 30s
    â”‚   â””â”€ trending:post:viral â†’ cached 10s
    â”‚
    â””â”€> Redis (fallback si cache miss)


ImplÃ©mentation (Python avec cachetools) :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

from cachetools import TTLCache
import redis

# Cache local avec TTL
local_cache = TTLCache(maxsize=1000, ttl=30)  # 30 secondes

def get_with_local_cache(key):
    """GET avec cache local"""

    # VÃ©rifier cache local
    if key in local_cache:
        print(f"Cache HIT (local): {key}")
        return local_cache[key]

    # Cache miss â†’ Redis
    value = redis_client.get(key)

    # Stocker dans cache local
    if value:
        local_cache[key] = value
        print(f"Cache MISS (Redis): {key}")

    return value

# Utilisation
config = get_with_local_cache("config:app:version")


Avantages :
â”œâ”€ Latence ultra-faible (in-memory local)
â”œâ”€ RÃ©duit drastiquement charge sur Redis
â”œâ”€ Pas de modification de Redis
â””â”€ ScalabilitÃ© parfaite

InconvÃ©nients :
â”œâ”€ Staleness (donnÃ©es peuvent Ãªtre pÃ©rimÃ©es pendant TTL)
â”œâ”€ Consommation mÃ©moire sur chaque instance d'application
â””â”€ CohÃ©rence Ã©ventuelle


STRATÃ‰GIE 3 : LECTURE SUR REPLICAS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Principe : Rediriger les lectures vers replicas (Redis 7+)


Configuration :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# redis.conf sur chaque nÅ“ud
replica-read-only yes

# Client configure route de lecture
# (certaines bibliothÃ¨ques le supportent nativement)


Load balancing manuel :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Python exemple
from rediscluster import RedisCluster

startup_nodes = [
    {"host": "192.168.1.10", "port": 6379},  # Master A
    {"host": "192.168.1.13", "port": 6379},  # Replica A
    {"host": "192.168.1.11", "port": 6379},  # Master B
    {"host": "192.168.1.14", "port": 6379},  # Replica B
]

# Configurer pour lire sur replicas
cluster = RedisCluster(
    startup_nodes=startup_nodes,
    decode_responses=True,
    read_from_replicas=True  # Active lectures sur replicas
)

value = cluster.get("trending:post:viral")
# Peut Ãªtre routÃ© vers replica automatiquement


Avantages :
â”œâ”€ Offload des masters
â”œâ”€ Double la capacitÃ© de lecture
â””â”€ Pas de modification de code mÃ©tier

InconvÃ©nients :
â”œâ”€ CohÃ©rence Ã©ventuelle (replica lag)
â”œâ”€ ComplexitÃ© de configuration client
â””â”€ Pas adaptÃ© si donnÃ©es doivent Ãªtre Ã  jour


STRATÃ‰GIE 4 : SHARDING DE LA HOT KEY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Principe : DÃ©composer une hot key en multiples sous-clÃ©s


Exemple : Compteur global
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Avant :
    counter:global:views â†’ INCR 100k/sec â†’ Node A saturÃ©


AprÃ¨s :
    counter:global:views:shard:0 â†’ Node A
    counter:global:views:shard:1 â†’ Node B
    counter:global:views:shard:2 â†’ Node C
    ...
    counter:global:views:shard:9 â†’ Node C


ImplÃ©mentation :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import hashlib

NUM_SHARDS = 10

def incr_sharded_counter(base_key, client_id):
    """IncrÃ©menter compteur shardÃ©"""
    # DÃ©terminer shard basÃ© sur client_id
    shard = int(hashlib.md5(client_id.encode()).hexdigest(), 16) % NUM_SHARDS
    sharded_key = f"{base_key}:shard:{shard}"

    return redis_client.incr(sharded_key)

def get_total_counter(base_key):
    """Obtenir total en agrÃ©geant tous les shards"""
    total = 0
    for shard in range(NUM_SHARDS):
        sharded_key = f"{base_key}:shard:{shard}"
        value = redis_client.get(sharded_key)
        total += int(value) if value else 0
    return total

# Utilisation
incr_sharded_counter("counter:global:views", "user123")
incr_sharded_counter("counter:global:views", "user456")

total = get_total_counter("counter:global:views")
print(f"Total views: {total}")


Avantages :
â”œâ”€ Distribution parfaite de la charge
â”œâ”€ ScalabilitÃ© linÃ©aire
â””â”€ Chaque shard sur nÅ“ud diffÃ©rent

InconvÃ©nients :
â”œâ”€ Obtenir total nÃ©cessite N lectures
â”œâ”€ ComplexitÃ© accrue
â””â”€ Pas adaptÃ© Ã  tous les types de donnÃ©es


STRATÃ‰GIE 5 : CDN / EDGE CACHING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Pour contenu web statique ou semi-statique


    Clients
       â”‚
       â–¼
    CDN (Cloudflare, Fastly)
       â”‚
       â”œâ”€> Cache hit (99%) â†’ Retourne directement
       â”‚
       â””â”€> Cache miss (1%) â†’ Redis Cluster
                              â””â”€> Mise en cache CDN


Avantages :
â”œâ”€ RÃ©duit charge Redis de 99%
â”œâ”€ Latence ultra-faible (POP CDN proche du client)
â”œâ”€ Absorption pics de trafic
â””â”€ Protection DDoS

InconvÃ©nients :
â”œâ”€ CoÃ»t supplÃ©mentaire (CDN)
â”œâ”€ Staleness (cache CDN peut Ãªtre pÃ©rimÃ©)
â””â”€ Uniquement pour donnÃ©es publiques
```

### Solutions pour Big Keys

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              StratÃ©gies pour attÃ©nuer Big Keys              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


STRATÃ‰GIE 1 : FRAGMENTATION DE LA BIG KEY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Principe : Diviser une grande structure en plusieurs petites


Exemple : Liste de tous les utilisateurs
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Avant :
    users:all LIST [user1, user2, ..., user1000000]  # 1M Ã©lÃ©ments


AprÃ¨s :
    users:batch:0 LIST [user1, ..., user1000]        # 1k Ã©lÃ©ments
    users:batch:1 LIST [user1001, ..., user2000]
    ...
    users:batch:999 LIST [user999001, ..., user1000000]


ImplÃ©mentation :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

BATCH_SIZE = 1000

def add_user_fragmented(user_id):
    """Ajouter user dans batch appropriÃ©"""
    batch_id = user_id // BATCH_SIZE
    batch_key = f"users:batch:{batch_id}"
    redis_client.rpush(batch_key, user_id)

def get_all_users_fragmented():
    """RÃ©cupÃ©rer tous les users en itÃ©rant sur batches"""
    all_users = []
    batch_id = 0

    while True:
        batch_key = f"users:batch:{batch_id}"
        users = redis_client.lrange(batch_key, 0, -1)

        if not users:
            break

        all_users.extend(users)
        batch_id += 1

    return all_users


Exemple : Session utilisateur avec hash gigantesque
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Avant :
    session:user:123 HASH
    â”œâ”€ field1: value1
    â”œâ”€ field2: value2
    ...
    â””â”€ field100000: value100000  # 100k champs


AprÃ¨s :
    session:user:123:profile HASH (10 champs)
    session:user:123:settings HASH (50 champs)
    session:user:123:history HASH (dynamic, paginated)


Avantages :
â”œâ”€ OpÃ©rations individuelles plus rapides
â”œâ”€ FlexibilitÃ© (expiration diffÃ©rente par fragment)
â””â”€ Limite impact d'une opÃ©ration

InconvÃ©nients :
â”œâ”€ ComplexitÃ© accrue
â”œâ”€ RequÃªtes multiples si besoin de tout
â””â”€ Fragmentation Ã  gÃ©rer


STRATÃ‰GIE 2 : PAGINATION ET CURSEURS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Utiliser SCAN, HSCAN, SSCAN, ZSCAN au lieu de KEYS, HGETALL, etc.


Mauvais :
â”€â”€â”€â”€â”€â”€â”€â”€

# Retourne TOUS les membres (bloquant)
all_members = redis_client.smembers("users:all")  # 1M membres, bloque 5s


Bon :
â”€â”€â”€â”€

# ItÃ©ration par curseur (non-bloquant)
cursor = 0
members = []

while True:
    cursor, batch = redis_client.sscan("users:all", cursor, count=1000)
    members.extend(batch)

    if cursor == 0:
        break


Encore mieux : GÃ©nÃ©rateur Python
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def scan_set_members(key, batch_size=1000):
    """GÃ©nÃ©rateur qui yield members par batch"""
    cursor = 0

    while True:
        cursor, batch = redis_client.sscan(key, cursor, count=batch_size)

        for member in batch:
            yield member

        if cursor == 0:
            break

# Utilisation
for member in scan_set_members("users:all"):
    process(member)  # Traiter un par un, pas de blocage


Avantages :
â”œâ”€ Pas de blocage du serveur
â”œâ”€ MÃ©moire constante cÃ´tÃ© client
â””â”€ Autres clients non impactÃ©s

InconvÃ©nients :
â”œâ”€ Plus lent si besoin de tout
â””â”€ Pas de snapshot atomique


STRATÃ‰GIE 3 : COMPRESSION DES DONNÃ‰ES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Compresser les grandes valeurs avant stockage


import gzip
import redis

def set_compressed(key, value):
    """Stocker valeur compressÃ©e"""
    compressed = gzip.compress(value.encode())
    redis_client.set(key, compressed)

def get_compressed(key):
    """RÃ©cupÃ©rer et dÃ©compresser"""
    compressed = redis_client.get(key)
    if compressed:
        return gzip.decompress(compressed).decode()
    return None

# Exemple
large_html = "<html>..." * 1000  # 1 MB
set_compressed("cache:page:home", large_html)

# StockÃ© comme ~100 KB (ratio 10:1)


Avantages :
â”œâ”€ RÃ©duction mÃ©moire significative (50-90%)
â”œâ”€ RÃ©duction bande passante rÃ©seau
â””â”€ Plus de clÃ©s dans la mÃ©moire disponible

InconvÃ©nients :
â”œâ”€ CPU pour compression/dÃ©compression
â”œâ”€ Latence lÃ©gÃ¨rement accrue
â””â”€ Pas adaptÃ© Ã  toutes les donnÃ©es


STRATÃ‰GIE 4 : EXTERNALISATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Stocker grandes valeurs en dehors de Redis


Avant :
    cache:video:123 STRING [50 MB de donnÃ©es binaires]


AprÃ¨s :
    cache:video:123 STRING "s3://bucket/videos/123.mp4"
    â””â”€> Pointeur vers S3


ImplÃ©mentation :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import boto3
import redis

s3 = boto3.client('s3')
BUCKET = 'video-cache'

def set_large_value(key, value, threshold_mb=10):
    """Stocker en Redis si petit, S3 si gros"""
    size_mb = len(value) / 1024 / 1024

    if size_mb > threshold_mb:
        # Uploader vers S3
        s3_key = f"redis-overflow/{key}"
        s3.put_object(Bucket=BUCKET, Key=s3_key, Body=value)

        # Stocker pointeur dans Redis
        pointer = f"s3://{BUCKET}/{s3_key}"
        redis_client.set(key, pointer)
    else:
        # Stocker directement dans Redis
        redis_client.set(key, value)

def get_large_value(key):
    """RÃ©cupÃ©rer de Redis ou S3"""
    value = redis_client.get(key)

    if value.startswith(b's3://'):
        # C'est un pointeur S3
        bucket, s3_key = value.decode().replace('s3://', '').split('/', 1)
        response = s3.get_object(Bucket=bucket, Key=s3_key)
        return response['Body'].read()
    else:
        # Valeur directe
        return value


Avantages :
â”œâ”€ Redis garde taille raisonnable
â”œâ”€ S3 optimisÃ© pour gros objets
â”œâ”€ CoÃ»t de stockage rÃ©duit (S3 moins cher)
â””â”€ ScalabilitÃ© illimitÃ©e

InconvÃ©nients :
â”œâ”€ Latence accrue (appel S3)
â”œâ”€ ComplexitÃ©
â”œâ”€ CoÃ»t transfert S3
â””â”€ DÃ©pendance externe


STRATÃ‰GIE 5 : LAZY DELETION (UNLINK)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Utiliser UNLINK au lieu de DEL pour big keys


# Mauvais (bloque le serveur)
redis_client.delete("big_list")  # Peut bloquer 5s


# Bon (asynchrone)
redis_client.unlink("big_list")  # Retourne immÃ©diatement


Redis 4.0+ : Background thread libÃ¨re la mÃ©moire


ImplÃ©mentation dans application :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def safe_delete_key(key):
    """Supprimer clÃ© de maniÃ¨re sÃ»re"""
    # VÃ©rifier taille
    size_mb = redis_client.memory_usage(key) / 1024 / 1024

    if size_mb > 10:
        # Big key â†’ UNLINK
        print(f"Using UNLINK for big key {key} ({size_mb} MB)")
        return redis_client.unlink(key)
    else:
        # Small key â†’ DEL standard
        return redis_client.delete(key)


Avantages :
â”œâ”€ Pas de blocage
â”œâ”€ Simple Ã  utiliser
â””â”€ Natif Redis (pas de dÃ©pendance)

Limitations :
â”œâ”€ Redis 4.0+ uniquement
â””â”€ N'empÃªche pas crÃ©ation de big keys


STRATÃ‰GIE 6 : TTL ET EXPIRATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Limiter la croissance avec expiration automatique


# Mauvais : Liste sans limite
redis_client.rpush("events:user:123", event)
# Liste grandit indÃ©finiment


# Bon : LTRIM + TTL
redis_client.rpush("events:user:123", event)
redis_client.ltrim("events:user:123", -1000, -1)  # Garder 1000 derniers
redis_client.expire("events:user:123", 86400)  # Expire aprÃ¨s 24h


# Alternative : ZADD avec score timestamp + ZREMRANGEBYSCORE
now = time.time()
redis_client.zadd("events:user:123", {event: now})

# Supprimer events > 7 jours
week_ago = now - 7 * 86400
redis_client.zremrangebyscore("events:user:123", 0, week_ago)


Avantages :
â”œâ”€ Limite automatique de taille
â”œâ”€ Pas de maintenance manuelle
â””â”€ PrÃ©vient croissance infinie

InconvÃ©nients :
â”œâ”€ Perte de donnÃ©es anciennes
â””â”€ Logique de trim Ã  implÃ©menter
```

## ProcÃ©dures de rÃ©solution en production

### ProcÃ©dure d'urgence : Hot Key critique

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROCÃ‰DURE D'URGENCE : HOT KEY SATURANT UN NÅ’UD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# SYMPTÃ”MES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â€¢ Node B Ã  95% CPU, autres nÅ“uds Ã  10%
# â€¢ Latence Ã©levÃ©e sur certaines requÃªtes (100ms+)
# â€¢ Timeouts clients
# â€¢ Logs montrent GET rÃ©pÃ©tÃ© sur mÃªme clÃ©


# Ã‰TAPE 1 : IDENTIFIER LA HOT KEY (5 minutes)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Activer monitoring sur le nÅ“ud saturÃ©
redis-cli -h 192.168.1.11 --hotkeys

# Ou MONITOR (trÃ¨s court, <30 secondes)
redis-cli -h 192.168.1.11 MONITOR | head -1000 > /tmp/commands.log
grep -oP '"[^"]+"' /tmp/commands.log | sort | uniq -c | sort -nr | head -5

# Supposons identification : trending:post:viral


# Ã‰TAPE 2 : MITIGATION IMMÃ‰DIATE (2 minutes)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Option A : Activer cache local cÃ´tÃ© application
# DÃ©ployer configuration d'urgence avec TTL court

# Exemple config (injecter via feature flag)
ENABLE_LOCAL_CACHE=true
LOCAL_CACHE_TTL_SECONDS=10
LOCAL_CACHE_KEYS="trending:post:viral"

# Option B : RÃ©pliquer la hot key manuellement

# Obtenir valeur
VALUE=$(redis-cli -h 192.168.1.11 GET trending:post:viral)

# CrÃ©er replicas sur autres nÅ“uds (avec hash tags pour forcer slots)
redis-cli -h 192.168.1.10 SET "trending:post:viral:1" "$VALUE"
redis-cli -h 192.168.1.11 SET "trending:post:viral:2" "$VALUE"
redis-cli -h 192.168.1.12 SET "trending:post:viral:3" "$VALUE"

# Mettre Ã  jour application pour load balance
# (nÃ©cessite dÃ©ploiement rapide ou feature flag)


# Ã‰TAPE 3 : VÃ‰RIFICATION (1 minute)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Surveiller charge CPU du nÅ“ud
watch -n 1 'redis-cli -h 192.168.1.11 INFO CPU | grep used_cpu_sys'

# Surveiller latence
redis-cli -h 192.168.1.11 --latency-history

# AprÃ¨s mitigation, charge devrait diminuer


# Ã‰TAPE 4 : SOLUTION PERMANENTE (post-incident)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# 1. Analyser pourquoi cette clÃ© est devenue hot
#    - Ã‰vÃ©nement externe (trending topic) ?
#    - Bug applicatif (polling agressif) ?
#    - Attaque DDoS ?

# 2. ImplÃ©menter solution appropriÃ©e
#    - Cache local avec TTL
#    - CDN pour contenu public
#    - Rate limiting cÃ´tÃ© application
#    - RÃ©plication permanente

# 3. Ajouter monitoring proactif
#    - Alertes sur dÃ©sÃ©quilibre de charge
#    - Dashboard visualisant top keys par trafic

# 4. Post-mortem
#    - Documenter incident
#    - Partager learnings
#    - AmÃ©liorer runbook


# Ã‰TAPE 5 : COMMUNICATION (durant incident)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Template de communication
cat <<EOF
INCIDENT: Hot key causing Redis node saturation

Status: INVESTIGATING / MITIGATING / RESOLVED
Start: $(date)
Impact: Increased latency on requests to Node B

Actions taken:
- [12:00] Hot key identified: trending:post:viral
- [12:03] Local cache enabled on application servers
- [12:05] Load balanced, Node B CPU back to normal

Next steps:
- Monitor for recurrence
- Implement permanent solution
- Schedule post-mortem

Updates: Every 15 minutes or when status changes
EOF
```

### ProcÃ©dure d'urgence : Big Key bloquant

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROCÃ‰DURE D'URGENCE : BIG KEY BLOQUANT LE SERVEUR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# SYMPTÃ”MES
# â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â€¢ Timeouts gÃ©nÃ©ralisÃ©s sur un nÅ“ud
# â€¢ Slowlog montre commandes prenant 1s+
# â€¢ Network bandwidth saturÃ© pÃ©riodiquement
# â€¢ Une commande GET/HGETALL/LRANGE prend Ã©normÃ©ment de temps


# Ã‰TAPE 1 : IDENTIFIER LA BIG KEY (3 minutes)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# VÃ©rifier slowlog
redis-cli -h 192.168.1.10 SLOWLOG GET 10

# Example output :
# 1) "GET cache:homepage 12345678"  # 5000000 microseconds (5 seconds)

# Confirmer que c'est une big key
redis-cli -h 192.168.1.10 MEMORY USAGE cache:homepage
# (integer) 104857600  # 100 MB !


# Ã‰TAPE 2 : Ã‰VALUER L'IMPACT (1 minute)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# FrÃ©quence d'accÃ¨s
redis-cli -h 192.168.1.10 OBJECT FREQ cache:homepage
# Ã‰levÃ© = problÃ¨me critique

# VÃ©rifier si d'autres big keys
redis-cli -h 192.168.1.10 --bigkeys -i 0.1

# Type de la clÃ©
TYPE=$(redis-cli -h 192.168.1.10 TYPE cache:homepage)
echo "Type: $TYPE"


# Ã‰TAPE 3 : MITIGATION IMMÃ‰DIATE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Option A : Si la clÃ© peut Ãªtre supprimÃ©e (cache invalide)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ATTENTION : NE PAS utiliser DEL (va bloquer encore plus)
# Utiliser UNLINK (asynchrone)
redis-cli -h 192.168.1.10 UNLINK cache:homepage

# VÃ©rifier suppression
redis-cli -h 192.168.1.10 EXISTS cache:homepage
# (integer) 0  âœ“


# Option B : Si la clÃ© est importante (ne peut pas Ãªtre supprimÃ©e)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Temporairement, dÃ©sactiver l'application qui accÃ¨de Ã  cette clÃ©
# Ou implÃ©menter circuit breaker pour cette clÃ© spÃ©cifique

# Config d'urgence dans l'application :
BLOCKED_KEYS="cache:homepage"
# Application skip l'accÃ¨s Ã  cette clÃ© et utilise fallback


# Option C : Migration vers stockage externe
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Si temps le permet, migrer vers S3/blob storage
aws s3 cp /tmp/homepage.html s3://cache-bucket/homepage.html

# Remplacer dans Redis par un pointeur
redis-cli -h 192.168.1.10 SET cache:homepage:pointer "s3://cache-bucket/homepage.html"

# Mettre Ã  jour application pour fetch depuis S3


# Ã‰TAPE 4 : SOLUTION PERMANENTE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Selon le type de big key :

# Pour STRING (blob) :
# â”œâ”€ Compression (gzip)
# â”œâ”€ CDN pour contenu statique
# â””â”€ S3 pour trÃ¨s gros objets

# Pour LIST/SET/HASH :
# â”œâ”€ Fragmentation (batching)
# â”œâ”€ Pagination avec SCAN/HSCAN
# â””â”€ TTL + LTRIM pour limiter croissance

# Pour ZSET (leaderboard) :
# â”œâ”€ ZREMRANGEBYRANK pour limiter taille
# â””â”€ Fragmentation temporelle (daily/weekly boards)


# Ã‰TAPE 5 : PRÃ‰VENTION FUTURE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# 1. Monitoring proactif
cat > /usr/local/bin/check-big-keys.sh <<'EOF'
#!/bin/bash
THRESHOLD_MB=10

redis-cli --bigkeys -i 0.01 | grep -E "string|list|set|hash|zset" | while read line; do
    key=$(echo "$line" | awk '{print $4}')
    size=$(redis-cli MEMORY USAGE "$key")
    size_mb=$(awk "BEGIN {print $size/1024/1024}")

    if (( $(echo "$size_mb > $THRESHOLD_MB" | bc -l) )); then
        echo "ALERT: Big key detected: $key ($size_mb MB)"
        # Envoyer alerte
    fi
done
EOF

chmod +x /usr/local/bin/check-big-keys.sh

# Cron toutes les 5 minutes
echo "*/5 * * * * /usr/local/bin/check-big-keys.sh" | crontab -


# 2. Limites au niveau application
# Rejeter Ã©critures qui crÃ©eraient big keys

def safe_set(key, value, max_size_mb=10):
    size_mb = len(value) / 1024 / 1024

    if size_mb > max_size_mb:
        raise ValueError(f"Value too large: {size_mb} MB > {max_size_mb} MB limit")

    return redis_client.set(key, value)


# 3. Documentation et training
# Former l'Ã©quipe sur :
# â”œâ”€ Dangers des big keys
# â”œâ”€ Utilisation de SCAN vs KEYS
# â”œâ”€ UNLINK vs DEL
# â””â”€ Patterns de fragmentation
```

### Migration d'une big key vers fragmentation

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MIGRATION : BIG KEY â†’ FRAGMENTATION (ZERO DOWNTIME)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import redis
import time

# Configuration
REDIS_HOST = "192.168.1.10"
OLD_KEY = "users:all"  # Big LIST avec 1M Ã©lÃ©ments
NEW_KEY_PREFIX = "users:batch"
BATCH_SIZE = 1000

r = redis.Redis(host=REDIS_HOST, decode_responses=True)


def migrate_big_list_to_batches():
    """
    Migrer une grande liste vers plusieurs petites listes
    Sans bloquer le serveur
    """

    print("=== Migration : Big List â†’ Batched Lists ===")

    # Ã‰TAPE 1 : VÃ©rifier la taille
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    total_elements = r.llen(OLD_KEY)
    print(f"Total elements in {OLD_KEY}: {total_elements}")

    if total_elements == 0:
        print("List is empty, nothing to migrate")
        return

    # Ã‰TAPE 2 : CrÃ©er les batches progressivement
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    batch_id = 0
    migrated_count = 0

    while True:
        # Lire un batch (non-destructif)
        start_idx = batch_id * BATCH_SIZE
        end_idx = start_idx + BATCH_SIZE - 1

        batch = r.lrange(OLD_KEY, start_idx, end_idx)

        if not batch:
            break  # Plus d'Ã©lÃ©ments

        # Ã‰crire le batch
        new_key = f"{NEW_KEY_PREFIX}:{batch_id}"
        r.rpush(new_key, *batch)

        migrated_count += len(batch)
        batch_id += 1

        print(f"Migrated batch {batch_id}: {len(batch)} elements ({migrated_count}/{total_elements})")

        # Pause pour ne pas saturer (5ms)
        time.sleep(0.005)

    print(f"âœ“ Migration complete: {batch_id} batches created")

    # Ã‰TAPE 3 : Double Ã©criture (application Ã©crit dans les deux)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nâš ï¸  Action required:")
    print("1. Deploy application update to write to BOTH old and new keys")
    print("2. Wait for deployment (ensure no data loss)")
    print("3. Run verification (see verify_migration)")
    print("4. Switch reads to new keys")
    print("5. Stop writing to old key")
    print("6. Delete old key")


def verify_migration():
    """
    VÃ©rifier que la migration est complÃ¨te et cohÃ©rente
    """
    print("\n=== Verification ===")

    # Compter Ã©lÃ©ments dans old key
    old_count = r.llen(OLD_KEY)
    print(f"Old key ({OLD_KEY}): {old_count} elements")

    # Compter Ã©lÃ©ments dans new batches
    batch_id = 0
    new_count = 0

    while True:
        new_key = f"{NEW_KEY_PREFIX}:{batch_id}"
        batch_len = r.llen(new_key)

        if batch_len == 0:
            break

        new_count += batch_len
        batch_id += 1

    print(f"New keys ({NEW_KEY_PREFIX}:*): {new_count} elements across {batch_id} batches")

    # VÃ©rifier cohÃ©rence
    if old_count == new_count:
        print("âœ“ Migration verified: counts match")
        return True
    else:
        print(f"âœ— Mismatch: old={old_count}, new={new_count}")
        return False


def delete_old_key_safely():
    """
    Supprimer l'ancienne big key de maniÃ¨re sÃ»re
    """
    print("\n=== Deleting old key ===")

    # VÃ©rifier une derniÃ¨re fois
    if not verify_migration():
        print("âœ— Verification failed, aborting deletion")
        return

    # Utiliser UNLINK (asynchrone)
    result = r.unlink(OLD_KEY)

    if result:
        print(f"âœ“ Old key {OLD_KEY} deleted (unlinked)")
    else:
        print(f"Key {OLD_KEY} not found or already deleted")


# EXÃ‰CUTION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    # Phase 1 : Migration
    migrate_big_list_to_batches()

    # Phase 2 : Attendre dÃ©ploiement application avec double Ã©criture
    input("\nPress Enter after deploying application with dual writes...")

    # Phase 3 : VÃ©rification
    if verify_migration():
        # Phase 4 : Basculer lectures vers new keys
        input("\nPress Enter after switching reads to new keys...")

        # Phase 5 : Supprimer old key
        delete_old_key_safely()

        print("\n=== Migration Complete ===")
        print("Next steps:")
        print("1. Monitor for any issues")
        print("2. Remove dual-write code after 24-48h")
        print("3. Update documentation")
```

## Best practices et recommandations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Best Practices - Hot Keys & Big Keys           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ DESIGN PRÃ‰VENTIF                                            â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                            â”‚
â”‚                                                             â”‚
â”‚ âœ“ ModÃ©liser donnÃ©es pour Ã©viter hot/big keys dÃ¨s la conception
â”‚ âœ“ Utiliser hash tags strategiquement pour fragmentation     â”‚
â”‚ âœ“ Limiter taille des collections (LTRIM, ZREMRANGEBYRANK)   â”‚
â”‚ âœ“ TTL systÃ©matique sur donnÃ©es temporaires                  â”‚
â”‚ âœ“ Compression pour grandes valeurs (gzip)                   â”‚
â”‚ âœ“ Cache local pour config globale / donnÃ©es read-heavy      â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ MONITORING PROACTIF                                         â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                         â”‚
â”‚                                                             â”‚
â”‚ âœ“ Scan quotidien avec --bigkeys                             â”‚
â”‚ âœ“ Alertes sur dÃ©sÃ©quilibre de charge entre nÅ“uds            â”‚
â”‚ âœ“ MÃ©triques : p99 latency, network I/O par nÅ“ud             â”‚
â”‚ âœ“ Dashboard Grafana avec top keys par taille/accÃ¨s          â”‚
â”‚ âœ“ Slowlog monitoring continu                                â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ OPÃ‰RATIONS SÃ‰CURISÃ‰ES                                       â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                      â”‚
â”‚                                                             â”‚
â”‚ âœ“ UNLINK au lieu de DEL pour big keys                       â”‚
â”‚ âœ“ SCAN au lieu de KEYS / SMEMBERS / HGETALL                 â”‚
â”‚ âœ“ Pagination (HSCAN, SSCAN, ZSCAN) pour itÃ©rations          â”‚
â”‚ âœ“ Pipeline pour rÃ©duire RTT sur opÃ©rations multiples        â”‚
â”‚ âœ“ Ã‰viter MONITOR en production (trÃ¨s coÃ»teux)               â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ ARCHITECTURE RÃ‰SILIENTE                                     â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                     â”‚
â”‚                                                             â”‚
â”‚ âœ“ Cache local (application-side) pour hot keys              â”‚
â”‚ âœ“ CDN pour contenu public statique/semi-statique            â”‚
â”‚ âœ“ Circuit breaker pour clÃ©s problÃ©matiques                  â”‚
â”‚ âœ“ Fallback mechanisms (degraded mode)                       â”‚
â”‚ âœ“ Rate limiting cÃ´tÃ© application si nÃ©cessaire              â”‚
â”‚                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚ DOCUMENTATION ET FORMATION                                  â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                              â”‚
â”‚                                                             â”‚
â”‚ âœ“ Runbooks pour incidents hot/big keys                      â”‚
â”‚ âœ“ Formation Ã©quipe sur patterns anti-patterns               â”‚
â”‚ âœ“ Code reviews pour identifier risques                      â”‚
â”‚ âœ“ Post-mortems aprÃ¨s chaque incident                        â”‚
â”‚ âœ“ Partage de learnings inter-Ã©quipes                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Conclusion

La gestion des Hot Keys et Big Keys dans Redis Cluster est un dÃ©fi permanent qui nÃ©cessite une approche multidimensionnelle combinant prÃ©vention, dÃ©tection et rÃ©action. Ces problÃ¨mes sont particuliÃ¨rement critiques dans un environnement distribuÃ© car ils crÃ©ent des dÃ©sÃ©quilibres qui ne peuvent Ãªtre rÃ©solus simplement en ajoutant des nÅ“uds.

Les points essentiels Ã  retenir :

1. **PrÃ©vention** : Conception applicative Ã©vitant crÃ©ation de hot/big keys
2. **DÃ©tection prÃ©coce** : Monitoring continu avec alertes
3. **RÃ©action rapide** : Runbooks et procÃ©dures d'urgence testÃ©es
4. **Solutions durables** : Fragmentation, cache local, CDN selon contexte
5. **AmÃ©lioration continue** : Post-mortems et partage de connaissances

Une stratÃ©gie efficace combine plusieurs techniques :
- Cache local pour hot keys de lecture
- Fragmentation pour big keys
- Monitoring proactif avec alertes
- Runbooks pour incidents
- Architecture rÃ©siliente avec fallbacks

En maÃ®trisant ces aspects, il devient possible de maintenir un cluster Redis performant et stable mÃªme face Ã  des patterns d'accÃ¨s non uniformes ou des donnÃ©es volumineuses.

---

**Points clÃ©s Ã  retenir :**

- **Hot Key** : Taux d'accÃ¨s disproportionnÃ© â†’ saturation d'un nÅ“ud
- **Big Key** : Taille excessive â†’ blocage du serveur (single-threaded)
- **DÃ©tection** : --hotkeys, --bigkeys, MONITOR, slowlog, instrumentation
- **Impact cluster** : DÃ©sÃ©quilibre, impossible Ã  rÃ©soudre par ajout de nÅ“uds
- **Solutions hot keys** : Cache local, rÃ©plication, CDN, sharding
- **Solutions big keys** : Fragmentation, UNLINK, pagination (SCAN), compression
- **UNLINK vs DEL** : UNLINK est asynchrone, crucial pour big keys
- **Monitoring** : Prometheus, Grafana, alertes sur dÃ©sÃ©quilibre

La prochaine section (11.9) explorera la rÃ©plication cross-datacenter pour la haute disponibilitÃ© gÃ©ographique.

â­ï¸ [Cross-datacenter replication (Active-Active vs Active-Passive)](/11-architecture-distribuee-scaling/09-cross-datacenter-replication.md)
