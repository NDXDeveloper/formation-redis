ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 11.3 Distribution des donnÃ©es : Hash Slots (0-16383)

## Introduction

Le mÃ©canisme de distribution des donnÃ©es dans Redis Cluster repose sur un concept Ã©lÃ©gant et dÃ©terministe : les **hash slots**. Contrairement Ã  d'autres systÃ¨mes distribuÃ©s qui utilisent du consistent hashing avec des anneaux virtuels, Redis implÃ©mente un modÃ¨le de partitionnement fixe basÃ© sur 16384 slots prÃ©dÃ©finis. Cette approche offre une prÃ©visibilitÃ© totale et simplifie considÃ©rablement les opÃ©rations de maintenance.

## Architecture des Hash Slots

### Le modÃ¨le de partitionnement

Redis Cluster divise l'espace de clÃ©s en **16384 hash slots** (numÃ©rotÃ©s de 0 Ã  16383). Chaque clÃ© de la base de donnÃ©es est assignÃ©e de maniÃ¨re dÃ©terministe Ã  l'un de ces slots via une fonction de hachage.

```
Espace total : 16384 slots (0-16383)
Fonction : HASH_SLOT = CRC16(key) mod 16384
```

#### Pourquoi 16384 slots ?

Ce nombre n'est pas arbitraire. Il reprÃ©sente un compromis optimal entre plusieurs contraintes techniques :

1. **Taille du bitmap de slots** : 16384 slots = 2048 octets (2KB)
   - Chaque nÅ“ud maintient un bitmap indiquant quels slots il possÃ¨de
   - 2KB est suffisamment petit pour Ãªtre transmis efficacement via le protocole Gossip
   - Permet des heartbeats rapides sans surcharge rÃ©seau

2. **GranularitÃ© de distribution** :
   - Avec 16384 slots, un cluster de 100 nÅ“uds peut avoir ~164 slots par nÅ“ud
   - GranularitÃ© suffisante pour un rÃ©Ã©quilibrage prÃ©cis
   - Pas de surcharge computationnelle lors des calculs de slot

3. **Limite pratique** :
   - Redis recommande un maximum de ~1000 nÅ“uds par cluster
   - 16384 slots permettent une distribution Ã©quitable mÃªme avec ce nombre de nÅ“uds
   - Au-delÃ , le protocole Gossip devient inefficace

### SchÃ©ma de distribution basique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Espace de Hash Slots                     â”‚
â”‚                        (0 - 16383)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NÅ“ud A      â”‚    â”‚  NÅ“ud B      â”‚    â”‚  NÅ“ud C      â”‚
â”‚              â”‚    â”‚              â”‚    â”‚              â”‚
â”‚ Slots:       â”‚    â”‚ Slots:       â”‚    â”‚ Slots:       â”‚
â”‚ 0-5460       â”‚    â”‚ 5461-10922   â”‚    â”‚ 10923-16383  â”‚
â”‚              â”‚    â”‚              â”‚    â”‚              â”‚
â”‚ (~33.3%)     â”‚    â”‚ (~33.3%)     â”‚    â”‚ (~33.4%)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Algorithme de calcul de Hash Slot

### Fonction de hachage CRC16

Redis utilise CRC16 (Cyclic Redundancy Check 16-bit) pour calculer le slot d'une clÃ© :

```
HASH_SLOT = CRC16(key) & 16383
```

L'opÃ©ration `& 16383` (Ã©quivalent Ã  `mod 16384`) est une optimisation bitwise car 16384 = 2^14.

### ImplÃ©mentation du calcul

Voici la logique interne simplifiÃ©e :

```c
unsigned int keyHashSlot(char *key, int keylen) {
    int s, e;

    // Recherche des marqueurs {hashtag}
    for (s = 0; s < keylen; s++)
        if (key[s] == '{') break;

    if (s == keylen) {
        // Pas de hashtag, utiliser la clÃ© complÃ¨te
        return crc16(key, keylen) & 16383;
    }

    // Hashtag trouvÃ©, rechercher la fermeture
    for (e = s+1; e < keylen; e++)
        if (key[e] == '}') break;

    if (e == keylen || e == s+1) {
        // Hashtag invalide, utiliser la clÃ© complÃ¨te
        return crc16(key, keylen) & 16383;
    }

    // Utiliser uniquement la partie entre { et }
    return crc16(key+s+1, e-s-1) & 16383;
}
```

### Exemples de calcul

```bash
# ClÃ© simple
user:1000 â†’ CRC16("user:1000") & 16383 = 5798

# Avec hashtag
user:{1000}:profile â†’ CRC16("1000") & 16383 = 5649
user:{1000}:settings â†’ CRC16("1000") & 16383 = 5649  # MÃªme slot !

# ClÃ©s multiples pour transaction
{user:1000}:profile
{user:1000}:friends
{user:1000}:posts
# Toutes mappÃ©es au mÃªme slot via le hashtag "user:1000"
```

## Hash Tags : ContrÃ´le de la co-localisation

### Principe des hash tags

Les hash tags permettent de forcer plusieurs clÃ©s Ã  Ãªtre assignÃ©es au mÃªme slot, essentiel pour :
- Les opÃ©rations multi-clÃ©s (MGET, MSET)
- Les transactions (MULTI/EXEC)
- Les scripts Lua
- Les opÃ©rations ensemblistes (SUNION, SINTER)

### Syntaxe et rÃ¨gles

```
RÃ¨gle : Seule la partie entre { et } est utilisÃ©e pour le calcul du hash

Exemples valides :
{user1000}:profile         â†’ hash sur "user1000"
{user1000}:friends         â†’ hash sur "user1000"
user:{1000}:sessions       â†’ hash sur "1000"
{invoice:2024:Q1}:total    â†’ hash sur "invoice:2024:Q1"

Exemples invalides (pas de hashtag dÃ©tectÃ©) :
user{1000:profile          â†’ hash sur toute la clÃ©
user:1000}:profile         â†’ hash sur toute la clÃ©
user:{}:profile            â†’ hash sur toute la clÃ© (vide)
user::profile              â†’ hash sur toute la clÃ©
```

### StratÃ©gies de naming avec hash tags

```
1. Par entitÃ© mÃ©tier :
   {order:12345}:items
   {order:12345}:customer
   {order:12345}:shipping

2. Par tenant (multi-tenancy) :
   {tenant:acme}:users:list
   {tenant:acme}:config
   {tenant:acme}:sessions

3. Par fenÃªtre temporelle :
   {analytics:2024-12-11}:pageviews
   {analytics:2024-12-11}:conversions
   {analytics:2024-12-11}:revenue

4. Par shard manuel :
   {shard:0}:user:1000
   {shard:1}:user:1001
   {shard:2}:user:1002
```

## Distribution et assignation des slots

### Architecture d'un cluster minimal (3 masters)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Redis Cluster (3 nÅ“uds)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

NÅ“ud Master A (192.168.1.10:6379)
â”œâ”€ Node ID: a1b2c3d4...
â”œâ”€ Slots assignÃ©s: 0-5460 (5461 slots)
â””â”€ Replica: NÅ“ud D (192.168.1.13:6379)

NÅ“ud Master B (192.168.1.11:6379)
â”œâ”€ Node ID: e5f6g7h8...
â”œâ”€ Slots assignÃ©s: 5461-10922 (5462 slots)
â””â”€ Replica: NÅ“ud E (192.168.1.14:6379)

NÅ“ud Master C (192.168.1.12:6379)
â”œâ”€ Node ID: i9j0k1l2...
â”œâ”€ Slots assignÃ©s: 10923-16383 (5461 slots)
â””â”€ Replica: NÅ“ud F (192.168.1.15:6379)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Principe : Chaque master possÃ¨de une plage continue de slots   â”‚
â”‚  Total : 16384 slots rÃ©partis Ã©quitablement                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mapping slots â†’ nÅ“uds

Chaque nÅ“ud du cluster maintient une table de correspondance :

```
Slot â†’ Node mapping table (maintenue en mÃ©moire)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Slot 0-5460      â†’ Node A (a1b2c3d4...)
Slot 5461-10922  â†’ Node B (e5f6g7h8...)
Slot 10923-16383 â†’ Node C (i9j0k1l2...)

Cette table est synchronisÃ©e via le protocole Gossip
et mise Ã  jour lors de :
- Ajout/suppression de nÅ“uds
- Resharding
- Failover
```

### VÃ©rification de la distribution

```bash
# Voir la distribution des slots sur tous les nÅ“uds
redis-cli --cluster check 192.168.1.10:6379

# Sortie typique :
192.168.1.10:6379 (a1b2c3d4...) -> 5461 keys | 5461 slots | 1 slaves
192.168.1.11:6379 (e5f6g7h8...) -> 5462 keys | 5462 slots | 1 slaves
192.168.1.12:6379 (i9j0k1l2...) -> 5461 keys | 5461 slots | 1 slaves

[OK] All 16384 slots covered.
```

## ProcÃ©dures de maintenance des slots

### 1. Visualisation de l'Ã©tat des slots

#### VÃ©rifier les slots d'un nÅ“ud spÃ©cifique

```bash
# Se connecter Ã  un nÅ“ud
redis-cli -h 192.168.1.10 -p 6379

# Voir les slots assignÃ©s au nÅ“ud courant
127.0.0.1:6379> CLUSTER SLOTS

# Sortie : Liste des plages de slots avec leurs nÅ“uds responsables
1) 1) (integer) 0           # DÃ©but de plage
   2) (integer) 5460        # Fin de plage
   3) 1) "192.168.1.10"     # IP du master
      2) (integer) 6379     # Port du master
      3) "a1b2c3d4..."      # Node ID
   4) 1) "192.168.1.13"     # IP de la replica
      2) (integer) 6379     # Port de la replica
      3) "d4e5f6g7..."      # Node ID replica
```

#### Obtenir les informations dÃ©taillÃ©es

```bash
# Info sur les slots du nÅ“ud local
127.0.0.1:6379> CLUSTER INFO
cluster_state:ok
cluster_slots_assigned:16384
cluster_slots_ok:16384
cluster_slots_pfail:0
cluster_slots_fail:0
cluster_known_nodes:6
cluster_size:3
cluster_current_epoch:6
cluster_my_epoch:1

# Voir tous les nÅ“uds et leurs slots
127.0.0.1:6379> CLUSTER NODES
a1b2c3d4... 192.168.1.10:6379@16379 myself,master - 0 0 1 connected 0-5460
e5f6g7h8... 192.168.1.11:6379@16379 master - 0 1623456789 2 connected 5461-10922
i9j0k1l2... 192.168.1.12:6379@16379 master - 0 1623456790 3 connected 10923-16383
```

### 2. Resharding : DÃ©placement de slots

Le resharding est le processus de dÃ©placement de slots d'un nÅ“ud Ã  un autre, nÃ©cessaire lors de :
- Ajout de nouveaux nÅ“uds
- Suppression de nÅ“uds
- RÃ©Ã©quilibrage de la charge

#### Processus de resharding

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Ã‰tapes du Resharding d'un Slot                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Phase 1 : PRÃ‰PARATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NÅ“ud Source              NÅ“ud Destination
(Master A)               (Master D - nouveau)
    â”‚                           â”‚
    â”‚  1. SETSLOT MIGRATING â”€â”€> â”‚
    â”‚                           â”‚ 2. SETSLOT IMPORTING
    â”‚                           â”‚

Phase 2 : MIGRATION DES CLÃ‰S
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚                           â”‚
    â”‚  3. Pour chaque clÃ© :     â”‚
    â”‚     â”œâ”€ DUMP key           â”‚
    â”‚     â”œâ”€ RESTORE â”€â”€â”€â”€â”€â”€â”€â”€â”€> â”‚
    â”‚     â””â”€ DEL key            â”‚
    â”‚                           â”‚

Phase 3 : FINALISATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚                           â”‚
    â”‚  4. SETSLOT NODE <dest>   â”‚
    â”‚                           â”‚
    â”‚  5. Propagation Gossip    â”‚
    â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•>â”‚
    â”‚         (tous nÅ“uds)      â”‚
    â”‚                           â”‚
```

#### Commandes de resharding manuel

```bash
# Ã‰tape 1 : Marquer le slot comme en cours de migration (sur source)
redis-cli -h 192.168.1.10 -p 6379
127.0.0.1:6379> CLUSTER SETSLOT 8000 MIGRATING i9j0k1l2-destination-node-id

# Ã‰tape 2 : Marquer le slot comme en cours d'import (sur destination)
redis-cli -h 192.168.1.12 -p 6379
127.0.0.1:6379> CLUSTER SETSLOT 8000 IMPORTING a1b2c3d4-source-node-id

# Ã‰tape 3 : Migration des clÃ©s une par une
redis-cli -h 192.168.1.10 -p 6379
127.0.0.1:6379> CLUSTER GETKEYSINSLOT 8000 1000
1) "user:5432"
2) "session:abc123"
# Pour chaque clÃ© :
127.0.0.1:6379> MIGRATE 192.168.1.12 6379 "user:5432" 0 5000

# Ã‰tape 4 : Finaliser la migration (sur tous les nÅ“uds)
127.0.0.1:6379> CLUSTER SETSLOT 8000 NODE i9j0k1l2-destination-node-id
```

#### Resharding automatisÃ© avec redis-cli

```bash
# Resharding interactif
redis-cli --cluster reshard 192.168.1.10:6379

# Resharding automatique : dÃ©placer 1000 slots vers un nÅ“ud
redis-cli --cluster reshard 192.168.1.10:6379 \
    --cluster-from a1b2c3d4-source-node-id \
    --cluster-to i9j0k1l2-dest-node-id \
    --cluster-slots 1000 \
    --cluster-yes

# RÃ©Ã©quilibrage automatique de tous les slots
redis-cli --cluster rebalance 192.168.1.10:6379 \
    --cluster-threshold 2 \
    --cluster-use-empty-masters
```

### 3. Ajout d'un nÅ“ud avec redistribution

#### ProcÃ©dure complÃ¨te

```bash
# Ã‰tape 1 : Ajouter le nouveau nÅ“ud au cluster
redis-cli --cluster add-node 192.168.1.15:6379 192.168.1.10:6379

# Ã€ ce stade, le nouveau nÅ“ud ne possÃ¨de aucun slot

# Ã‰tape 2 : VÃ©rifier l'Ã©tat
redis-cli --cluster check 192.168.1.10:6379

# Sortie :
# 192.168.1.15:6379 (m4n5o6p7...) -> 0 keys | 0 slots | 0 slaves  â† Nouveau
# 192.168.1.10:6379 (a1b2c3d4...) -> 5461 keys | 5461 slots | 1 slaves
# 192.168.1.11:6379 (e5f6g7h8...) -> 5462 keys | 5462 slots | 1 slaves
# 192.168.1.12:6379 (i9j0k1l2...) -> 5461 keys | 5461 slots | 1 slaves

# Ã‰tape 3 : Redistribuer les slots Ã©quitablement
redis-cli --cluster rebalance 192.168.1.10:6379

# RÃ©sultat final (4 nÅ“uds, ~4096 slots chacun) :
# 192.168.1.15:6379 -> 4096 slots (0-4095)
# 192.168.1.10:6379 -> 4096 slots (4096-8191)
# 192.168.1.11:6379 -> 4096 slots (8192-12287)
# 192.168.1.12:6379 -> 4096 slots (12288-16383)
```

### 4. Suppression d'un nÅ“ud avec redistribution

```bash
# Ã‰tape 1 : DÃ©placer tous les slots du nÅ“ud Ã  supprimer
redis-cli --cluster reshard 192.168.1.10:6379 \
    --cluster-from i9j0k1l2-node-to-remove \
    --cluster-to all \
    --cluster-slots 5461 \
    --cluster-yes

# Ã‰tape 2 : VÃ©rifier que le nÅ“ud n'a plus de slots
redis-cli --cluster check 192.168.1.10:6379
# Le nÅ“ud devrait afficher : 0 keys | 0 slots

# Ã‰tape 3 : Supprimer le nÅ“ud du cluster
redis-cli --cluster del-node 192.168.1.10:6379 i9j0k1l2-node-to-remove

# Ã‰tape 4 : ArrÃªter le service Redis sur le nÅ“ud supprimÃ©
ssh 192.168.1.12
sudo systemctl stop redis
```

### 5. Gestion des slots orphelins

Des slots peuvent devenir orphelins lors de :
- Ã‰chec d'un resharding
- Crash d'un nÅ“ud pendant une migration
- Corruption de la configuration du cluster

#### DÃ©tection des slots orphelins

```bash
# VÃ©rifier l'intÃ©gritÃ© du cluster
redis-cli --cluster check 192.168.1.10:6379

# Sortie en cas de problÃ¨me :
[WARNING] Node 192.168.1.11:6379 has slots in migrating state (8000).
[WARNING] Node 192.168.1.12:6379 has slots in importing state (8000).
[ERR] Not all 16384 slots are covered by nodes.

# Identifier les slots non assignÃ©s
redis-cli --cluster fix 192.168.1.10:6379 --cluster-fix-with-unreachable-masters
```

#### Correction manuelle

```bash
# Cas 1 : Slot en Ã©tat MIGRATING bloquÃ©
redis-cli -h 192.168.1.11 -p 6379
127.0.0.1:6379> CLUSTER SETSLOT 8000 STABLE

# Cas 2 : Slot en Ã©tat IMPORTING bloquÃ©
redis-cli -h 192.168.1.12 -p 6379
127.0.0.1:6379> CLUSTER SETSLOT 8000 STABLE

# Cas 3 : RÃ©assigner un slot orphelin
127.0.0.1:6379> CLUSTER SETSLOT 8000 NODE i9j0k1l2-target-node-id

# VÃ©rifier la correction
redis-cli --cluster check 192.168.1.10:6379
[OK] All 16384 slots covered.
```

### 6. Monitoring continu des slots

#### Script de surveillance

```bash
#!/bin/bash
# check-cluster-slots.sh

CLUSTER_NODE="192.168.1.10:6379"

echo "=== VÃ©rification de la couverture des slots ==="
redis-cli -h ${CLUSTER_NODE%:*} -p ${CLUSTER_NODE#*:} --cluster check $CLUSTER_NODE | grep -E "slots|All 16384"

echo ""
echo "=== Distribution des slots par nÅ“ud ==="
redis-cli -h ${CLUSTER_NODE%:*} -p ${CLUSTER_NODE#*:} --cluster info $CLUSTER_NODE

echo ""
echo "=== Slots en migration ==="
redis-cli -h ${CLUSTER_NODE%:*} -p ${CLUSTER_NODE#*:} CLUSTER NODES | grep -E "MIGRATING|IMPORTING"

if [ $? -eq 0 ]; then
    echo "âš ï¸  ATTENTION : Des slots sont en cours de migration"
    exit 1
else
    echo "âœ… Aucune migration en cours"
fi
```

## Optimisations et considÃ©rations avancÃ©es

### GranularitÃ© du resharding

```
Compromis entre vitesse et disponibilitÃ© :

Migration de 1000 slots en une fois :
â”œâ”€ Avantages : Plus rapide (moins d'overhead)
â””â”€ InconvÃ©nients : Impact sur les performances

Migration de 10 slots Ã  la fois :
â”œâ”€ Avantages : Impact minimal sur les performances
â””â”€ InconvÃ©nients : Plus lent, plus d'opÃ©rations

Recommandation production :
â””â”€ Migrer par lots de 100-500 slots
   avec pause de 1-2 secondes entre chaque lot
```

### Pipeline de migration

Pour optimiser les performances lors du resharding :

```bash
# Utiliser le pipeline pour rÃ©duire les RTT
redis-cli -h source-node --cluster reshard target-node \
    --cluster-slots 1000 \
    --cluster-pipeline 10 \
    --cluster-replace

# --cluster-pipeline 10 : migrer 10 clÃ©s en parallÃ¨le
# --cluster-replace : remplacer les clÃ©s existantes sur destination
```

### Calcul de la charge par slot

```bash
# Obtenir le nombre de clÃ©s dans une plage de slots
redis-cli -h 192.168.1.10 -p 6379

# Pour un slot spÃ©cifique
127.0.0.1:6379> CLUSTER COUNTKEYSINSLOT 5000
(integer) 42

# Pour une plage de slots (script)
for slot in {0..100}; do
    count=$(redis-cli CLUSTER COUNTKEYSINSLOT $slot)
    echo "Slot $slot: $count keys"
done | sort -t: -k2 -n -r | head -20  # Top 20 slots les plus chargÃ©s
```

### Impact sur les clients pendant resharding

```
Comportement client pendant la migration d'un slot :

Client envoie GET user:5432 (slot 8000)
         â”‚
         â–¼
    NÅ“ud Source (A)
         â”‚
         â”œâ”€ ClÃ© prÃ©sente localement ?
         â”‚  â””â”€> Oui : Retourner la valeur
         â”‚
         â””â”€ ClÃ© dÃ©jÃ  migrÃ©e ?
            â””â”€> Oui : Retourner "-MOVED 8000 192.168.1.12:6379"

Client suit la redirection :
         â”‚
         â–¼
    NÅ“ud Destination (D)
         â””â”€> Retourner la valeur

Pendant la pÃ©riode de migration :
- Certaines clÃ©s sur source
- Certaines clÃ©s sur destination
- Redirections -MOVED automatiques
- Transparence pour l'application (client intelligent)
```

## Cas limites et situations exceptionnelles

### Cluster en mode dÃ©gradÃ©

```
ScÃ©nario : Un master tombe sans replica disponible

Ã‰tat initial :
Node A: Slots 0-5460     âœ… UP
Node B: Slots 5461-10922 âœ… UP
Node C: Slots 10923-16383 âŒ DOWN (no replica)

RÃ©sultat :
cluster_state: fail
cluster_slots_fail: 5461

Les slots 10923-16383 sont INACCESSIBLES
â””â”€> Toutes les opÃ©rations sur ces slots Ã©chouent
    avec "-CLUSTERDOWN Hash slot not served"
```

### RÃ©cupÃ©ration aprÃ¨s incident

```bash
# Option 1 : Forcer le cluster Ã  accepter l'Ã©tat dÃ©gradÃ©
redis-cli -h 192.168.1.10 -p 6379
127.0.0.1:6379> CLUSTER SETSLOT 10923 STABLE
# RÃ©pÃ©ter pour chaque slot affectÃ©...

# Option 2 : RÃ©assigner les slots orphelins Ã  un autre master
redis-cli --cluster fix 192.168.1.10:6379 \
    --cluster-fix-with-unreachable-masters

# Cette commande va :
# 1. Identifier les slots non servis
# 2. Les rÃ©assigner au master disponible le moins chargÃ©
# 3. Propager la nouvelle configuration via Gossip
```

### Limite de resharding

```
Contrainte : On ne peut pas dÃ©placer un slot qui contient
des clÃ©s en cours de modification (race condition)

Solution : Redis implÃ©mente un mÃ©canisme de locking :
1. Les clÃ©s du slot en migration restent accessibles
2. Nouvelles Ã©critures sur la destination
3. Lecture redirigÃ©e automatiquement
4. Migration atomique des clÃ©s restantes
```

## Checklist de maintenance des slots

```
âœ… Avant toute opÃ©ration de maintenance :
   â”œâ”€ VÃ©rifier cluster_state:ok
   â”œâ”€ Confirmer que tous les slots sont couverts (16384)
   â”œâ”€ S'assurer qu'aucune migration n'est en cours
   â””â”€ Backup de la configuration du cluster

âœ… Pendant le resharding :
   â”œâ”€ Monitorer la latence des requÃªtes
   â”œâ”€ Surveiller l'utilisation mÃ©moire (MIGRATE = copie temporaire)
   â”œâ”€ VÃ©rifier les logs pour les erreurs de migration
   â””â”€ Mesurer le taux de redirections -MOVED

âœ… AprÃ¨s le resharding :
   â”œâ”€ ExÃ©cuter CLUSTER CHECK pour validation
   â”œâ”€ VÃ©rifier la distribution des clÃ©s par nÅ“ud
   â”œâ”€ Confirmer que cluster_slots_assigned = 16384
   â””â”€ Tester l'accÃ¨s aux clÃ©s sur tous les slots migrÃ©s

âœ… En cas de problÃ¨me :
   â”œâ”€ Identifier l'Ã©tat des slots (CLUSTER NODES)
   â”œâ”€ VÃ©rifier les logs Redis de tous les nÅ“uds
   â”œâ”€ Utiliser CLUSTER SETSLOT STABLE pour dÃ©bloquer
   â””â”€ En dernier recours : CLUSTER RESET + recrÃ©ation
```

## Conclusion

Le systÃ¨me de hash slots de Redis Cluster offre un modÃ¨le de partitionnement dÃ©terministe et prÃ©visible, essentiel pour construire des systÃ¨mes distribuÃ©s fiables. La comprÃ©hension approfondie de ce mÃ©canisme permet :

- **Planification prÃ©cise** : Anticiper la distribution des donnÃ©es lors de l'ajout/suppression de nÅ“uds
- **Maintenance contrÃ´lÃ©e** : Effectuer des opÃ©rations de resharding sans interruption de service
- **Optimisation** : Utiliser les hash tags pour garantir la co-localisation des donnÃ©es liÃ©es
- **Troubleshooting** : Diagnostiquer et corriger rapidement les problÃ¨mes de slots orphelins ou bloquÃ©s

La maÃ®trise du resharding et des procÃ©dures de maintenance des slots est une compÃ©tence fondamentale pour tout architecte ou opÃ©rateur de Redis Cluster en environnement de production critique.

---

**Points clÃ©s Ã  retenir :**

1. **16384 slots fixes** : Espace prÃ©dÃ©terminÃ©, pas de consistent hashing dynamique
2. **CRC16 & 16383** : Fonction de hachage dÃ©terministe et rapide
3. **Hash tags `{...}`** : Permettent la co-localisation pour opÃ©rations multi-clÃ©s
4. **Resharding = 4 phases** : MIGRATING â†’ IMPORTING â†’ Migration clÃ©s â†’ SETSLOT NODE
5. **Monitoring continu** : VÃ©rifier rÃ©guliÃ¨rement avec `CLUSTER CHECK` et `CLUSTER SLOTS`
6. **Pipeline de migration** : Utiliser `--cluster-pipeline` pour optimiser les performances
7. **Gestion des erreurs** : Toujours avoir un plan de rÃ©cupÃ©ration pour les slots orphelins

â­ï¸ [Redis Cluster : Concepts (Sharding, Hash Slots, Gossip Protocol)](/11-architecture-distribuee-scaling/01-redis-cluster-concepts.md)
