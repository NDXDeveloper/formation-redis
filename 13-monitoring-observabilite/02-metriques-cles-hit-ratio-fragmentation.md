üîù Retour au [Sommaire](/SOMMAIRE.md)

# 13.2 M√©triques cl√©s : Hit ratio, Fragmentation, √âvictions

## Introduction

En production Redis, trois m√©triques se distinguent par leur impact direct sur la performance, la disponibilit√© et les co√ªts d'infrastructure. Ces m√©triques sont les **indicateurs de sant√©** qui, lorsqu'elles d√©gradent, pr√©c√®dent g√©n√©ralement un incident majeur.

### Pourquoi ces trois m√©triques sont critiques

| M√©trique | Impact direct | Sympt√¥me visible | Co√ªt business |
|----------|---------------|------------------|---------------|
| **Hit Ratio** | Performance applicative | Latence ‚Üë, timeouts | Perte d'utilisateurs |
| **Fragmentation** | Gaspillage m√©moire | OOM, crashes | Surco√ªt infra 2-3√ó |
| **√âvictions** | Perte de donn√©es | Cache misses ‚Üë, bugs | Charge DB ‚Üë, incidents |

### La triade de la sant√© Redis

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Application Layer                  ‚îÇ
‚îÇ         (latence, availability, UX)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   Hit Ratio     ‚îÇ ‚Üê Efficacit√© du cache
        ‚îÇ   (Cache hit %) ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Fragmentation‚îÇ     ‚îÇ   √âvictions     ‚îÇ
‚îÇ (M√©moire)    ‚îÇ     ‚îÇ   (Capacit√©)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                      ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ  Infrastructure ‚îÇ
       ‚îÇ  (RAM, Co√ªts)   ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 1. Hit Ratio : L'efficacit√© du cache

### 1.1 D√©finition et calcul

Le **hit ratio** (ou taux de succ√®s du cache) mesure le pourcentage de requ√™tes de lecture trouvant la donn√©e dans Redis.

#### Formule de base

```
Hit Ratio = Hits / (Hits + Misses) √ó 100
```

#### M√©triques Redis impliqu√©es

```bash
# Redis INFO stats
keyspace_hits:8547123      # Cl√©s trouv√©es
keyspace_misses:1245632    # Cl√©s non trouv√©es

# Calcul
hit_ratio = 8547123 / (8547123 + 1245632) = 87.3%
```

#### Requ√™te Prometheus

```promql
# Hit ratio sur 5 minutes
100 * (
  rate(redis_keyspace_hits_total{instance="$instance"}[5m]) /
  (
    rate(redis_keyspace_hits_total{instance="$instance"}[5m]) +
    rate(redis_keyspace_misses_total{instance="$instance"}[5m])
  )
)
```

### 1.2 Objectifs par use case

| Use Case | Hit Ratio cible | Justification |
|----------|----------------|---------------|
| **Cache HTTP/API** | > 85% | R√©duire la charge backend |
| **Session Store** | > 95% | Sessions actives toujours pr√©sentes |
| **Full-page cache** | > 80% | Pages populaires en cache |
| **Query cache (SQL)** | > 90% | Requ√™tes r√©p√©titives |
| **CDN backend cache** | > 75% | Contenu statique |
| **Rate limiting** | N/A | Pas de notion de hit/miss |
| **Job Queue** | N/A | M√©trique non pertinente |

### 1.3 Anatomie d'un hit et d'un miss

#### Qu'est-ce qu'un HIT ?

Commandes qui incr√©mentent `keyspace_hits` :
```
GET key         ‚Üí Cl√© existe ‚Üí HIT
HGET hash f     ‚Üí Hash et field existent ‚Üí HIT
LINDEX list 0   ‚Üí Liste existe et index valide ‚Üí HIT
SISMEMBER s m   ‚Üí Set existe et membre pr√©sent ‚Üí HIT
ZRANK ss m      ‚Üí Sorted set existe et membre pr√©sent ‚Üí HIT
EXISTS key      ‚Üí Cl√© existe ‚Üí HIT
```

#### Qu'est-ce qu'un MISS ?

```
GET key         ‚Üí Cl√© n'existe pas ‚Üí MISS
HGET hash f     ‚Üí Hash n'existe pas ‚Üí MISS
EXISTS key      ‚Üí Cl√© n'existe pas ‚Üí MISS
```

#### Commandes qui n'affectent PAS hit/miss

```
SET key value   ‚Üí Write operation (ni hit ni miss)
DEL key         ‚Üí Write operation
INCR key        ‚Üí Write operation
LPUSH list val  ‚Üí Write operation
KEYS *          ‚Üí Scan operation
INFO            ‚Üí Admin operation
```

### 1.4 Facteurs impactant le hit ratio

#### 1. TTL (Time To Live)

**TTL trop court** :
```
TTL: 60 secondes
Fr√©quence d'acc√®s: toutes les 90 secondes
‚Üí Hit ratio catastrophique (~0%)
```

**TTL optimal** :
```
TTL ‚â• 2 √ó Intervalle_moyen_entre_requ√™tes

Exemple :
Acc√®s moyen toutes les 30s ‚Üí TTL ‚â• 60s
```

**Cas r√©el** :
```python
# ‚ùå Mauvais : TTL trop court
redis.setex(f"user:{user_id}", 300, user_data)  # 5 min
# Si le user est actif (requ√™tes toutes les 10s),
# la cl√© expire alors qu'elle est chaude

# ‚úÖ Bon : TTL adapt√©
redis.setex(f"user:{user_id}", 1800, user_data)  # 30 min
# Couvre une session utilisateur typique
```

#### 2. Capacit√© m√©moire insuffisante

**Sc√©nario** : √âvictions forc√©es
```
Maxmemory: 4GB
Dataset: 6GB de donn√©es chaudes
‚Üí √âvictions permanentes ‚Üí Hit ratio effondr√©
```

**Calcul du dimensionnement** :
```
RAM_n√©cessaire = Working_set_size √ó 1.5

Working set = Donn√©es acc√©d√©es dans la fen√™tre de TTL
```

**Exemple** :
```
10M cl√©s actives
Taille moyenne : 500 bytes
Working set : 10M √ó 500 = 5GB
RAM n√©cessaire : 5GB √ó 1.5 = 7.5GB
```

#### 3. Pattern d'acc√®s impr√©visible

**Cache inutile si** :
```
# Pattern al√©atoire (ex: UUID sans pattern)
GET user:a1b2c3d4-5678-90ef-ghij-klmnopqrstuv
GET user:b2c3d4e5-6789-01fg-hijk-lmnopqrstuvw
GET user:c3d4e5f6-7890-12gh-ijkl-mnopqrstuvwx
‚Üí Chaque requ√™te est unique ‚Üí Hit ratio ~0%
```

**Cache efficace si** :
```
# Pattern avec hotspots
GET product:12345  (100 requ√™tes/sec)
GET product:67890  (80 requ√™tes/sec)
GET product:11111  (60 requ√™tes/sec)
‚Üí 20% des cl√©s = 80% du trafic ‚Üí Hit ratio √©lev√©
```

#### 4. Politique d'√©viction inadapt√©e

```
# ‚ùå Mauvaise config pour cache
maxmemory-policy volatile-lru
# Si 50% des cl√©s n'ont pas de TTL ‚Üí Jamais √©vict√©es ‚Üí Saturation

# ‚úÖ Bonne config pour cache
maxmemory-policy allkeys-lru
# Toutes les cl√©s peuvent √™tre √©vict√©es
```

### 1.5 Diagnostic d'un hit ratio d√©grad√©

#### √âtape 1 : √âtablir une baseline

```promql
# Hit ratio moyen sur 7 jours
avg_over_time(
  (
    rate(redis_keyspace_hits_total[5m]) /
    (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))
  )[7d:]
)
```

**Baseline typique** :
```
Heure   | Hit Ratio
--------|----------
02:00   | 92%      ‚Üê Nuit, cache chaud
08:00   | 85%      ‚Üê Pic matin, cache froid
14:00   | 91%      ‚Üê Apr√®s-midi, cache stable
20:00   | 88%      ‚Üê Soir√©e, nouveau trafic
```

#### √âtape 2 : Identifier la d√©gradation

**D√©gradation progressive** :
```
Jour 1: 90%
Jour 2: 88%
Jour 3: 85%
Jour 4: 82%
‚Üí Dataset qui cro√Æt + m√©moire fixe ‚Üí √âvictions
```

**D√©gradation brutale** :
```
12:00 ‚Üí 91%
12:15 ‚Üí 47%  ‚Üê Drop soudain
‚Üí D√©ploiement applicatif ? Changement de pattern ?
```

#### √âtape 3 : Corr√©ler avec d'autres m√©triques

```promql
# Graphique de corr√©lation
{
  hit_ratio: rate(redis_keyspace_hits_total[5m]) /
             (rate(redis_keyspace_hits_total[5m]) +
              rate(redis_keyspace_misses_total[5m])),
  evictions: rate(redis_evicted_keys_total[5m]),
  memory_pct: redis_memory_used_bytes / redis_memory_max_bytes * 100
}
```

**Pattern typique** :
```
Memory_pct ‚Üë ‚Üí √âvictions ‚Üë ‚Üí Hit_ratio ‚Üì
```

#### √âtape 4 : Analyser les patterns de cl√©s

```bash
# Identifier les cl√©s les plus "miss√©es"
redis-cli MONITOR | grep -i "get" | awk '{print $4}' | sort | uniq -c | sort -rn | head -20

# Exemple de sortie
1547 "GET" "product:99999"    ‚Üê Produit inexistant ?
892  "GET" "user:deleted_123" ‚Üê Utilisateur supprim√© ?
456  "GET" "session:expired"  ‚Üê Session expir√©e ?
```

### 1.6 Strat√©gies d'am√©lioration du hit ratio

#### Strat√©gie 1 : Augmentation intelligente des TTL

**Analyse** :
```sql
-- Analyser les patterns d'acc√®s
SELECT
  key_prefix,
  AVG(time_between_access) as avg_interval,
  RECOMMENDED_TTL = AVG(time_between_access) * 2
FROM access_logs
GROUP BY key_prefix;
```

**Impl√©mentation** :
```python
# Cache adaptatif bas√© sur la fr√©quence
def cache_with_adaptive_ttl(key, fetcher):
    # R√©cup√©rer historique d'acc√®s
    access_count = redis.get(f"{key}:access_count") or 0

    # TTL adaptatif
    if access_count > 100:      # Tr√®s populaire
        ttl = 3600              # 1 heure
    elif access_count > 10:     # Populaire
        ttl = 1800              # 30 min
    else:                       # Peu acc√©d√©
        ttl = 300               # 5 min

    data = redis.get(key)
    if not data:
        data = fetcher()
        redis.setex(key, ttl, data)
        redis.incr(f"{key}:access_count")

    return data
```

#### Strat√©gie 2 : Cache warming (pr√©-chauffage)

**Cas d'usage** : Apr√®s un red√©marrage ou un d√©ploiement

```python
# Script de warming
def warm_cache():
    # Top 1000 produits les plus consult√©s
    hot_products = db.query("""
        SELECT product_id
        FROM product_views
        WHERE created_at > NOW() - INTERVAL '7 days'
        GROUP BY product_id
        ORDER BY COUNT(*) DESC
        LIMIT 1000
    """)

    for product_id in hot_products:
        product_data = db.get_product(product_id)
        redis.setex(
            f"product:{product_id}",
            3600,
            json.dumps(product_data)
        )

    logging.info(f"Cache warmed with {len(hot_products)} products")
```

**Scheduler** :
```yaml
# Kubernetes CronJob
apiVersion: batch/v1
kind: CronJob
metadata:
  name: redis-cache-warmer
spec:
  schedule: "0 2 * * *"  # 2h du matin
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: warmer
            image: app:latest
            command: ["python", "warm_cache.py"]
```

#### Strat√©gie 3 : Cache-aside avec fallback

```python
def get_user(user_id):
    # Tentative 1 : Redis
    cache_key = f"user:{user_id}"
    user = redis.get(cache_key)

    if user:
        # HIT
        return json.loads(user)

    # MISS ‚Üí Fallback DB
    user = db.query(f"SELECT * FROM users WHERE id = {user_id}")

    if user:
        # Cacher pour la prochaine fois
        redis.setex(cache_key, 1800, json.dumps(user))
    else:
        # Cacher les "not found" pour √©viter les requ√™tes r√©p√©t√©es
        # (Cache Penetration protection)
        redis.setex(cache_key, 60, json.dumps({"_not_found": True}))

    return user
```

#### Strat√©gie 4 : Augmentation de la capacit√© m√©moire

**Calcul du ROI** :
```
Co√ªt actuel :
- RAM : 8GB @ $50/mois
- Hit ratio : 75%
- 25% requ√™tes ‚Üí DB (100ms latence)
- 1000 req/s √ó 25% = 250 req/s vers DB
- Surco√ªt DB : CPU √©lev√©, slowdowns

Co√ªt apr√®s upgrade :
- RAM : 16GB @ $100/mois (+$50)
- Hit ratio : 95%
- 5% requ√™tes ‚Üí DB (100ms latence)
- 1000 req/s √ó 5% = 50 req/s vers DB
- √âconomie : R√©duction DB scaling (-$200/mois)

ROI : -$50 (Redis) + $200 (DB) = +$150/mois
```

### 1.7 Alerting sur le hit ratio

#### R√®gle Prometheus de base

```yaml
- alert: RedisHitRatioLow
  expr: |
    (
      rate(redis_keyspace_hits_total[5m]) /
      (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))
    ) < 0.80
  for: 10m
  labels:
    severity: warning
  annotations:
    summary: "Hit ratio faible sur {{ $labels.instance }}"
    description: "Hit ratio: {{ $value | humanizePercentage }} (< 80%)"
```

#### R√®gle avanc√©e avec baseline

```yaml
- alert: RedisHitRatioDegradation
  expr: |
    (
      (
        rate(redis_keyspace_hits_total[5m]) /
        (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))
      )
      /
      avg_over_time(
        (
          rate(redis_keyspace_hits_total[5m]) /
          (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))
        )[7d:]
      )
    ) < 0.90
  for: 15m
  labels:
    severity: warning
  annotations:
    summary: "D√©gradation du hit ratio sur {{ $labels.instance }}"
    description: "Hit ratio actuel: {{ $value | humanizePercentage }} de la baseline 7j"
```

#### Alerting par segment

```yaml
# Diff√©rencier par use case
- alert: SessionStoreHitRatioLow
  expr: |
    (
      rate(redis_keyspace_hits_total{redis_role="session"}[5m]) /
      (rate(redis_keyspace_hits_total{redis_role="session"}[5m]) +
       rate(redis_keyspace_misses_total{redis_role="session"}[5m]))
    ) < 0.95
  for: 5m
  labels:
    severity: critical
  annotations:
    summary: "Session store hit ratio critique"
    description: "Sessions non trouv√©es ‚Üí D√©connexions utilisateurs"
```

## 2. Fragmentation m√©moire : L'optimisation cach√©e

### 2.1 Comprendre la fragmentation

#### D√©finition

La **fragmentation m√©moire** survient quand la m√©moire allou√©e par l'allocateur (jemalloc) ne correspond plus √† la m√©moire r√©ellement utilis√©e par Redis.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  M√©moire physique (used_memory_rss)         ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ M√©moire utilis√©e (used_memory)     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  [Donn√©es Redis]                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                    ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  [Trous] [Trous] [Trous] [Trous]            ‚îÇ ‚Üê Fragmentation
‚îÇ                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Calcul

```
mem_fragmentation_ratio = used_memory_rss / used_memory
```

**M√©triques Redis** :
```bash
# Redis INFO memory
used_memory:2147483648          # 2GB (donn√©es logiques)
used_memory_rss:2952790016      # 2.75GB (m√©moire physique)
mem_fragmentation_ratio:1.37    # 37% de fragmentation
mem_fragmentation_bytes:805306368  # 768MB gaspill√©s
```

### 2.2 √âchelle d'interpr√©tation d√©taill√©e

| Ratio | √âtat | Signification | Impact m√©moire | Action |
|-------|------|---------------|----------------|--------|
| < 1.0 | üî¥ DANGER | Swap actif | Variable | **URGENT** : RAM insuffisante |
| 1.0 - 1.1 | üü¢ EXCELLENT | Fragmentation minimale | < 10% overhead | Monitoring normal |
| 1.1 - 1.3 | üü¢ OPTIMAL | Fragmentation acceptable | 10-30% overhead | RAS |
| 1.3 - 1.5 | üü° ACCEPTABLE | Fragmentation mod√©r√©e | 30-50% overhead | Surveiller tendance |
| 1.5 - 2.0 | üü† PROBL√âMATIQUE | Fragmentation √©lev√©e | 50-100% overhead | Planifier action |
| 2.0 - 3.0 | üî¥ CRITIQUE | Perte importante | 100-200% overhead | Red√©marrage recommand√© |
| > 3.0 | üî¥ S√âV√àRE | Gaspillage majeur | > 200% overhead | Red√©marrage urgent |

### 2.3 Causes de la fragmentation

#### Cause 1 : Workload volatil

**Sc√©nario** : Cr√©ations/suppressions fr√©quentes de cl√©s de tailles vari√©es

```python
# Pattern g√©n√©rant de la fragmentation
for i in range(1000000):
    # Cr√©er une cl√© de taille al√©atoire
    size = random.randint(100, 10000)
    redis.set(f"data:{i}", "x" * size)

    # Supprimer une cl√© al√©atoire
    if random.random() > 0.5:
        redis.delete(f"data:{random.randint(0, i)}")

# R√©sultat : Trous m√©moire partout
```

**Visualisation** :
```
Temps T0: [100B][200B][150B][300B][250B]
Temps T1: [100B][____][150B][____][250B]  ‚Üê Suppressions
Temps T2: [100B][80B_][150B][____][250B]  ‚Üê Nouvelle cl√© 80B ne remplit pas le trou 200B
```

#### Cause 2 : Mix de petites et grosses cl√©s

```python
# Fragmentation par h√©t√©rog√©n√©it√©
redis.set("tiny", "x")                    # 1 byte
redis.set("small", "x" * 100)             # 100 bytes
redis.set("medium", "x" * 10000)          # 10KB
redis.set("large", "x" * 1000000)         # 1MB

# L'allocateur alloue par "classes de taille"
# ‚Üí Gaspillage dans chaque allocation
```

#### Cause 3 : √âvictions massives

```python
# Sc√©nario : Atteinte de maxmemory
# ‚Üí Redis √©victe 10000 cl√©s d'un coup
# ‚Üí 10000 trous m√©moire
# ‚Üí Fragmentation soudaine
```

#### Cause 4 : Longue dur√©e d'uptime

```
Jour 1:   fragmentation_ratio = 1.05
Jour 30:  fragmentation_ratio = 1.35
Jour 90:  fragmentation_ratio = 1.58
Jour 180: fragmentation_ratio = 1.87
‚Üí Accumulation naturelle
```

### 2.4 Impact de la fragmentation

#### Impact 1 : Surconsommation m√©moire

**Exemple r√©el** :
```
Configuration serveur : 16GB RAM
Maxmemory Redis : 12GB
Fragmentation : 1.8

M√©moire r√©ellement consomm√©e :
12GB √ó 1.8 = 21.6GB
‚Üí Serveur en OOM !
```

#### Impact 2 : D√©clenchement pr√©matur√© des √©victions

```
Maxmemory : 4GB
Used_memory : 3.5GB (87.5%, pas encore d'√©viction)
Fragmentation : 1.6
Used_memory_rss : 5.6GB

‚Üí Syst√®me en swap
‚Üí Redis ralentit
‚Üí Clients timeout
```

#### Impact 3 : Co√ªt infrastructure

```
Sc√©nario A : Sans fragmentation
- Dataset : 10GB
- RAM n√©cessaire : 15GB (marge 50%)
- Co√ªt : $150/mois

Sc√©nario B : Avec fragmentation (ratio 2.0)
- Dataset : 10GB
- Fragmentation : 10GB suppl√©mentaires
- RAM n√©cessaire : 30GB (20GB + marge)
- Co√ªt : $300/mois

Surco√ªt : $150/mois soit 100%
```

### 2.5 Monitoring de la fragmentation

#### Dashboard Grafana

**Panel 1 : Fragmentation Ratio (Gauge)**
```promql
redis_mem_fragmentation_ratio{instance="$instance"}
```

**Seuils** :
- Vert : < 1.3
- Jaune : 1.3 - 1.5
- Orange : 1.5 - 2.0
- Rouge : > 2.0

**Panel 2 : M√©moire gaspill√©e (Graph)**
```promql
# M√©moire fragment√©e en bytes
redis_mem_fragmentation_bytes{instance="$instance"}

# Ou calcul√©e
redis_memory_used_rss_bytes - redis_memory_used_bytes
```

**Panel 3 : Tendance fragmentation (Graph)**
```promql
# Fragmentation sur 30 jours
redis_mem_fragmentation_ratio{instance="$instance"}[30d]
```

**Panel 4 : Corr√©lation fragmentation vs √©victions**
```promql
{
  fragmentation: redis_mem_fragmentation_ratio,
  evictions: rate(redis_evicted_keys_total[5m])
}
```

#### Alertes Prometheus

**Alerte de base** :
```yaml
- alert: RedisFragmentationHigh
  expr: redis_mem_fragmentation_ratio > 1.5
  for: 30m
  labels:
    severity: warning
  annotations:
    summary: "Fragmentation m√©moire √©lev√©e sur {{ $labels.instance }}"
    description: "Ratio: {{ $value }} (> 1.5) - {{ $value | humanize }}% de m√©moire gaspill√©e"
```

**Alerte critique** :
```yaml
- alert: RedisFragmentationCritical
  expr: redis_mem_fragmentation_ratio > 2.0
  for: 10m
  labels:
    severity: critical
  annotations:
    summary: "Fragmentation m√©moire CRITIQUE sur {{ $labels.instance }}"
    description: |
      Ratio: {{ $value }}
      M√©moire gaspill√©e: {{ query "redis_mem_fragmentation_bytes{instance='{{ $labels.instance }}'}" | humanize1024 }}
      Action: Red√©marrage recommand√©
```

**Alerte tendance** :
```yaml
- alert: RedisFragmentationIncreasing
  expr: |
    (
      redis_mem_fragmentation_ratio -
      redis_mem_fragmentation_ratio offset 7d
    ) > 0.3
  for: 1h
  labels:
    severity: warning
  annotations:
    summary: "Fragmentation en augmentation sur {{ $labels.instance }}"
    description: "Augmentation de {{ $value }} sur 7 jours"
```

### 2.6 Solutions √† la fragmentation

#### Solution 1 : Active Defragmentation (Redis 4.0+)

**Configuration optimale** :
```conf
# redis.conf

# Activer la d√©fragmentation active
activedefrag yes

# Ne d√©marrer que si fragmentation significative
active-defrag-ignore-bytes 100mb        # Ignorer si < 100MB fragment√©s
active-defrag-threshold-lower 10        # D√©marrer √† 10% fragmentation
active-defrag-threshold-upper 100       # Mode agressif √† 100%

# Contr√¥le de la charge CPU
active-defrag-cycle-min 1               # Min 1% CPU
active-defrag-cycle-max 25              # Max 25% CPU (ajuster selon charge)

# Agressivit√© du scanning
active-defrag-max-scan-fields 1000      # Scan 1000 fields par cycle
```

**Monitoring de la d√©fragmentation** :
```bash
# Redis INFO memory
active_defrag_running:1                  # D√©frag en cours
active_defrag_hits:1547896              # Succ√®s de d√©frag
active_defrag_misses:245678             # √âchecs
active_defrag_key_hits:15478            # Cl√©s d√©fragment√©es
active_defrag_key_misses:2456           # Cl√©s non-d√©fragmentables
```

**Efficacit√©** :
```
Avant : fragmentation_ratio = 1.8
Apr√®s 24h de defrag : fragmentation_ratio = 1.3
Gain : 27% de m√©moire r√©cup√©r√©e
```

**Limitations** :
- Augmente l√©g√®rement la latence (scanning actif)
- Pas efficace si workload trop volatil
- CPU overhead 1-25%

#### Solution 2 : Red√©marrage planifi√©

**Quand red√©marrer** :
- Fragmentation > 2.0 pendant > 7 jours
- Active defrag inefficace
- Maintenance planifi√©e

**Strat√©gie de red√©marrage** :

**Option A : Red√©marrage avec r√©plication (Zero Downtime)**
```bash
# 1. Promouvoir un replica
redis-cli -h replica1 REPLICAOF NO ONE

# 2. Rediriger le trafic applicatif vers replica1

# 3. Red√©marrer l'ancien master
systemctl restart redis

# 4. Attendre chargement complet

# 5. Reconfigurer en replica
redis-cli -h old-master REPLICAOF replica1 6379

# 6. Une fois sync, repromouvoir en master
redis-cli -h old-master REPLICAOF NO ONE
redis-cli -h replica1 REPLICAOF old-master 6379
```

**Option B : Red√©marrage avec Sentinel (Automatique)**
```bash
# Sentinel g√®re le failover automatiquement
systemctl restart redis

# Sentinel d√©tecte la panne et promouvoit un replica
# Apr√®s red√©marrage, l'instance rejoint comme replica
# Puis peut √™tre repromue manuellement si n√©cessaire
```

**Option C : Red√©marrage Cluster (Rolling restart)**
```bash
# Red√©marrer les slaves d'abord, puis les masters
for node in slave1 slave2 slave3 master1 master2 master3; do
  echo "Red√©marrage de $node..."
  redis-cli -h $node SHUTDOWN NOSAVE
  sleep 60  # Attendre le red√©marrage
  # V√©rifier que le node est revenu
  redis-cli -h $node PING
  sleep 300  # Attendre stabilisation r√©plication
done
```

#### Solution 3 : Tuning de l'allocateur

**jemalloc tuning** (avanc√©) :
```bash
# Variables d'environnement au d√©marrage Redis
export JEMALLOC_CONF="narenas:4,lg_tcache_max:15"
redis-server /etc/redis/redis.conf
```

**Param√®tres** :
- `narenas:4` : Nombre d'ar√®nes (r√©duire si mono-thread)
- `lg_tcache_max:15` : Taille max du thread cache

**Attention** : R√©glages tr√®s sp√©cifiques, tester avant production

#### Solution 4 : Optimisation du workload

**Strat√©gie 1 : R√©duire la volatilit√©**
```python
# ‚ùå Mauvais : Volatilit√© √©lev√©e
def cache_user(user_id):
    redis.setex(f"user:{user_id}", 300, data)  # TTL court
    # ‚Üí Cr√©ations/suppressions fr√©quentes

# ‚úÖ Meilleur : Stabilit√©
def cache_user(user_id):
    redis.setex(f"user:{user_id}", 3600, data)  # TTL plus long
    # ‚Üí Moins de churn
```

**Strat√©gie 2 : Homog√©n√©iser les tailles**
```python
# ‚ùå Mauvais : Tailles h√©t√©rog√®nes
redis.set("small", "x" * 10)
redis.set("huge", "x" * 1000000)

# ‚úÖ Meilleur : Tailles similaires ou s√©paration
# Option A : Compression pour homog√©n√©iser
import zlib
data_compressed = zlib.compress(data.encode())
redis.set(key, data_compressed)

# Option B : Instances s√©par√©es
redis_small.set("small", data)   # Instance pour petites cl√©s
redis_large.set("large", data)   # Instance pour grosses cl√©s
```

### 2.7 Cas d'√©tude : Fragmentation en production

**Contexte** :
- E-commerce, 50M de sessions actives
- Redis 16GB RAM
- Fragmentation pass√©e de 1.2 √† 2.4 en 3 mois

**Analyse** :
```bash
# Pattern identifi√©
INFO commandstats | grep set
cmdstat_setex:calls=15478963,usec_per_call=45.2

INFO keyspace
db0:keys=50000000,expires=50000000,avg_ttl=900000  # 15 min TTL

# Calcul
50M cl√©s √ó 4 renouvellements/heure = 200M SET/heure
‚Üí Churn massif ‚Üí Fragmentation
```

**Solution appliqu√©e** :
```python
# Avant : TTL court, churn √©lev√©
redis.setex(f"session:{sid}", 900, data)  # 15 min

# Apr√®s : TTL long, lazy cleanup
redis.setex(f"session:{sid}", 3600, data)  # 60 min

# Background job de cleanup bas√© sur activit√©
def cleanup_inactive_sessions():
    for session_id in get_inactive_sessions():
        redis.delete(f"session:{session_id}")
```

**R√©sultats** :
- Fragmentation : 2.4 ‚Üí 1.4 en 2 semaines
- RAM √©conomis√©e : 6GB (37%)
- Co√ªt : -$500/mois

## 3. √âvictions : Quand le cache d√©borde

### 3.1 Comprendre les √©victions

#### D√©finition

Une **√©viction** survient quand Redis supprime une cl√© pour lib√©rer de la m√©moire, car `maxmemory` est atteint.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  RAM: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100%      ‚îÇ
‚îÇ                                        ‚îÇ
‚îÇ  Nouvelle cl√© arrive ‚Üí                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ Redis doit supprimer une    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ cl√© existante (√©viction)    ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                        ‚îÇ
‚îÇ  Politique: maxmemory-policy           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Diff√©rence √©viction vs expiration

| Aspect | √âviction | Expiration |
|--------|----------|------------|
| **D√©clencheur** | M√©moire pleine | TTL expir√© |
| **Intentionnel** | Non (probl√®me) | Oui (normal) |
| **M√©trique** | `evicted_keys` | `expired_keys` |
| **Impact** | Perte de donn√©es chaudes | Nettoyage pr√©vu |
| **Action** | Augmenter RAM | RAS |

### 3.2 M√©triques d'√©viction

```bash
# Redis INFO stats
evicted_keys:154789              # Nombre total d'√©victions
expired_keys:8547123             # Expirations (comparaison)

# Taux d'√©viction
rate(redis_evicted_keys_total[5m])
```

**Objectif** : `evicted_keys` devrait rester √† **0** dans un syst√®me sain

### 3.3 Politiques d'√©viction

#### Vue d'ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            maxmemory-policy                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                 ‚îÇ
‚îÇ  Bas√©es sur LRU/LFU (toutes cl√©s)               ‚îÇ
‚îÇ  ‚îú‚îÄ allkeys-lru    : LRU global                 ‚îÇ
‚îÇ  ‚îú‚îÄ allkeys-lfu    : LFU global (Redis 4+)      ‚îÇ
‚îÇ  ‚îî‚îÄ allkeys-random : Al√©atoire global           ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Bas√©es sur LRU/LFU (cl√©s avec TTL)             ‚îÇ
‚îÇ  ‚îú‚îÄ volatile-lru   : LRU sur expires            ‚îÇ
‚îÇ  ‚îú‚îÄ volatile-lfu   : LFU sur expires            ‚îÇ
‚îÇ  ‚îú‚îÄ volatile-random: Al√©atoire sur expires      ‚îÇ
‚îÇ  ‚îî‚îÄ volatile-ttl   : Plus court TTL             ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Pas d'√©viction                                 ‚îÇ
‚îÇ  ‚îî‚îÄ noeviction     : Erreur OOM (d√©faut)        ‚îÇ
‚îÇ                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Comparaison LRU vs LFU

**LRU (Least Recently Used)** :
```
Cl√© A : Acc√©d√©e il y a 10 secondes  (r√©cente)
Cl√© B : Acc√©d√©e il y a 60 secondes  (ancienne)
‚Üí √âviction de B (moins r√©cente)

Probl√®me : Une cl√© acc√©d√©e massivement hier
mais pas aujourd'hui sera conserv√©e
```

**LFU (Least Frequently Used)** :
```
Cl√© A : 1000 acc√®s sur 24h  (fr√©quente)
Cl√© B : 5 acc√®s sur 24h     (peu fr√©quente)
‚Üí √âviction de B (moins fr√©quente)

Avantage : Conserve les vraies cl√©s chaudes
```

#### Choix de la politique

| Use Case | Politique recommand√©e | Justification |
|----------|----------------------|---------------|
| Cache pur | `allkeys-lru` ou `allkeys-lfu` | Tout est √©victable |
| Session store | `volatile-lru` | Sessions avec TTL |
| Mixed (cache + permanent) | `allkeys-lru` | Balance optimal |
| Queue/Stream | `noeviction` | Perte de donn√©es inacceptable |
| Rate limiting | `allkeys-lru` | Entr√©es anciennes moins importantes |

### 3.4 Impact des √©victions

#### Impact 1 : D√©gradation du hit ratio

```
Sc√©nario :
- 1000 req/s
- Hit ratio sans √©viction : 95%
- √âvictions : 100 cl√©s/s

Calcul :
Nouvelles cl√©s √©vict√©es = 100/s
Requ√™tes affect√©es = 100/s (maintenant en miss)
Hit ratio d√©grad√© = (950 - 100) / 1000 = 85%

Perte : 10 points de hit ratio
```

#### Impact 2 : Charge sur la base de donn√©es

```
Avant √©victions :
- 1000 req/s vers Redis
- 50 req/s vers DB (5% miss)
- DB CPU : 20%

Avec √©victions (100/s) :
- 1000 req/s vers Redis
- 150 req/s vers DB (15% miss)
- DB CPU : 60%

Impact : DB CPU √ó 3
```

#### Impact 3 : Latence applicative

```python
# Sans √©viction
def get_user(user_id):
    user = redis.get(f"user:{user_id}")  # 1ms (hit)
    return user

# Avec √©viction
def get_user(user_id):
    user = redis.get(f"user:{user_id}")  # 1ms (miss)
    if not user:
        user = db.query(...)             # +100ms (DB query)
        redis.setex(...)                 # +1ms
    return user

Latence : 1ms ‚Üí 102ms (√ó100 pour les requ√™tes √©vict√©es)
```

### 3.5 Diagnostic des √©victions

#### √âtape 1 : Confirmer les √©victions

```bash
# √âvictions actuelles
redis-cli INFO stats | grep evicted_keys
evicted_keys:154789

# Taux d'√©viction sur 5 minutes
redis-cli --stat | grep evicted
# Ou via Prometheus
rate(redis_evicted_keys_total[5m])
```

#### √âtape 2 : Analyser la cause

**Requ√™te Grafana multi-m√©triques** :
```promql
{
  memory_used_pct: (redis_memory_used_bytes / redis_memory_max_bytes) * 100,
  evictions_rate: rate(redis_evicted_keys_total[5m]),
  keys_total: redis_db_keys,
  hit_ratio: rate(redis_keyspace_hits_total[5m]) /
             (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))
}
```

**Patterns √† identifier** :

**Pattern 1 : Saturation chronique**
```
memory_used_pct: 100% permanent
evictions_rate: 50-100/s constant
‚Üí Sous-dimensionnement
```

**Pattern 2 : Pics d'√©viction**
```
08:00-09:00 : evictions_rate = 200/s
Rest of day : evictions_rate = 0
‚Üí Pic de charge matinal
```

**Pattern 3 : √âvictions croissantes**
```
Semaine 1 : 10 √©victions/s
Semaine 2 : 25 √©victions/s
Semaine 3 : 50 √©victions/s
‚Üí Dataset qui cro√Æt
```

#### √âtape 3 : Identifier les cl√©s √©vict√©es

```bash
# Monitoring en temps r√©el
redis-cli MONITOR | grep -i "del"

# Ou via logs (si log-level debug)
tail -f /var/log/redis/redis.log | grep "evict"
```

**Impossible de voir pr√©cis√©ment quelles cl√©s** : Redis ne log pas les √©victions individuelles

**Workaround** : Instrumenter l'application
```python
# Wrapper Redis avec logging
class InstrumentedRedis:
    def __init__(self, redis_client):
        self.redis = redis_client

    def get(self, key):
        value = self.redis.get(key)
        if value is None:
            # Log potential eviction
            logger.warning(f"Cache miss for key: {key} - Possible eviction")
        return value
```

### 3.6 Solutions aux √©victions

#### Solution 1 : Augmentation de maxmemory

**Calcul du dimensionnement optimal** :
```
# M√©thode 1 : Bas√© sur le working set
working_set_size = nb_cl√©s_actives √ó taille_moyenne_cl√©

# M√©thode 2 : Bas√© sur le taux d'acc√®s
donn√©es_acc√©d√©es_dans_TTL = (requ√™tes/s √ó TTL) √ó taille_moyenne

# Exemple :
# 1000 req/s, TTL 3600s, taille moyenne 1KB
working_set = 1000 √ó 3600 √ó 1024 = 3.6GB

# Ajout marge 50%
maxmemory_optimal = 3.6GB √ó 1.5 = 5.4GB
```

**Impl√©mentation** :
```bash
# Mise √† jour dynamique (sans red√©marrage)
redis-cli CONFIG SET maxmemory 5gb

# Persist√© dans redis.conf
echo "maxmemory 5gb" >> /etc/redis/redis.conf
```

#### Solution 2 : Optimisation des TTL

**Strat√©gie** : R√©duire le working set en diminuant les TTL des donn√©es froides

```python
# Analyse : Identifier les patterns d'acc√®s
def analyze_key_access():
    for key in redis.scan_iter():
        last_access = redis.object("idletime", key)  # Secondes depuis dernier acc√®s
        ttl = redis.ttl(key)

        if last_access > ttl * 0.8:
            # Cl√© rarement acc√©d√©e mais avec TTL long
            print(f"Candidate for shorter TTL: {key}")

# Ajustement
# Avant
redis.setex("cold_data", 3600, data)  # 1h

# Apr√®s
redis.setex("cold_data", 600, data)   # 10 min
```

#### Solution 3 : Compression des donn√©es

```python
import zlib
import json

# Avant compression
data = {"user": "john", "email": "john@example.com", ...}
redis.set("user:123", json.dumps(data))
# Taille : ~500 bytes

# Avec compression
data_json = json.dumps(data)
data_compressed = zlib.compress(data_json.encode(), level=6)
redis.set("user:123", data_compressed)
# Taille : ~150 bytes (70% √©conomie)

# Lecture
data_compressed = redis.get("user:123")
data_json = zlib.decompress(data_compressed).decode()
data = json.loads(data_json)
```

**Gain** :
```
Avant : 10M cl√©s √ó 500 bytes = 5GB
Apr√®s : 10M cl√©s √ó 150 bytes = 1.5GB
√âconomie : 3.5GB (70%)
```

#### Solution 4 : Sharding (Redis Cluster)

**Quand sharder** :
- Dataset > 50GB
- √âvictions permanentes malgr√© max RAM
- Besoin de scalabilit√© horizontale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Application                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Redis Cluster    ‚îÇ
    ‚îÇ  (Hash Slots)     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Node1 ‚îÇ ‚îÇ Node2 ‚îÇ ‚îÇ Node3 ‚îÇ
‚îÇ 16GB  ‚îÇ ‚îÇ 16GB  ‚îÇ ‚îÇ 16GB  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Total : 48GB de cache distribu√©
```

### 3.7 Alerting sur les √©victions

#### Alerte de base

```yaml
- alert: RedisEvictingKeys
  expr: rate(redis_evicted_keys_total[5m]) > 0
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "Redis √©viction de cl√©s sur {{ $labels.instance }}"
    description: |
      Taux d'√©viction: {{ $value }} cl√©s/sec
      Cause probable: M√©moire insuffisante
```

#### Alerte conditionnelle (selon la politique)

```yaml
- alert: RedisEvictionWithNoEvictionPolicy
  expr: |
    rate(redis_evicted_keys_total[5m]) > 0
    and
    redis_config_maxmemory_policy == "noeviction"
  for: 1m
  labels:
    severity: critical
  annotations:
    summary: "CRITIQUE: √âvictions avec politique noeviction"
    description: |
      Des √©victions se produisent alors que la politique est noeviction
      Cela ne devrait JAMAIS arriver - Bug ou config incorrecte
```

#### Alerte de tendance

```yaml
- alert: RedisEvictionRateIncreasing
  expr: |
    rate(redis_evicted_keys_total[5m]) >
    rate(redis_evicted_keys_total[5m] offset 1h) * 2
  for: 15m
  labels:
    severity: warning
  annotations:
    summary: "Taux d'√©viction en augmentation rapide"
    description: "√âvictions doubl√©es en 1 heure - Dataset croissant ?"
```

## 4. Corr√©lation des trois m√©triques

### 4.1 Le triangle de la performance

```
         Hit Ratio ‚Üì
              ‚îÇ
              ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                   ‚îÇ
    ‚ñº                   ‚ñº
Fragmentation ‚Üë    √âvictions ‚Üë
    ‚îÇ                   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
        Probl√®me M√©moire
```

### 4.2 Patterns de corr√©lation courants

#### Pattern 1 : Cascade de d√©gradation

```
√âtape 1 : Fragmentation ‚Üë (1.2 ‚Üí 1.8)
         ‚Üì
√âtape 2 : M√©moire effective ‚Üì (moins de place pour donn√©es)
         ‚Üì
√âtape 3 : √âvictions ‚Üë (manque de place)
         ‚Üì
√âtape 4 : Hit ratio ‚Üì (cl√©s √©vict√©es = misses)
```

**Requ√™te Prometheus pour d√©tecter** :
```promql
# Alerte si les 3 m√©triques d√©grad√©es simultan√©ment
(
  redis_mem_fragmentation_ratio > 1.5
  and
  rate(redis_evicted_keys_total[5m]) > 10
  and
  (
    rate(redis_keyspace_hits_total[5m]) /
    (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))
  ) < 0.85
)
```

#### Pattern 2 : √âvictions sans fragmentation

```
Fragmentation : 1.2 (bon)
√âvictions : 100/s (√©lev√©)
Hit ratio : 75% (bas)

‚Üí Diagnostic : Maxmemory trop petit, pas de fragmentation
‚Üí Action : Augmenter RAM
```

#### Pattern 3 : Fragmentation sans √©viction

```
Fragmentation : 2.0 (√©lev√©)
√âvictions : 0
Hit ratio : 92% (bon)

‚Üí Diagnostic : Gaspillage m√©moire mais capacit√© suffisante
‚Üí Action : Active defrag ou red√©marrage planifi√© (moins urgent)
```

### 4.3 Dashboard de corr√©lation Grafana

**Vue unifi√©e recommand√©e** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Panel 1 : M√©triques actuelles (Single Stat)        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ  Hit Ratio  ‚îÇ Fragmentation‚îÇ  √âvictions  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ    89.2%    ‚îÇ     1.42     ‚îÇ   12.5/s    ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Panel 2 : Tendances sur 24h (Graph)                ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  Hit Ratio ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                   ‚îÇ
‚îÇ  Fragmentation ‚îÄ ‚îÄ ‚îÄ                                ‚îÇ
‚îÇ  √âvictions ¬∑¬∑¬∑¬∑¬∑¬∑¬∑                                  ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Panel 3 : Corr√©lation (Heatmap)                    ‚îÇ
‚îÇ                                                     ‚îÇ
‚îÇ  [Matrice de corr√©lation entre les 3 m√©triques]     ‚îÇ
‚îÇ                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Panel 4 : Actions recommand√©es (Table)             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ √âtat         ‚îÇ Action                      ‚îÇ     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§     ‚îÇ
‚îÇ  ‚îÇ ‚ö†Ô∏è √âvictions  ‚îÇ Augmenter maxmemory        ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ ‚ö†Ô∏è Fragm. 1.5 ‚îÇ Activer active defrag      ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Code JSON du dashboard** (extrait) :
```json
{
  "panels": [
    {
      "title": "M√©triques Critiques",
      "targets": [
        {
          "expr": "100 * (rate(redis_keyspace_hits_total[5m]) / (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m])))",
          "legendFormat": "Hit Ratio %"
        },
        {
          "expr": "redis_mem_fragmentation_ratio * 100",
          "legendFormat": "Fragmentation √ó100"
        },
        {
          "expr": "rate(redis_evicted_keys_total[5m])",
          "legendFormat": "√âvictions/s"
        }
      ]
    }
  ]
}
```

## 5. Strat√©gies op√©rationnelles avanc√©es

### 5.1 Matrice de d√©cision

| M√©triques | Diagnostic | Actions | Urgence |
|-----------|-----------|---------|---------|
| √âvictions > 0, Fragm < 1.5, Hit ratio < 90% | Sous-dimensionnement | Augmenter RAM | üî¥ Haute |
| √âvictions > 0, Fragm > 1.8, Hit ratio < 85% | Sous-dim + Fragmentation | Red√©marrage + RAM ‚Üë | üî¥ Haute |
| √âvictions = 0, Fragm > 2.0, Hit ratio > 90% | Fragmentation isol√©e | Active defrag ou red√©marrage planifi√© | üü° Moyenne |
| √âvictions = 0, Fragm < 1.5, Hit ratio < 85% | TTL inadapt√©s | Ajuster TTL, warming | üü° Moyenne |
| √âvictions = 0, Fragm < 1.5, Hit ratio > 95% | Optimal | Monitoring continu | üü¢ Basse |

### 5.2 Playbook d'intervention

#### Sc√©nario 1 : √âvictions actives

```bash
# 1. Confirmer les √©victions
redis-cli INFO stats | grep evicted_keys

# 2. V√©rifier la m√©moire
redis-cli INFO memory | grep -E "used_memory:|maxmemory:|used_memory_peak"

# 3. Analyser la politique
redis-cli CONFIG GET maxmemory-policy

# 4. Solution imm√©diate : Augmenter maxmemory (si RAM dispo)
redis-cli CONFIG SET maxmemory 8gb

# 5. Solution permanente : Provisionner plus de RAM ou sharder
```

#### Sc√©nario 2 : Fragmentation critique

```bash
# 1. Mesurer la fragmentation
redis-cli INFO memory | grep mem_fragmentation_ratio

# 2. Activer active defrag si pas d√©j√† fait
redis-cli CONFIG SET activedefrag yes

# 3. Monitorer l'√©volution
watch -n 60 'redis-cli INFO memory | grep -E "mem_fragmentation|active_defrag"'

# 4. Si pas d'am√©lioration apr√®s 24h : Planifier red√©marrage
```

#### Sc√©nario 3 : Hit ratio d√©grad√©

```bash
# 1. V√©rifier les √©victions
redis-cli INFO stats | grep evicted_keys

# 2. Analyser les TTL
redis-cli INFO keyspace

# 3. Identifier les patterns
redis-cli --bigkeys

# 4. Ajuster selon la cause
# - √âvictions ‚Üí Augmenter RAM
# - TTL courts ‚Üí Allonger TTL
# - Pattern impr√©visible ‚Üí Revoir strat√©gie caching
```

### 5.3 Automation via Runbooks

**Exemple de runbook Ansible** :
```yaml
---
- name: Redis Health Check and Remediation
  hosts: redis_servers
  tasks:
    - name: Get Redis metrics
      shell: redis-cli INFO stats
      register: redis_info

    - name: Check for evictions
      set_fact:
        evictions: "{{ redis_info.stdout | regex_search('evicted_keys:(\\d+)', '\\1') | first }}"

    - name: Alert if evictions detected
      debug:
        msg: "WARNING: {{ evictions }} evictions detected"
      when: evictions | int > 0

    - name: Get fragmentation ratio
      shell: redis-cli INFO memory | grep mem_fragmentation_ratio | cut -d: -f2
      register: fragmentation

    - name: Enable active defrag if fragmentation > 1.5
      command: redis-cli CONFIG SET activedefrag yes
      when: fragmentation.stdout | float > 1.5
```

## Conclusion

Les trois m√©triques cl√©s ‚Äî **hit ratio**, **fragmentation**, et **√©victions** ‚Äî forment le triangle de la sant√© Redis. Une surveillance proactive de ces m√©triques permet :

1. **Pr√©vention** : D√©tecter les probl√®mes avant impact utilisateur
2. **Optimisation** : Dimensionner correctement l'infrastructure
3. **√âconomies** : √âviter le surprovisionnement ou les incidents co√ªteux

**Points √† retenir** :
- Hit ratio > 90% = cache efficace
- Fragmentation < 1.5 = m√©moire utilis√©e efficacement
- √âvictions = 0 = capacit√© suffisante

**Prochaine action** : Mettre en place les dashboards et alertes recommand√©s dans cette section.

---

**Prochaine section** : 13.3 - Redis Exporter et Prometheus (configuration avanc√©e)

‚è≠Ô∏è [Redis Exporter et Prometheus](/13-monitoring-observabilite/03-redis-exporter-prometheus.md)
