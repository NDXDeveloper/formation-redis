üîù Retour au [Sommaire](/SOMMAIRE.md)

# 14.1 - Profiling : Slowlog et analyse des commandes lentes

## üéØ Objectifs de cette section

- Ma√Ætriser le SLOWLOG pour identifier les goulots d'√©tranglement
- Analyser et interpr√©ter les patterns de commandes lentes
- Mettre en place une m√©thodologie syst√©matique de profiling
- Identifier les optimisations critiques en production
- Pr√©venir les probl√®mes de performance avant qu'ils n'impactent les utilisateurs

---

## üìö Introduction : Pourquoi le profiling est critique

### Le paradoxe de Redis

Redis est con√ßu pour √™tre **extr√™mement rapide** :
- Ops/sec : 100,000+ par c≈ìur CPU
- Latence moyenne : < 1ms (souvent < 0.1ms)
- Architecture single-threaded optimis√©e

**Mais** : Une seule commande lente peut bloquer toutes les autres requ√™tes.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Temps d'ex√©cution des commandes                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  GET key          ‚Üí  0.05ms  ‚úÖ                 ‚îÇ
‚îÇ  SET key value    ‚Üí  0.06ms  ‚úÖ                 ‚îÇ
‚îÇ  INCR counter     ‚Üí  0.04ms  ‚úÖ                 ‚îÇ
‚îÇ  KEYS *           ‚Üí 500.00ms  ‚ùå CATASTROPHE    ‚îÇ
‚îÇ  GET key2         ‚Üí  0.05ms (attend 500ms!)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Impact** : Pendant que KEYS * s'ex√©cute, toutes les autres commandes sont en attente.

### Les 3 niveaux de "lenteur"

| Niveau | Dur√©e | Impact | Priorit√© |
|--------|-------|--------|----------|
| **Acceptable** | < 1ms | Aucun | Monitoring |
| **Pr√©occupant** | 1-10ms | Latence perceptible | Investigation |
| **Critique** | > 10ms | Timeouts, erreurs | Action imm√©diate |

---

## üîß Le SLOWLOG : Votre meilleur alli√©

### Qu'est-ce que le SLOWLOG ?

Le SLOWLOG est un **enregistreur de commandes lentes** int√©gr√© √† Redis :
- Enregistre automatiquement les commandes d√©passant un seuil
- Stock√© en m√©moire (pas d'impact I/O)
- FIFO avec taille configurable
- Impact minimal sur les performances

### Architecture du SLOWLOG

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ          REDIS INSTANCE                        ‚îÇ
‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Command Queue                         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ GET  ‚îÇ SET  ‚îÇ KEYS ‚îÇ GET  ‚îÇ         ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ               ‚Üì                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Execution Timer                       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  (mesure le temps d'ex√©cution)         ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ               ‚Üì                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Slowlog Threshold Check               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  Si dur√©e > slowlog-log-slower-than    ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ               ‚Üì                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  SLOWLOG (ring buffer in-memory)       ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Entry 1: KEYS * (500ms)      ‚îÇ      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Entry 2: SMEMBERS big (50ms) ‚îÇ      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Entry 3: HGETALL huge (20ms) ‚îÇ      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ ...                          ‚îÇ      ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚öôÔ∏è Configuration du SLOWLOG

### Param√®tres de configuration

#### 1. `slowlog-log-slower-than` (seuil en microsecondes)

D√©finit √† partir de quelle dur√©e une commande est consid√©r√©e comme "lente".

```bash
# Valeur par d√©faut : 10000 (10ms)
CONFIG GET slowlog-log-slower-than
# R√©sultat : "10000"

# Modifier le seuil (runtime)
CONFIG SET slowlog-log-slower-than 1000  # 1ms

# Modifier dans redis.conf (permanent)
slowlog-log-slower-than 1000
```

**Valeurs recommand√©es** :

| Environnement | Seuil | Justification |
|---------------|-------|---------------|
| **Production critique** | 1000 Œºs (1ms) | D√©tection pr√©coce |
| **Production standard** | 10000 Œºs (10ms) | √âquilibre performance/d√©tection |
| **D√©veloppement** | 100 Œºs (0.1ms) | Profiling agressif |
| **Debugging** | 0 Œºs | Log TOUTES les commandes |

‚ö†Ô∏è **Attention** : `slowlog-log-slower-than 0` log TOUTES les commandes ‚Üí Impact m√©moire !

#### 2. `slowlog-max-len` (nombre d'entr√©es)

D√©finit le nombre maximum d'entr√©es dans le SLOWLOG.

```bash
# Valeur par d√©faut : 128
CONFIG GET slowlog-max-len
# R√©sultat : "128"

# Augmenter la taille
CONFIG SET slowlog-max-len 1000

# Dans redis.conf
slowlog-max-len 1000
```

**Calcul de la m√©moire utilis√©e** :

```
Chaque entr√©e ‚âà 250-500 bytes (selon la longueur de la commande)

128 entr√©es   ‚âà  32-64 KB   ‚úÖ Minimal
1000 entr√©es  ‚âà 250-500 KB  ‚úÖ Raisonnable
10000 entr√©es ‚âà 2.5-5 MB    ‚ö†Ô∏è Attention en production
```

### Configuration recommand√©e pour la production

```conf
# redis.conf

# Seuil agressif pour d√©tecter les probl√®mes t√¥t
slowlog-log-slower-than 1000  # 1ms

# Historique suffisant pour analyser les patterns
slowlog-max-len 500

# Alternative : seuil plus tol√©rant
# slowlog-log-slower-than 5000  # 5ms
# slowlog-max-len 1000
```

---

## üîç Utilisation du SLOWLOG

### Commandes principales

#### 1. SLOWLOG GET [count]

R√©cup√®re les derni√®res entr√©es du SLOWLOG.

```bash
# R√©cup√©rer les 10 derni√®res entr√©es
redis-cli SLOWLOG GET 10
```

**Format de sortie** :

```bash
1) 1) (integer) 14           # ID unique de l'entr√©e
   2) (integer) 1702293847   # Timestamp Unix
   3) (integer) 52431        # Dur√©e en microsecondes (52.4ms)
   4) 1) "KEYS"              # Commande
      2) "*"                 # Arguments
   5) "127.0.0.1:43501"      # Client IP:port
   6) "client-name"          # Nom du client (si d√©fini)

2) 1) (integer) 13
   2) (integer) 1702293845
   3) (integer) 15234
   4) 1) "SMEMBERS"
      2) "large_set"
   5) "127.0.0.1:43502"
   6) ""
```

#### 2. SLOWLOG LEN

Retourne le nombre d'entr√©es actuelles dans le SLOWLOG.

```bash
redis-cli SLOWLOG LEN
# R√©sultat : (integer) 127
```

#### 3. SLOWLOG RESET

Vide compl√®tement le SLOWLOG.

```bash
redis-cli SLOWLOG RESET
# R√©sultat : OK
```

**Utilisation** : Nettoyer avant un test de charge sp√©cifique.

---

## üìä M√©thodologie d'analyse : Le framework SLOW-CHECK

### √âtape 1 : Capture initiale (SNAPSHOT)

```bash
#!/bin/bash
# Script de capture du SLOWLOG

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
OUTPUT_FILE="slowlog_${TIMESTAMP}.txt"

echo "=== SLOWLOG SNAPSHOT ===" > $OUTPUT_FILE
echo "Date: $(date)" >> $OUTPUT_FILE
echo "" >> $OUTPUT_FILE

# Informations contextuelles
echo "--- Redis Info ---" >> $OUTPUT_FILE
redis-cli INFO stats | grep -E "total_commands|instantaneous_ops" >> $OUTPUT_FILE
redis-cli INFO memory | grep -E "used_memory_human|mem_fragmentation" >> $OUTPUT_FILE
echo "" >> $OUTPUT_FILE

# SLOWLOG complet
echo "--- SLOWLOG Entries ---" >> $OUTPUT_FILE
redis-cli SLOWLOG GET 200 >> $OUTPUT_FILE

# R√©sum√©
echo "" >> $OUTPUT_FILE
echo "--- Summary ---" >> $OUTPUT_FILE
redis-cli SLOWLOG LEN >> $OUTPUT_FILE

echo "Snapshot saved to: $OUTPUT_FILE"
```

### √âtape 2 : Analyse des patterns (PATTERN DETECTION)

#### Extraction et agr√©gation

```bash
# Extraire uniquement les commandes
redis-cli SLOWLOG GET 100 | grep -A 2 "integer" | grep -v "integer" | grep -v "^--$"

# Compter les occurrences par type de commande
redis-cli SLOWLOG GET 100 | \
  grep -E "^\s+[0-9]+\)" | \
  awk '{print $1}' | \
  sort | uniq -c | sort -rn
```

**Script d'analyse Python** :

```python
#!/usr/bin/env python3
import redis
from collections import Counter
import statistics

def analyze_slowlog(host='localhost', port=6379):
    r = redis.Redis(host=host, port=port, decode_responses=True)

    slowlog = r.slowlog_get(500)

    if not slowlog:
        print("No slow queries found.")
        return

    # Analyse par type de commande
    commands = Counter()
    durations = []
    command_durations = {}

    for entry in slowlog:
        cmd = entry['command']
        duration = entry['duration']  # en microsecondes

        commands[cmd] += 1
        durations.append(duration)

        if cmd not in command_durations:
            command_durations[cmd] = []
        command_durations[cmd].append(duration)

    # R√©sultats
    print("=== SLOWLOG ANALYSIS ===\n")

    print(f"Total slow queries: {len(slowlog)}")
    print(f"Unique commands: {len(commands)}\n")

    print("--- Top 10 slowest commands ---")
    for cmd, count in commands.most_common(10):
        avg_duration = statistics.mean(command_durations[cmd])
        max_duration = max(command_durations[cmd])
        print(f"{cmd:20} | Count: {count:4} | Avg: {avg_duration/1000:7.2f}ms | Max: {max_duration/1000:7.2f}ms")

    print("\n--- Duration statistics ---")
    print(f"Average: {statistics.mean(durations)/1000:.2f}ms")
    print(f"Median:  {statistics.median(durations)/1000:.2f}ms")
    print(f"P95:     {sorted(durations)[int(len(durations)*0.95)]/1000:.2f}ms")
    print(f"P99:     {sorted(durations)[int(len(durations)*0.99)]/1000:.2f}ms")
    print(f"Max:     {max(durations)/1000:.2f}ms")

if __name__ == "__main__":
    analyze_slowlog()
```

### √âtape 3 : Identification des causes (ROOT CAUSE)

Pour chaque commande lente identifi√©e :

#### Questions √† poser :

1. **Quelle est la commande ?**
   - Commande O(N) ? (KEYS, SMEMBERS, HGETALL...)
   - Commande O(1) mais sur une big key ?
   - Commande avec arguments probl√©matiques ?

2. **Quelle est la fr√©quence ?**
   - Sporadique ‚Üí Probl√®me ponctuel
   - R√©guli√®re ‚Üí Pattern d'acc√®s probl√©matique
   - Continue ‚Üí D√©faut de conception

3. **Quel est le client ?**
   - Quelle application ?
   - Quelle version du code ?
   - Y a-t-il un pattern temporel ?

4. **Quel est le contexte syst√®me ?**
   - CPU √©lev√© au moment de la commande ?
   - M√©moire satur√©e ?
   - I/O disque (persistance) ?

---

## üé≠ Les patterns de commandes lentes classiques

### Pattern 1 : KEYS * (Le tueur silencieux)

**Signature SLOWLOG** :
```
1) "KEYS"
2) "*"
Duration: 500-5000ms (selon la taille du keyspace)
```

**Pourquoi c'est lent** :
- O(N) o√π N = nombre total de cl√©s
- Bloque Redis pendant toute la dur√©e
- Aucune possibilit√© d'interruption

**Impact** :
```
1M cl√©s ‚Üí 1-2 secondes de blocage total
10M cl√©s ‚Üí 10-20 secondes de blocage total
```

**Solution** :

```bash
# ‚ùå JAMAIS
KEYS *

# ‚úÖ TOUJOURS
SCAN 0 MATCH pattern* COUNT 100

# Alternative avec SCAN complet
cursor=0
while true; do
    result=$(redis-cli SCAN $cursor MATCH "user:*" COUNT 1000)
    cursor=$(echo "$result" | head -1)
    keys=$(echo "$result" | tail -n +2)

    # Traiter les cl√©s ici
    echo "$keys"

    # Si cursor = 0, on a fini
    [ "$cursor" -eq 0 ] && break
done
```

### Pattern 2 : SMEMBERS sur un gros Set

**Signature SLOWLOG** :
```
1) "SMEMBERS"
2) "large_set"
Duration: 50-500ms
```

**Pourquoi c'est lent** :
- O(N) o√π N = nombre d'√©l√©ments dans le set
- Retourne TOUS les membres en une seule fois
- Consommation m√©moire sur le client

**Diagnostic** :

```bash
# V√©rifier la taille du set
redis-cli SCARD large_set
# R√©sultat : 500000

# Estimer la m√©moire
redis-cli MEMORY USAGE large_set
# R√©sultat : 50000000 (50MB)
```

**Solution** :

```bash
# ‚ùå √âviter
SMEMBERS large_set

# ‚úÖ Utiliser SSCAN
SSCAN large_set 0 COUNT 100

# ‚úÖ Ou limiter avec SRANDMEMBER
SRANDMEMBER large_set 100  # R√©cup√®re 100 membres al√©atoires
```

### Pattern 3 : HGETALL sur un gros Hash

**Signature SLOWLOG** :
```
1) "HGETALL"
2) "user:12345:profile"
Duration: 20-200ms
```

**Pourquoi c'est lent** :
- O(N) o√π N = nombre de champs
- Retourne tous les champs d'un coup

**Diagnostic** :

```bash
# Nombre de champs
redis-cli HLEN user:12345:profile
# R√©sultat : 10000

# M√©moire utilis√©e
redis-cli MEMORY USAGE user:12345:profile
# R√©sultat : 5000000 (5MB)
```

**Solution** :

```bash
# ‚ùå √âviter
HGETALL user:12345:profile

# ‚úÖ R√©cup√©rer uniquement les champs n√©cessaires
HMGET user:12345:profile name email age

# ‚úÖ Si vraiment besoin de tout, utiliser HSCAN
HSCAN user:12345:profile 0 COUNT 100

# ‚úÖ Refactorer le mod√®le de donn√©es
# Au lieu d'un gros hash, utiliser plusieurs petits hash
HMGET user:12345:basic name email
HMGET user:12345:preferences theme language
HMGET user:12345:stats loginCount lastLogin
```

### Pattern 4 : LRANGE avec gros range

**Signature SLOWLOG** :
```
1) "LRANGE"
2) "queue:tasks"
3) "0"
4) "-1"
Duration: 30-300ms
```

**Probl√®me** :
```bash
# ‚ùå R√©cup√©rer toute la liste
LRANGE queue:tasks 0 -1

# La liste contient 100,000 √©l√©ments !
LLEN queue:tasks
# R√©sultat : 100000
```

**Solution** :

```bash
# ‚úÖ Pagination
LRANGE queue:tasks 0 99    # Premiers 100 √©l√©ments
LRANGE queue:tasks 100 199 # 100 suivants

# ‚úÖ Pour une queue, utiliser LPOP/RPOP
LPOP queue:tasks 100  # Redis 6.2+ : pop multiple

# ‚úÖ Ou utiliser Redis Streams (meilleure solution)
XREAD COUNT 100 STREAMS mystream 0-0
```

### Pattern 5 : SORT (Tri complexe)

**Signature SLOWLOG** :
```
1) "SORT"
2) "list:items"
3) "BY"
4) "item:*->price"
5) "GET"
6) "item:*->name"
Duration: 100-1000ms
```

**Pourquoi c'est lent** :
- O(N log N) pour le tri
- Acc√®s multiples √† d'autres cl√©s
- Pas de cache du r√©sultat

**Solution** :

```bash
# ‚ùå √âviter SORT complexe
SORT list:items BY item:*->price GET item:*->name

# ‚úÖ Utiliser un Sorted Set √† la place
# Ins√©rer les items d√©j√† tri√©s par prix
ZADD items:by_price 19.99 "item:1" 29.99 "item:2"

# R√©cup√©rer tri√©s instantan√©ment (O(log N))
ZRANGE items:by_price 0 9 WITHSCORES

# ‚úÖ Pr√©-calculer et cacher le r√©sultat
# Sortir le tri de Redis si possible
```

### Pattern 6 : SUNION/SINTER/SDIFF sur gros Sets

**Signature SLOWLOG** :
```
1) "SUNION"
2) "set:tags:1"
3) "set:tags:2"
4) "set:tags:3"
Duration: 50-500ms
```

**Probl√®me** :
- O(N) o√π N = somme des √©l√©ments de tous les sets
- Peut cr√©er un tr√®s gros r√©sultat temporaire

**Solution** :

```bash
# ‚ùå √âviter sur de gros sets
SUNION set:tags:1 set:tags:2 set:tags:3

# ‚úÖ Alternative 1 : Limiter le nombre de sets
SUNION set:tags:1 set:tags:2  # Max 2-3 sets

# ‚úÖ Alternative 2 : Utiliser SUNIONSTORE + pagination
SUNIONSTORE result:temp set:tags:1 set:tags:2
SSCAN result:temp 0 COUNT 100
DEL result:temp

# ‚úÖ Alternative 3 : Revoir le mod√®le de donn√©es
# Utiliser des Sorted Sets avec timestamps
ZADD tags:all timestamp1 "tag1" timestamp2 "tag2"
```

---

## üî¨ Techniques avanc√©es de profiling

### 1. Profiling en temps r√©el avec MONITOR (DANGER)

‚ö†Ô∏è **ATTENTION** : MONITOR a un impact MAJEUR sur les performances.

**Utilisation s√©curis√©e** :

```bash
# ‚úÖ Limiter la dur√©e √† quelques secondes maximum
timeout 5 redis-cli MONITOR > monitor_output.txt

# ‚úÖ Rediriger vers un fichier pour analyse offline
redis-cli MONITOR | head -n 10000 > commands.log

# ‚úÖ Filtrer en temps r√©el
redis-cli MONITOR | grep "KEYS"
```

**Analyse de la sortie MONITOR** :

```bash
# Format de sortie :
# timestamp [database client] "command" "arg1" "arg2"
1702293847.123456 [0 127.0.0.1:43501] "SET" "user:123" "value"
1702293847.234567 [0 127.0.0.1:43502] "GET" "user:123"

# Analyser les patterns
cat monitor_output.txt | awk '{print $4}' | sort | uniq -c | sort -rn | head -20
```

### 2. Analyse avec redis-cli --latency

```bash
# Latency en temps r√©el
redis-cli --latency

# Latency avec historique
redis-cli --latency-history

# Latency distribution
redis-cli --latency-dist

# Monitoring de latence intrins√®que
redis-cli --intrinsic-latency 60  # Test pendant 60 secondes
```

### 3. Corr√©lation SLOWLOG + M√©triques syst√®me

**Script de corr√©lation** :

```bash
#!/bin/bash
# Capture synchronis√©e SLOWLOG + m√©triques syst√®me

while true; do
    TIMESTAMP=$(date +%s)

    # SLOWLOG
    SLOW_COUNT=$(redis-cli SLOWLOG LEN)

    # M√©triques syst√®me
    CPU=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}')
    MEM=$(free | grep Mem | awk '{print ($3/$2) * 100.0}')

    # Redis stats
    OPS=$(redis-cli INFO stats | grep instantaneous_ops_per_sec | cut -d: -f2)

    echo "$TIMESTAMP,$SLOW_COUNT,$CPU,$MEM,$OPS"

    sleep 5
done > metrics_correlation.csv
```

**Analyse** :

```python
import pandas as pd
import matplotlib.pyplot as plt

# Charger les donn√©es
df = pd.read_csv('metrics_correlation.csv',
                 names=['timestamp', 'slow_count', 'cpu', 'memory', 'ops'])

# Calculer les corr√©lations
correlations = df.corr()
print("Correlation avec slow_count:")
print(correlations['slow_count'].sort_values(ascending=False))

# Visualiser
fig, axes = plt.subplots(3, 1, figsize=(12, 10))
axes[0].plot(df['timestamp'], df['slow_count'])
axes[0].set_title('Slow Queries over Time')

axes[1].plot(df['timestamp'], df['cpu'])
axes[1].set_title('CPU Usage')

axes[2].plot(df['timestamp'], df['ops'])
axes[2].set_title('Operations per Second')

plt.tight_layout()
plt.savefig('slowlog_correlation.png')
```

---

## üéØ Guide de r√©solution pas √† pas

### Sc√©nario 1 : Pic soudain de commandes lentes

**Sympt√¥mes** :
- Alertes de latence
- SLOWLOG LEN augmente rapidement
- Applications signalent des timeouts

**Investigation** :

```bash
# √âtape 1 : Quick check
redis-cli SLOWLOG GET 10

# √âtape 2 : Identifier le pattern
redis-cli SLOWLOG GET 100 | grep -E "^\s+[0-9]+\)" | head -20

# √âtape 3 : V√©rifier la charge syst√®me
redis-cli INFO stats | grep instantaneous_ops_per_sec
top -p $(pgrep redis-server)

# √âtape 4 : Identifier le client probl√©matique
redis-cli CLIENT LIST | grep -v "idle=0"
```

**Actions** :

```bash
# Si un client ex√©cute une commande bloquante
redis-cli CLIENT LIST | grep "cmd=KEYS"
# Killer le client si n√©cessaire
redis-cli CLIENT KILL ID <client-id>

# Si c'est un pattern d'acc√®s
# ‚Üí Contacter l'√©quipe de dev pour optimiser
# ‚Üí Mettre en place un rate limiting temporaire
```

### Sc√©nario 2 : D√©gradation progressive des performances

**Sympt√¥mes** :
- SLOWLOG se remplit de plus en plus
- Commandes auparavant rapides deviennent lentes
- Fragmentation m√©moire √©lev√©e

**Investigation** :

```bash
# √âtape 1 : Historique du SLOWLOG
redis-cli SLOWLOG GET 500 > slowlog_history.txt

# √âtape 2 : Analyse temporelle
# Extraire les timestamps
awk '/integer/ {if (NR % 6 == 2) print $2}' slowlog_history.txt | sort | uniq -c

# √âtape 3 : V√©rifier les big keys
redis-cli --bigkeys

# √âtape 4 : Memory analysis
redis-cli INFO memory
redis-cli MEMORY DOCTOR
```

**Causes possibles** :

1. **Croissance des donn√©es**
   ```bash
   # Comparer la taille actuelle avec le baseline
   redis-cli DBSIZE
   redis-cli INFO memory | grep used_memory_human
   ```

2. **Fragmentation m√©moire**
   ```bash
   redis-cli INFO memory | grep mem_fragmentation_ratio
   # Si > 1.5 ‚Üí Consid√©rer un restart ou active defrag
   ```

3. **Big keys accumul√©es**
   ```bash
   redis-cli --bigkeys --bigkeys-output bigkeys.txt
   # Analyser et nettoyer
   ```

### Sc√©nario 3 : Commande sp√©cifique toujours lente

**Investigation approfondie** :

```bash
# 1. Identifier la commande exacte
redis-cli SLOWLOG GET 100 | grep -A 5 "COMMAND_NAME"

# 2. Tester la commande manuellement
redis-cli --latency-history <<EOF
COMMAND_NAME args
EOF

# 3. Analyser la complexit√©
redis-cli TYPE key_name
redis-cli OBJECT ENCODING key_name

# 4. Mesurer la taille
redis-cli MEMORY USAGE key_name
redis-cli STRLEN key_name  # Pour strings
redis-cli LLEN key_name    # Pour lists
redis-cli HLEN key_name    # Pour hashes
redis-cli SCARD key_name   # Pour sets
redis-cli ZCARD key_name   # Pour sorted sets
```

**Plan d'action** :

```bash
# Option 1 : Refactoring
# - Diviser les big keys
# - Changer le mod√®le de donn√©es

# Option 2 : Optimisation de la commande
# - SMEMBERS ‚Üí SSCAN
# - HGETALL ‚Üí HMGET
# - KEYS ‚Üí SCAN

# Option 3 : Cache c√¥t√© application
# - Cacher le r√©sultat si la donn√©e ne change pas souvent
# - Impl√©menter un cache local avec TTL
```

---

## üìà Dashboard et monitoring continu

### M√©triques cl√©s √† monitorer

```bash
# Script de collecte pour Prometheus/Grafana
#!/bin/bash

# Nombre d'entr√©es dans le SLOWLOG
SLOWLOG_LEN=$(redis-cli SLOWLOG LEN)

# Dur√©e max de la derni√®re commande lente
LAST_SLOW_DURATION=$(redis-cli SLOWLOG GET 1 | grep -A 1 "integer) 3" | tail -1 | awk '{print $2}')

# Taux de commandes lentes par seconde
# (n√©cessite de tracker le delta)

echo "redis_slowlog_length{instance=\"redis1\"} $SLOWLOG_LEN"
echo "redis_slowlog_last_duration_us{instance=\"redis1\"} $LAST_SLOW_DURATION"
```

### Alertes recommand√©es

```yaml
# Prometheus alerting rules
groups:
  - name: redis_slowlog
    rules:
      - alert: RedisSlowlogGrowing
        expr: increase(redis_slowlog_length[5m]) > 50
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Redis SLOWLOG growing rapidly"
          description: "{{ $labels.instance }} has logged {{ $value }} slow queries in 5min"

      - alert: RedisSlowlogCritical
        expr: redis_slowlog_last_duration_us > 50000
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis extremely slow query detected"
          description: "{{ $labels.instance }} had a query taking {{ $value }}Œºs ({{ humanizeDuration $value }})"

      - alert: RedisSlowlogFull
        expr: redis_slowlog_length >= 500
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Redis SLOWLOG is full"
          description: "Consider increasing slowlog-max-len or investigating the slow queries"
```

---

## üéì Best Practices

### Configuration

‚úÖ **DO**
- Configurer un seuil bas en production (1-5ms) pour d√©tection pr√©coce
- Maintenir un historique suffisant (500-1000 entr√©es)
- Monitorer le SLOWLOG en continu via Prometheus
- Exporter r√©guli√®rement le SLOWLOG pour analyse historique

‚ùå **DON'T**
- Ne pas configurer un seuil trop bas (< 100Œºs) sans raison
- Ne pas ignorer le SLOWLOG pendant des semaines
- Ne jamais utiliser `slowlog-log-slower-than -1` (d√©sactiv√©) en production

### Analyse

‚úÖ **DO**
- Analyser le SLOWLOG quotidiennement
- Corr√©ler avec les m√©triques syst√®me et applicatives
- Documenter les patterns r√©currents
- Cr√©er des runbooks pour les probl√®mes fr√©quents

‚ùå **DON'T**
- Ne pas se fier uniquement au SLOWLOG (analyser aussi le contexte)
- Ne pas ignorer les commandes "mod√©r√©ment lentes" (5-10ms)
- Ne pas supposer que toutes les commandes lentes sont probl√©matiques

### R√©solution

‚úÖ **DO**
- Tester les solutions en dev/staging avant la production
- Documenter chaque intervention
- V√©rifier l'impact des changements
- Impliquer les d√©veloppeurs dans l'optimisation

‚ùå **DON'T**
- Ne jamais red√©marrer Redis sans comprendre la cause
- Ne pas modifier la configuration sans backup
- Ne pas optimiser pr√©matur√©ment (profiling d'abord!)

---

## üîó Checklist de profiling

### Avant de d√©ployer en production

- [ ] SLOWLOG configur√© avec un seuil appropri√©
- [ ] Monitoring du SLOWLOG en place (Grafana)
- [ ] Alertes configur√©es pour commandes critiques
- [ ] Script d'export du SLOWLOG automatis√©
- [ ] Runbooks cr√©√©s pour les patterns connus
- [ ] √âquipe form√©e √† l'interpr√©tation du SLOWLOG

### En cas de probl√®me de performance

- [ ] Consulter le SLOWLOG imm√©diatement
- [ ] Identifier le pattern de commandes lentes
- [ ] V√©rifier les m√©triques syst√®me corr√©l√©es
- [ ] Identifier le client/application responsable
- [ ] Tester la reproduction en environnement contr√¥l√©
- [ ] Appliquer le correctif et valider
- [ ] Documenter l'incident (post-mortem)

---

## üìö Ressources compl√©mentaires

### Documentation officielle
- [Redis SLOWLOG](https://redis.io/commands/slowlog/)
- [Redis Latency Monitoring](https://redis.io/docs/management/optimization/latency/)

### Outils
- **Redis Insight** : Visualisation du SLOWLOG dans l'interface graphique
- **redis-cli --latency** : Tests de latence int√©gr√©s
- **Prometheus + Grafana** : Monitoring continu

### Lectures avanc√©es
- "Redis in Action" - Chapter on Performance
- Blog Antirez (cr√©ateur de Redis) sur l'optimisation
- Redis Labs blogs sur le profiling

---

## üéØ Points cl√©s √† retenir

1. **Le SLOWLOG est votre premier outil de profiling** - Configurez-le d√®s le d√©part
2. **Une commande lente bloque toutes les autres** - L'architecture single-threaded ne pardonne pas
3. **O(N) est l'ennemi** - √âvitez KEYS, SMEMBERS, HGETALL sur de grosses donn√©es
4. **Profilez avant d'optimiser** - Ne devinez pas, mesurez !
5. **Corr√©lation = cl√© du diagnostic** - SLOWLOG + m√©triques syst√®me + logs applicatifs
6. **Monitoring continu > r√©action** - D√©tectez les probl√®mes avant qu'ils n'impactent les utilisateurs

---

**üöÄ Section suivante** : [14.2 - Memory Analysis : --bigkeys, --memkeys et memory doctor](./02-memory-analysis-bigkeys-memkeys.md)

‚è≠Ô∏è [Memory Analysis : --bigkeys, --memkeys et memory doctor](/14-performance-troubleshooting/02-memory-analysis-bigkeys-memkeys.md)
