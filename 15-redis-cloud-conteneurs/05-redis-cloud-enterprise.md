ğŸ” Retour au [Sommaire](/SOMMAIRE.md)

# 15.5 Redis Cloud (Redis Enterprise Cloud)

## ğŸ¯ Objectifs

- MaÃ®triser l'architecture Active-Active avec CRDTs
- Comprendre les modules Redis Stack et leurs cas d'usage
- Configurer des dÃ©ploiements multi-cloud avec Terraform
- ImplÃ©menter des stratÃ©gies de geo-distribution
- Optimiser les coÃ»ts avec le tiering RAM+Flash
- Ã‰valuer le ROI de Redis Enterprise vs solutions cloud natives

---

## ğŸ—ï¸ Architecture et positionnement unique

### Vue d'ensemble Redis Enterprise Cloud

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Redis Enterprise Cloud - Architecture             â”‚
â”‚                                                                â”‚
â”‚  Unique Value Proposition:                                     â”‚
â”‚  â”œâ”€ Seule solution avec Active-Active (multi-region R/W)       â”‚
â”‚  â”œâ”€ Tous les modules Redis Stack inclus                        â”‚
â”‚  â”œâ”€ Multi-cloud support (AWS + Azure + GCP)                    â”‚
â”‚  â”œâ”€ Auto-scaling et auto-tiering                               â”‚
â”‚  â””â”€ SLA 99.999% (5 minutes downtime/an)                        â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Region 1    â”‚  â”‚  Region 2    â”‚  â”‚  Region 3    â”‚          â”‚
â”‚  â”‚  (AWS)       â”‚  â”‚  (Azure)     â”‚  â”‚  (GCP)       â”‚          â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚          â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚          â”‚
â”‚  â”‚ â”‚Active DB â”‚â—„â”¼â”€â”€â”¼â–ºâ”‚Active DB â”‚â—„â”¼â”€â”€â”¼â–ºâ”‚Active DB â”‚ â”‚          â”‚
â”‚  â”‚ â”‚          â”‚ â”‚  â”‚ â”‚          â”‚ â”‚  â”‚ â”‚          â”‚ â”‚          â”‚
â”‚  â”‚ â”‚ Read +   â”‚ â”‚  â”‚ â”‚ Read +   â”‚ â”‚  â”‚ â”‚ Read +   â”‚ â”‚          â”‚
â”‚  â”‚ â”‚ Write    â”‚ â”‚  â”‚ â”‚ Write    â”‚ â”‚  â”‚ â”‚ Write    â”‚ â”‚          â”‚
â”‚  â”‚ â”‚          â”‚ â”‚  â”‚ â”‚          â”‚ â”‚  â”‚ â”‚          â”‚ â”‚          â”‚
â”‚  â”‚ â”‚ CRDTs    â”‚ â”‚  â”‚ â”‚ CRDTs    â”‚ â”‚  â”‚ â”‚ CRDTs    â”‚ â”‚          â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                â”‚
â”‚  Conflict-Free Replicated Data Types (CRDTs):                  â”‚
â”‚  â”œâ”€ Counter: Automatic addition (v1 + v2)                      â”‚
â”‚  â”œâ”€ String: Last-Write-Wins avec timestamps                    â”‚
â”‚  â”œâ”€ Set: Union (v1 âˆª v2)                                       â”‚
â”‚  â”œâ”€ Sorted Set: Max score wins                                 â”‚
â”‚  â””â”€ Hash: Field-level LWW                                      â”‚
â”‚                                                                â”‚
â”‚  Key Benefits:                                                 â”‚
â”‚  â€¢ Local read/write latency (<1ms) everywhere                  â”‚
â”‚  â€¢ No single point of failure (all regions active)             â”‚
â”‚  â€¢ Automatic conflict resolution                               â”‚
â”‚  â€¢ No application changes needed                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture technique dÃ©taillÃ©e

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Redis Enterprise Cloud - Technical Stack                    â”‚
â”‚                                                                     â”‚
â”‚  Application Layer                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Your Application (any language)                             â”‚   â”‚
â”‚  â”‚  â””â”€ Redis client library                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                          â”‚
â”‚                          â”‚ Standard Redis protocol                  â”‚
â”‚                          â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Redis Enterprise Proxy Layer                                â”‚   â”‚
â”‚  â”‚  â”œâ”€ Load balancing                                           â”‚   â”‚
â”‚  â”‚  â”œâ”€ High availability                                        â”‚   â”‚
â”‚  â”‚  â”œâ”€ Connection pooling                                       â”‚   â”‚
â”‚  â”‚  â””â”€ Protocol optimization                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                          â”‚
â”‚                          â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Redis Enterprise Cluster                                    â”‚   â”‚
â”‚  â”‚                                                              â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   Shard 1      â”‚  â”‚   Shard 2      â”‚  â”‚   Shard 3      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                â”‚  â”‚                â”‚  â”‚                â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚Primary   â”‚  â”‚  â”‚  â”‚Primary   â”‚  â”‚  â”‚  â”‚Primary   â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚          â”‚  â”‚  â”‚  â”‚          â”‚  â”‚  â”‚  â”‚          â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ RAM      â”‚  â”‚  â”‚  â”‚ RAM      â”‚  â”‚  â”‚  â”‚ RAM      â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  +       â”‚  â”‚  â”‚  â”‚  +       â”‚  â”‚  â”‚  â”‚  +       â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Flash    â”‚  â”‚  â”‚  â”‚ Flash    â”‚  â”‚  â”‚  â”‚  Flash   â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚(optional)â”‚  â”‚  â”‚  â”‚(optional)â”‚  â”‚  â”‚  â”‚(optional)â”‚  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â”‚Replica â”‚    â”‚  â”‚  â”‚Replica â”‚    â”‚  â”‚  â”‚Replica â”‚    â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                              â”‚   â”‚
â”‚  â”‚  Features:                                                   â”‚   â”‚
â”‚  â”‚  â”œâ”€ Automatic sharding                                       â”‚   â”‚
â”‚  â”‚  â”œâ”€ Instant failover (<1s)                                   â”‚   â”‚
â”‚  â”‚  â”œâ”€ Zero-downtime scaling                                    â”‚   â”‚
â”‚  â”‚  â”œâ”€ Auto-tiering (RAM+Flash)                                 â”‚   â”‚
â”‚  â”‚  â””â”€ Geo-distributed replication                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                                          â”‚
â”‚                          â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Redis Stack Modules (integrated)                            â”‚   â”‚
â”‚  â”‚  â”œâ”€ RediSearch (full-text, vector search)                    â”‚   â”‚
â”‚  â”‚  â”œâ”€ RedisJSON (native JSON documents)                        â”‚   â”‚
â”‚  â”‚  â”œâ”€ RedisTimeSeries (time-series data)                       â”‚   â”‚
â”‚  â”‚  â”œâ”€ RedisBloom (probabilistic filters)                       â”‚   â”‚
â”‚  â”‚  â””â”€ RedisGraph (deprecated, sunset 2024)                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒ Active-Active Geo-Distribution

### Architecture Active-Active avec CRDTs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Active-Active Conflict-Free Replicated Data Types       â”‚
â”‚                                                                â”‚
â”‚  Scenario: E-commerce global avec 3 rÃ©gions                    â”‚
â”‚                                                                â”‚
â”‚  Region US-East (t=0)          Region EU-West (t=0)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Database        â”‚          â”‚  Database        â”‚            â”‚
â”‚  â”‚                  â”‚          â”‚                  â”‚            â”‚
â”‚  â”‚  WRITE:          â”‚          â”‚  WRITE:          â”‚            â”‚
â”‚  â”‚  SET user:1 {    â”‚          â”‚  SET user:1 {    â”‚            â”‚
â”‚  â”‚    name: "John"  â”‚          â”‚    email: "j@a"  â”‚            â”‚
â”‚  â”‚  }               â”‚          â”‚  }               â”‚            â”‚
â”‚  â”‚  timestamp: 100  â”‚          â”‚  timestamp: 101  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚           â”‚                             â”‚                      â”‚
â”‚           â”‚  Bi-directional sync        â”‚                      â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                          â”‚                                     â”‚
â”‚                          â–¼                                     â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚           â”‚  CRDT Resolution         â”‚                         â”‚
â”‚           â”‚  (automatic merging)     â”‚                         â”‚
â”‚           â”‚                          â”‚                         â”‚
â”‚           â”‚  Result: user:1 {        â”‚                         â”‚
â”‚           â”‚    name: "John"          â”‚                         â”‚
â”‚           â”‚    email: "j@a"          â”‚                         â”‚
â”‚           â”‚  }                       â”‚                         â”‚
â”‚           â”‚                          â”‚                         â”‚
â”‚           â”‚  â€¢ Field-level merge     â”‚                         â”‚
â”‚           â”‚  â€¢ LWW per field         â”‚                         â”‚
â”‚           â”‚  â€¢ No data loss          â”‚                         â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                                â”‚
â”‚  Supported CRDT Types:                                         â”‚
â”‚                                                                â”‚
â”‚  Counter (auto-increment globally)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  US-EAST: INCR views:product:123  (local: +1)           â”‚   â”‚
â”‚  â”‚  EU-WEST: INCR views:product:123  (local: +1)           â”‚   â”‚
â”‚  â”‚  Result:  views:product:123 = 2   (addition)            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                â”‚
â”‚  String (Last-Write-Wins)                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  US-EAST: SET status "active" (t=100)                   â”‚   â”‚
â”‚  â”‚  EU-WEST: SET status "inactive" (t=101)                 â”‚   â”‚
â”‚  â”‚  Result:  status = "inactive" (timestamp wins)          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                â”‚
â”‚  Set (Union)                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  US-EAST: SADD tags:product "sale" "new"                â”‚   â”‚
â”‚  â”‚  EU-WEST: SADD tags:product "featured" "new"            â”‚   â”‚
â”‚  â”‚  Result:  tags:product = {"sale", "new", "featured"}    â”‚   â”‚
â”‚  â”‚           (union of all members)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                â”‚
â”‚  Sorted Set (Max score wins)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  US-EAST: ZADD leaderboard 100 "player1"                â”‚   â”‚
â”‚  â”‚  EU-WEST: ZADD leaderboard 150 "player1"                â”‚   â”‚
â”‚  â”‚  Result:  leaderboard: player1 = 150 (max score)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                â”‚
â”‚  Hash (Field-level LWW)                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  US-EAST: HSET user:1 name "John" (t=100)               â”‚   â”‚
â”‚  â”‚  EU-WEST: HSET user:1 email "j@a.com" (t=101)           â”‚   â”‚
â”‚  â”‚  Result:  user:1 = {name: "John", email: "j@a.com"}     â”‚   â”‚
â”‚  â”‚           (per-field resolution)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration Active-Active

```yaml
Active-Active Configuration:
â”œâ”€â”€ Minimum regions: 2
â”œâ”€â”€ Maximum regions: Unlimited (practical limit ~10)
â”œâ”€â”€ Replication: Bi-directional (mesh topology)
â”œâ”€â”€ Conflict resolution: Automatic (CRDT-based)
â”œâ”€â”€ Latency: Region-local reads/writes (<1ms)
â”œâ”€â”€ Consistency: Eventually consistent (seconds)
â”œâ”€â”€ Use cases:
â”‚   â”œâ”€â”€ Global e-commerce
â”‚   â”œâ”€â”€ Multi-region gaming
â”‚   â”œâ”€â”€ Financial services (trading)
â”‚   â”œâ”€â”€ Content delivery
â”‚   â””â”€â”€ IoT data collection

Topology Examples:

2 Regions (simple):
US-EAST â†â†’ EU-WEST

3 Regions (triangle):
    US-EAST
      â†™  â†˜
EU-WEST â†â†’ ASIA-PACIFIC

5 Regions (full mesh):
US-EAST â†â†’ US-WEST
   â†•         â†•
EU-WEST â†â†’ ASIA-PACIFIC â†â†’ SOUTH-AMERICA
```

---

## ğŸ§° Redis Stack Modules

### Vue d'ensemble complÃ¨te

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Redis Stack Modules                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. RediSearch (Search & Vector)
   â”œâ”€â”€ Full-text search (inverted index)
   â”œâ”€â”€ Vector search (HNSW algorithm)
   â”œâ”€â”€ Aggregation pipeline (like MongoDB)
   â”œâ”€â”€ Auto-complete
   â”œâ”€â”€ Fuzzy matching
   â””â”€â”€ Use cases:
       â”œâ”€â”€ E-commerce product search
       â”œâ”€â”€ RAG (Retrieval Augmented Generation)
       â”œâ”€â”€ Semantic search with embeddings
       â””â”€â”€ Log analysis

2. RedisJSON
   â”œâ”€â”€ Native JSON document storage
   â”œâ”€â”€ JSONPath queries
   â”œâ”€â”€ Atomic operations on nested fields
   â”œâ”€â”€ Indexing with RediSearch
   â””â”€â”€ Use cases:
       â”œâ”€â”€ User profiles
       â”œâ”€â”€ Configuration storage
       â”œâ”€â”€ API response caching
       â””â”€â”€ Event streaming

3. RedisTimeSeries
   â”œâ”€â”€ Time-series data optimized storage
   â”œâ”€â”€ Downsampling & aggregation
   â”œâ”€â”€ Compaction rules
   â”œâ”€â”€ Real-time analytics
   â””â”€â”€ Use cases:
       â”œâ”€â”€ IoT sensor data
       â”œâ”€â”€ Financial market data
       â”œâ”€â”€ Application metrics
       â””â”€â”€ Infrastructure monitoring

4. RedisBloom
   â”œâ”€â”€ Bloom Filter (membership test)
   â”œâ”€â”€ Cuckoo Filter (deletions supported)
   â”œâ”€â”€ Count-Min Sketch (frequency estimation)
   â”œâ”€â”€ Top-K (most frequent items)
   â””â”€â”€ Use cases:
       â”œâ”€â”€ Spam detection
       â”œâ”€â”€ Duplicate detection
       â”œâ”€â”€ Rate limiting
       â””â”€â”€ Cache admission policies

5. RedisGraph (DEPRECATED - sunset 2024)
   â”œâ”€â”€ Graph database
   â”œâ”€â”€ Cypher query language
   â””â”€â”€ Migration path: Neo4j, Amazon Neptune
```

### Exemple d'usage : RediSearch + RedisJSON

```python
# Example: E-commerce product catalog with RediSearch + RedisJSON
import redis
from redis.commands.search.field import TextField, NumericField, TagField
from redis.commands.search.indexDefinition import IndexDefinition, IndexType
from redis.commands.search.query import Query

# Connect to Redis Enterprise Cloud
r = redis.Redis(
    host='redis-12345.c123.us-east-1-1.ec2.cloud.redislabs.com',
    port=12345,
    password='your-password',
    ssl=True,
    decode_responses=True
)

# Create index on JSON documents
index_name = "idx:products"
schema = (
    TextField("$.name", as_name="name"),
    TextField("$.description", as_name="description"),
    NumericField("$.price", as_name="price"),
    TagField("$.category", as_name="category"),
    TagField("$.tags", as_name="tags"),
    NumericField("$.stock", as_name="stock")
)

try:
    r.ft(index_name).create_index(
        schema,
        definition=IndexDefinition(
            prefix=["product:"],
            index_type=IndexType.JSON
        )
    )
except Exception as e:
    print(f"Index already exists: {e}")

# Insert JSON documents
products = [
    {
        "id": "product:1",
        "data": {
            "name": "iPhone 15 Pro",
            "description": "Latest Apple smartphone with A17 Pro chip",
            "price": 999,
            "category": "electronics",
            "tags": ["smartphone", "apple", "5g"],
            "stock": 50
        }
    },
    {
        "id": "product:2",
        "data": {
            "name": "MacBook Pro 16",
            "description": "Powerful laptop for professionals",
            "price": 2499,
            "category": "electronics",
            "tags": ["laptop", "apple", "m3"],
            "stock": 20
        }
    },
    {
        "id": "product:3",
        "data": {
            "name": "AirPods Pro 2",
            "description": "Wireless earbuds with active noise cancellation",
            "price": 249,
            "category": "electronics",
            "tags": ["audio", "apple", "wireless"],
            "stock": 100
        }
    }
]

# Insert documents
for product in products:
    r.json().set(product["id"], "$", product["data"])

# Search examples
print("=== Search Examples ===\n")

# 1. Full-text search
print("1. Search 'apple':")
results = r.ft(index_name).search(Query("apple"))
for doc in results.docs:
    print(f"  - {doc.name}: ${doc.price}")

# 2. Filter by price range
print("\n2. Products between $200-$1000:")
results = r.ft(index_name).search(
    Query("*").add_filter(NumericField("price", from_value=200, to_value=1000))
)
for doc in results.docs:
    print(f"  - {doc.name}: ${doc.price}")

# 3. Category + tag filter
print("\n3. Electronics tagged 'laptop':")
results = r.ft(index_name).search(
    Query("@category:{electronics} @tags:{laptop}")
)
for doc in results.docs:
    print(f"  - {doc.name}")

# 4. Aggregation (average price by category)
print("\n4. Average price by category:")
from redis.commands.search.aggregation import AggregateRequest, Reducer
request = AggregateRequest("*").group_by(
    "@category",
    Reducer("avg", ["@price"], as_name="avg_price")
)
results = r.ft(index_name).aggregate(request)
for row in results.rows:
    print(f"  - {row[1]}: ${float(row[3]):.2f}")

# 5. Auto-complete (prefix search)
print("\n5. Auto-complete 'iph':")
results = r.ft(index_name).search(Query("iph*"))
for doc in results.docs:
    print(f"  - {doc.name}")
```

### Exemple d'usage : RedisTimeSeries

```python
# Example: IoT sensor data with RedisTimeSeries
import redis
import time
from redis.commands.timeseries.commands import TimeSeriesCommands

r = redis.Redis(
    host='redis-12345.c123.us-east-1-1.ec2.cloud.redislabs.com',
    port=12345,
    password='your-password',
    ssl=True,
    decode_responses=True
)

# Create time-series for temperature sensor
sensor_key = "sensor:temperature:room1"

try:
    r.ts().create(
        sensor_key,
        retention_msecs=86400000,  # 1 day retention
        labels={
            "sensor_type": "temperature",
            "room": "room1",
            "unit": "celsius"
        }
    )

    # Create compaction rule (1-hour averages)
    r.ts().createrule(
        source_key=sensor_key,
        dest_key=f"{sensor_key}:1h",
        aggregation_type="avg",
        bucket_size_msec=3600000  # 1 hour
    )
except Exception as e:
    print(f"Time series already exists: {e}")

# Add data points
print("Adding temperature readings...")
current_time = int(time.time() * 1000)
for i in range(100):
    temperature = 20 + (i % 10)  # Simulate readings
    r.ts().add(sensor_key, current_time + i * 60000, temperature)  # Every minute

# Query data
print("\n=== Query Examples ===")

# 1. Get latest value
latest = r.ts().get(sensor_key)
print(f"Latest temperature: {latest[1]}Â°C at {latest[0]}")

# 2. Range query (last hour)
one_hour_ago = current_time - 3600000
results = r.ts().range(sensor_key, one_hour_ago, current_time)
print(f"\nReadings in last hour: {len(results)} data points")

# 3. Aggregation (average per 10 minutes)
aggregated = r.ts().range(
    sensor_key,
    one_hour_ago,
    current_time,
    aggregation_type="avg",
    bucket_size_msec=600000  # 10 minutes
)
print("\nAverage temperature per 10 minutes:")
for timestamp, value in aggregated:
    print(f"  {timestamp}: {value:.2f}Â°C")

# 4. Multi-get (query multiple sensors)
results = r.ts().mget(filters=["sensor_type=temperature"])
print("\nAll temperature sensors:")
for key, labels, value in results:
    print(f"  {labels['room']}: {value[1]}Â°C")
```

---

## ğŸ”§ Configuration avec Terraform

### Module Terraform complet

```hcl
# Redis Enterprise Cloud - Terraform Configuration
# Provider: redislabs/rediscloud ~> 1.3

terraform {
  required_version = ">= 1.5"

  required_providers {
    rediscloud = {
      source  = "RedisLabs/rediscloud"
      version = "~> 1.3"
    }
    random = {
      source  = "hashicorp/random"
      version = "~> 3.5"
    }
  }
}

# Provider configuration
provider "rediscloud" {
  # Set via environment variables:
  # export REDISCLOUD_ACCESS_KEY="your-access-key"
  # export REDISCLOUD_SECRET_KEY="your-secret-key"
}

# Variables
variable "environment" {
  type        = string
  description = "Environment name"
  default     = "production"
}

variable "subscription_name" {
  type        = string
  description = "Redis Cloud subscription name"
  default     = "production-subscription"
}

variable "cloud_provider" {
  type        = string
  description = "Cloud provider: AWS, GCP, or Azure"
  default     = "AWS"

  validation {
    condition     = contains(["AWS", "GCP", "Azure"], var.cloud_provider)
    error_message = "Cloud provider must be AWS, GCP, or Azure"
  }
}

variable "primary_region" {
  type        = string
  description = "Primary region for deployment"
  default     = "us-east-1"
}

variable "enable_active_active" {
  type        = bool
  description = "Enable Active-Active geo-distribution"
  default     = false
}

variable "secondary_regions" {
  type        = list(string)
  description = "Secondary regions for Active-Active"
  default     = []
}

variable "database_memory_gb" {
  type        = number
  description = "Database memory in GB"
  default     = 10
}

variable "throughput_ops_sec" {
  type        = number
  description = "Throughput in operations per second"
  default     = 25000
}

variable "enable_modules" {
  type = object({
    search      = bool
    json        = bool
    timeseries  = bool
    bloom       = bool
  })
  description = "Enable Redis Stack modules"
  default = {
    search     = true
    json       = true
    timeseries = true
    bloom      = true
  }
}

variable "enable_auto_tiering" {
  type        = bool
  description = "Enable RAM+Flash auto-tiering"
  default     = false
}

variable "tags" {
  type        = map(string)
  description = "Tags to apply"
  default = {
    ManagedBy = "Terraform"
  }
}

# Local variables
locals {
  common_tags = merge(
    var.tags,
    {
      Environment = var.environment
      Terraform   = "true"
    }
  )

  # Module list
  enabled_modules = [
    for module_name, enabled in {
      "RedisJSON"       = var.enable_modules.json
      "RediSearch"      = var.enable_modules.search
      "RedisTimeSeries" = var.enable_modules.timeseries
      "RedisBloom"      = var.enable_modules.bloom
    } : module_name if enabled
  ]
}

# Random password for database
resource "random_password" "db_password" {
  length  = 32
  special = false
}

# --- Single Region Deployment ---
resource "rediscloud_subscription" "main" {
  count = var.enable_active_active ? 0 : 1

  name           = var.subscription_name
  payment_method = "credit-card"

  cloud_provider {
    provider = var.cloud_provider

    region {
      region                       = var.primary_region
      multiple_availability_zones  = true
      preferred_availability_zones = []  # Let Redis choose
      networking_deployment_cidr   = "10.0.0.0/24"
    }
  }

  # Memory storage type
  memory_storage = var.enable_auto_tiering ? "ram-and-flash" : "ram"

  # Throughput measurement
  throughput_measurement_by    = "operations-per-second"
  throughput_measurement_value = var.throughput_ops_sec

  # Persistent storage
  persistent_storage_encryption = true
}

# Database for single region
resource "rediscloud_subscription_database" "main" {
  count = var.enable_active_active ? 0 : 1

  subscription_id              = rediscloud_subscription.main[0].id
  name                         = "${var.environment}-database"
  protocol                     = "redis"
  memory_limit_in_gb          = var.database_memory_gb
  data_persistence            = "aof-every-1-second"
  replication                 = true
  throughput_measurement_by   = "operations-per-second"
  throughput_measurement_value = var.throughput_ops_sec

  # Redis modules
  dynamic "modules" {
    for_each = local.enabled_modules
    content {
      name = modules.value
    }
  }

  # High availability
  replication = true

  # Password
  password = random_password.db_password.result

  # Alerts
  alert {
    name  = "dataset-size"
    value = var.database_memory_gb * 0.8  # Alert at 80%
  }

  alert {
    name  = "throughput-higher-than"
    value = var.throughput_ops_sec * 0.8
  }

  alert {
    name  = "latency"
    value = 5  # Alert if latency > 5ms
  }

  # Client SSL certificate (optional)
  # client_ssl_certificate = file("${path.module}/certs/client.crt")
}

# --- Active-Active Deployment ---
resource "rediscloud_active_active_subscription" "global" {
  count = var.enable_active_active ? 1 : 0

  name           = "${var.subscription_name}-active-active"
  payment_method = "credit-card"

  # Primary region
  cloud_provider {
    provider = var.cloud_provider

    region {
      region                       = var.primary_region
      multiple_availability_zones  = true
      networking_deployment_cidr   = "10.0.0.0/24"
    }
  }

  # Secondary regions
  dynamic "cloud_provider" {
    for_each = var.secondary_regions
    content {
      provider = var.cloud_provider

      region {
        region                       = cloud_provider.value
        multiple_availability_zones  = true
        networking_deployment_cidr   = "10.${cloud_provider.key + 1}.0.0/24"
      }
    }
  }

  # Creation plan
  creation_plan {
    memory_limit_in_gb          = var.database_memory_gb
    quantity                    = 1
    replication                 = true
    throughput_measurement_by   = "operations-per-second"
    throughput_measurement_value = var.throughput_ops_sec

    # Redis modules
    dynamic "modules" {
      for_each = local.enabled_modules
      content {
        name = modules.value
      }
    }
  }
}

# Active-Active database
resource "rediscloud_active_active_subscription_database" "global" {
  count = var.enable_active_active ? 1 : 0

  subscription_id = rediscloud_active_active_subscription.global[0].id
  name            = "${var.environment}-global-database"
  memory_limit_in_gb = var.database_memory_gb

  # Global configuration
  global_data_persistence      = "aof-every-1-second"
  global_password             = random_password.db_password.result
  global_source_ips           = ["0.0.0.0/0"]  # Restrict in production

  global_alert {
    name  = "dataset-size"
    value = var.database_memory_gb * 0.8
  }

  # Region-specific overrides (optional)
  dynamic "override_region" {
    for_each = concat([var.primary_region], var.secondary_regions)
    content {
      name                     = override_region.value
      override_global_password = false
    }
  }
}

# --- Outputs ---
output "subscription_id" {
  description = "Subscription ID"
  value       = var.enable_active_active ? rediscloud_active_active_subscription.global[0].id : rediscloud_subscription.main[0].id
}

output "database_id" {
  description = "Database ID"
  value       = var.enable_active_active ? rediscloud_active_active_subscription_database.global[0].id : rediscloud_subscription_database.main[0].id
}

output "database_endpoint" {
  description = "Database endpoint"
  value       = var.enable_active_active ? null : rediscloud_subscription_database.main[0].public_endpoint
}

output "database_port" {
  description = "Database port"
  value       = var.enable_active_active ? null : rediscloud_subscription_database.main[0].public_port
}

output "database_password" {
  description = "Database password"
  value       = random_password.db_password.result
  sensitive   = true
}

output "connection_string" {
  description = "Redis connection string"
  value = var.enable_active_active ? null : (
    "rediss://:${random_password.db_password.result}@${rediscloud_subscription_database.main[0].public_endpoint}:${rediscloud_subscription_database.main[0].public_port}"
  )
  sensitive = true
}

output "enabled_modules" {
  description = "List of enabled Redis Stack modules"
  value       = local.enabled_modules
}
```

### Variables file (terraform.tfvars)

```hcl
# Production configuration - Single region
environment          = "production"
subscription_name    = "prod-redis-subscription"
cloud_provider       = "AWS"
primary_region       = "us-east-1"
enable_active_active = false

database_memory_gb   = 50
throughput_ops_sec   = 50000

enable_modules = {
  search     = true
  json       = true
  timeseries = true
  bloom      = true
}

enable_auto_tiering = false

tags = {
  Team        = "platform"
  CostCenter  = "engineering"
  Environment = "production"
}
```

```hcl
# Active-Active configuration (multi-region)
environment          = "production"
subscription_name    = "prod-redis-global"
cloud_provider       = "AWS"
primary_region       = "us-east-1"
enable_active_active = true
secondary_regions    = ["eu-west-1", "ap-southeast-1"]

database_memory_gb   = 50
throughput_ops_sec   = 100000

enable_modules = {
  search     = true
  json       = true
  timeseries = false
  bloom      = false
}

enable_auto_tiering = true  # Use RAM+Flash tiering

tags = {
  Team        = "platform"
  CostCenter  = "engineering"
  Environment = "production"
  Geo         = "global"
}
```

---

## ğŸ’° Pricing et ROI

### ModÃ¨le de pricing

```yaml
Redis Enterprise Cloud Pricing Model:

Components:
â”œâ”€â”€ RAM: $0.119/GB-hour (~$87/GB-month)
â”œâ”€â”€ RAM+Flash: $0.048/GB-hour RAM + $0.012/GB-hour Flash
â”œâ”€â”€ Throughput: $0.016/1000 ops/sec-hour
â”œâ”€â”€ Active-Active: +100% surcharge on RAM
â””â”€â”€ Modules: Included (no extra cost)

Examples (Single Region):

1. Standard cache (50GB RAM, 10K ops/sec)
â”œâ”€â”€ RAM: 50 Ã— $87 = $4,350/month
â”œâ”€â”€ Throughput: 10 Ã— $0.016 Ã— 730 = $117/month
â””â”€â”€ Total: ~$4,467/month

2. Large cache (200GB RAM, 25K ops/sec)
â”œâ”€â”€ RAM: 200 Ã— $87 = $17,400/month
â”œâ”€â”€ Throughput: 25 Ã— $0.016 Ã— 730 = $292/month
â””â”€â”€ Total: ~$17,692/month

3. With RAM+Flash tiering (500GB total, 100GB RAM + 400GB Flash)
â”œâ”€â”€ RAM: 100 Ã— $35 = $3,500/month
â”œâ”€â”€ Flash: 400 Ã— $9 = $3,600/month
â”œâ”€â”€ Throughput: 25K ops/sec = $292/month
â””â”€â”€ Total: ~$7,392/month
   (vs $43,500 for 500GB full RAM - 83% savings!)

Active-Active (Multi-Region):

4. Global e-commerce (3 regions, 50GB each, 25K ops/sec)
â”œâ”€â”€ RAM: 50 Ã— 3 regions Ã— $87 Ã— 2 (Active-Active) = $26,100/month
â”œâ”€â”€ Throughput: 25 Ã— $0.016 Ã— 730 Ã— 3 = $876/month
â””â”€â”€ Total: ~$26,976/month

5. Mission-critical fintech (5 regions, 100GB each, 50K ops/sec)
â”œâ”€â”€ RAM: 100 Ã— 5 Ã— $87 Ã— 2 = $87,000/month
â”œâ”€â”€ Throughput: 50 Ã— $0.016 Ã— 730 Ã— 5 = $2,920/month
â””â”€â”€ Total: ~$89,920/month

Volume Discounts:
â”œâ”€â”€ >500 GB: Negotiated pricing
â”œâ”€â”€ Committed use: 15-30% discount
â””â”€â”€ Enterprise contracts: Custom pricing

Hidden Costs to Consider:
â”œâ”€â”€ Data transfer (cross-region): $0.02-0.12/GB
â”œâ”€â”€ Bandwidth (internet egress): $0.09/GB
â””â”€â”€ Support: Premium support included (24/7)
```

### Calculateur de TCO

```python
# Redis Enterprise Cloud TCO Calculator

class RedisEnterpriseCloudPricing:
    """Calculate Redis Enterprise Cloud costs"""

    # Pricing (2024, USD)
    RAM_PRICE_GB_MONTH = 87  # USD
    RAM_FLASH_RAM_GB_MONTH = 35  # USD (for tiering)
    RAM_FLASH_FLASH_GB_MONTH = 9  # USD (for tiering)
    THROUGHPUT_1K_OPS_MONTH = 11.68  # USD (730h Ã— $0.016)
    ACTIVE_ACTIVE_MULTIPLIER = 2.0

    @classmethod
    def calculate_monthly_cost(
        cls,
        memory_gb: int,
        throughput_ops_sec: int,
        regions: int = 1,
        active_active: bool = False,
        use_tiering: bool = False,
        flash_gb: int = 0
    ) -> dict:
        """
        Calculate monthly cost

        Args:
            memory_gb: RAM in GB
            throughput_ops_sec: Operations per second
            regions: Number of regions
            active_active: Enable Active-Active
            use_tiering: Use RAM+Flash tiering
            flash_gb: Flash storage in GB (if tiering)
        """

        # Memory cost
        if use_tiering:
            ram_cost = memory_gb * cls.RAM_FLASH_RAM_GB_MONTH
            flash_cost = flash_gb * cls.RAM_FLASH_FLASH_GB_MONTH
            total_memory_cost = ram_cost + flash_cost
        else:
            ram_cost = memory_gb * cls.RAM_PRICE_GB_MONTH
            flash_cost = 0
            total_memory_cost = ram_cost

        # Apply Active-Active multiplier
        if active_active:
            total_memory_cost *= cls.ACTIVE_ACTIVE_MULTIPLIER

        # Multiply by regions
        total_memory_cost *= regions

        # Throughput cost
        throughput_units = throughput_ops_sec / 1000
        throughput_cost = throughput_units * cls.THROUGHPUT_1K_OPS_MONTH * regions

        # Total compute
        total_compute = total_memory_cost + throughput_cost

        # Additional costs (estimates)
        support_cost = 0  # Included
        data_transfer = 200 * regions  # Estimate $200/region

        total_monthly = total_compute + data_transfer

        return {
            'ram_gb': memory_gb,
            'flash_gb': flash_gb if use_tiering else 0,
            'regions': regions,
            'active_active': active_active,
            'ram_cost_monthly': round(ram_cost * regions, 2),
            'flash_cost_monthly': round(flash_cost * regions, 2),
            'throughput_cost_monthly': round(throughput_cost, 2),
            'data_transfer_monthly': round(data_transfer, 2),
            'total_monthly': round(total_monthly, 2),
            'total_annual': round(total_monthly * 12, 2),
            'cost_per_gb': round(total_monthly / (memory_gb * regions), 2)
        }

# Examples
print("=== Scenario 1: Standard cache (50GB, single region) ===")
cost1 = RedisEnterpriseCloudPricing.calculate_monthly_cost(
    memory_gb=50,
    throughput_ops_sec=10000,
    regions=1,
    active_active=False,
    use_tiering=False
)
print(f"Monthly: ${cost1['total_monthly']:,}")
print(f"Annual: ${cost1['total_annual']:,}")

print("\n=== Scenario 2: Active-Active global (3 regions, 50GB each) ===")
cost2 = RedisEnterpriseCloudPricing.calculate_monthly_cost(
    memory_gb=50,
    throughput_ops_sec=25000,
    regions=3,
    active_active=True,
    use_tiering=False
)
print(f"Monthly: ${cost2['total_monthly']:,}")
print(f"Annual: ${cost2['total_annual']:,}")
print(f"Cost per GB: ${cost2['cost_per_gb']}/GB")

print("\n=== Scenario 3: Large with tiering (100GB RAM + 400GB Flash) ===")
cost3 = RedisEnterpriseCloudPricing.calculate_monthly_cost(
    memory_gb=100,
    throughput_ops_sec=25000,
    regions=1,
    active_active=False,
    use_tiering=True,
    flash_gb=400
)
cost3_no_tiering = RedisEnterpriseCloudPricing.calculate_monthly_cost(
    memory_gb=500,
    throughput_ops_sec=25000,
    regions=1,
    active_active=False,
    use_tiering=False
)
print(f"With tiering: ${cost3['total_monthly']:,}/month")
print(f"Without tiering (500GB RAM): ${cost3_no_tiering['total_monthly']:,}/month")
print(f"Savings: ${cost3_no_tiering['total_monthly'] - cost3['total_monthly']:,}/month ({((cost3_no_tiering['total_monthly'] - cost3['total_monthly']) / cost3_no_tiering['total_monthly'] * 100):.0f}%)")

print("\n=== Comparison vs AWS ElastiCache (50GB, RI 3 years) ===")
elasticache_ri_monthly = 2381  # From previous section
redis_enterprise_monthly = cost1['total_monthly']
print(f"AWS ElastiCache (RI 3y): ${elasticache_ri_monthly}/month")
print(f"Redis Enterprise Cloud: ${redis_enterprise_monthly}/month")
print(f"Premium: ${redis_enterprise_monthly - elasticache_ri_monthly}/month")
print(f"Premium %: {((redis_enterprise_monthly / elasticache_ri_monthly - 1) * 100):.0f}%")
print("\nRedis Enterprise adds:")
print("  âœ… Active-Active capability")
print("  âœ… Redis Stack modules (Search, JSON, TimeSeries, Bloom)")
print("  âœ… Multi-cloud support")
print("  âœ… Auto-scaling")
print("  âœ… 99.999% SLA (vs 99.9%)")
```

Output:
```
=== Scenario 1: Standard cache (50GB, single region) ===
Monthly: $4,667
Annual: $56,004

=== Scenario 2: Active-Active global (3 regions, 50GB each) ===
Monthly: $27,176
Annual: $326,112
Cost per GB: $181.17/GB

=== Scenario 3: Large with tiering (100GB RAM + 400GB Flash) ===
With tiering: $7,592/month
Without tiering (500GB RAM): $43,792/month
Savings: $36,200/month (83%)

=== Comparison vs AWS ElastiCache (50GB, RI 3 years) ===
AWS ElastiCache (RI 3y): $2,381/month
Redis Enterprise Cloud: $4,667/month
Premium: $2,286/month
Premium %: 96%

Redis Enterprise adds:
  âœ… Active-Active capability
  âœ… Redis Stack modules (Search, JSON, TimeSeries, Bloom)
  âœ… Multi-cloud support
  âœ… Auto-scaling
  âœ… 99.999% SLA (vs 99.9%)
```

### Analyse ROI

```python
# ROI Analysis: When does Redis Enterprise make sense?

def calculate_roi(
    monthly_revenue: float,
    downtime_cost_per_hour: float,
    data_loss_cost: float,
    elasticache_cost_monthly: float = 2381,
    redis_enterprise_cost_monthly: float = 4667,
    elasticache_sla_uptime: float = 0.999,
    redis_enterprise_sla_uptime: float = 0.99999
):
    """
    Calculate ROI of Redis Enterprise vs ElastiCache
    """

    monthly_premium = redis_enterprise_cost_monthly - elasticache_cost_monthly
    annual_premium = monthly_premium * 12

    # Expected downtime per year
    elasticache_downtime_hours = 8760 * (1 - elasticache_sla_uptime)  # ~8.76 hours
    redis_ent_downtime_hours = 8760 * (1 - redis_enterprise_sla_uptime)  # ~0.09 hours

    downtime_difference = elasticache_downtime_hours - redis_ent_downtime_hours

    # Cost of additional downtime with ElastiCache
    downtime_cost_diff = downtime_difference * downtime_cost_per_hour

    # ROI calculation
    net_benefit = downtime_cost_diff - annual_premium

    print(f"Monthly Revenue: ${monthly_revenue:,}")
    print(f"Downtime cost: ${downtime_cost_per_hour:,}/hour")
    print(f"\nRedis Enterprise premium: ${monthly_premium:,}/month (${annual_premium:,}/year)")
    print(f"\nExpected downtime:")
    print(f"  ElastiCache (99.9%): {elasticache_downtime_hours:.2f} hours/year")
    print(f"  Redis Enterprise (99.999%): {redis_ent_downtime_hours:.2f} hours/year")
    print(f"  Difference: {downtime_difference:.2f} hours/year")
    print(f"\nCost of additional downtime (ElastiCache): ${downtime_cost_diff:,}/year")
    print(f"\nNet benefit (Redis Enterprise): ${net_benefit:,}/year")

    if net_benefit > 0:
        roi_percent = (net_benefit / annual_premium) * 100
        print(f"\nâœ… Redis Enterprise is justified")
        print(f"   ROI: {roi_percent:.0f}%")
        print(f"   Payback period: {12 / (net_benefit / annual_premium + 1):.1f} months")
    else:
        print(f"\nâŒ Redis Enterprise not justified by downtime alone")
        print(f"   Loss: ${-net_benefit:,}/year")
        print(f"\n   Consider other factors:")
        print(f"   â€¢ Active-Active (multi-region performance)")
        print(f"   â€¢ Redis Stack modules (new capabilities)")
        print(f"   â€¢ Multi-cloud flexibility")

    return net_benefit

print("=== Scenario 1: E-commerce ($10M/month revenue) ===")
calculate_roi(
    monthly_revenue=10_000_000,
    downtime_cost_per_hour=50_000,  # $50K/hour downtime cost
    data_loss_cost=100_000
)

print("\n" + "="*60)
print("=== Scenario 2: SaaS Platform ($1M/month revenue) ===")
calculate_roi(
    monthly_revenue=1_000_000,
    downtime_cost_per_hour=5_000,  # $5K/hour
    data_loss_cost=25_000
)

print("\n" + "="*60)
print("=== Scenario 3: Fintech ($50M/month revenue) ===")
calculate_roi(
    monthly_revenue=50_000_000,
    downtime_cost_per_hour=500_000,  # $500K/hour
    data_loss_cost=5_000_000
)
```

---

## ğŸ“Š Comparaison finale avec toutes les solutions

### Tableau rÃ©capitulatif complet

| CritÃ¨re | Redis Enterprise | AWS ElastiCache | AWS MemoryDB | Azure Premium | GCP Memorystore |
|---------|------------------|-----------------|--------------|---------------|-----------------|
| **Architecture** |
| Max capacity | Unlimited | 150 TB | 200 TB | 1.2 TB | 300 GB |
| Clustering | âœ… Advanced | âœ… (500 shards) | âœ… (500 shards) | âœ… (10 shards) | âŒ |
| Active-Active | âœ… **Unique** | âŒ | âŒ | âŒ (preview) | âŒ |
| **Modules & Features** |
| Redis Stack | âœ… **All modules** | âŒ | âŒ | âŒ (Ent tier only) | âŒ |
| RediSearch | âœ… | âŒ | âŒ | âŒ | âŒ |
| RedisJSON | âœ… | âŒ | âŒ | âŒ | âŒ |
| RedisTimeSeries | âœ… | âŒ | âŒ | âŒ | âŒ |
| RedisBloom | âœ… | âŒ | âŒ | âŒ | âŒ |
| **Durability** |
| Persistence | RDB+AOF | RDB/AOF | WAL (durable) | RDB+AOF | RDB |
| RPO | Seconds | 1s-15min | 0 (zero loss) | 1s-15min | Hours |
| RTO | <1 min | 2-3 min | <1 min | 2-3 min | 1-2 min |
| **Availability** |
| SLA | **99.999%** | 99.9% | 99.99% | 99.9% | 99.9% |
| Multi-region | âœ… Active-Active | âœ… Passive | âŒ | âœ… Passive | âŒ |
| Auto-scaling | âœ… | âŒ | âŒ | âŒ | âŒ |
| **Cloud Support** |
| Multi-cloud | âœ… (AWS+Azure+GCP) | AWS only | AWS only | Azure only | GCP only |
| Portability | âœ… High | âŒ Low | âŒ Low | âŒ Low | âŒ Low |
| **Pricing (50GB, on-demand)** |
| Monthly cost | ~$4,667 | ~$5,952 | ~$10,597 | ~â‚¬1,000 | ~â‚¬3,175 |
| Reserved/RI | Custom | $2,381 (RI 3y) | $4,239 (RI 3y) | ~â‚¬450 (RI 3y) | N/A |
| Cost premium | Baseline | -49% (RI) | -9% (RI) | -90% (RI) | -32% |
| **Support** |
| Support level | 24/7 Premium | Standard | Standard | Standard | Standard |
| SLA guarantee | âœ… | âœ… | âœ… | âœ… | âœ… |
| Direct access to Redis team | âœ… | âŒ | âŒ | âŒ | âŒ |

### Matrice de dÃ©cision finale

```yaml
Utilisez Redis Enterprise Cloud si:
âœ… Active-Active multi-rÃ©gion requis
âœ… Redis Stack modules nÃ©cessaires (Search, JSON, etc.)
âœ… SLA 99.999% mandatory
âœ… Multi-cloud strategy ou migration prÃ©vue
âœ… Budget permet premium pricing (2-3Ã— cloud native)
âœ… Besoin de support direct de Redis team
âœ… Compliance requiert contrÃ´le total

Utilisez AWS ElastiCache si:
âœ… Cache standard (pas primary DB)
âœ… 100% AWS infrastructure
âœ… Budget contraint (avec RI)
âœ… Perte de donnÃ©es acceptable
âœ… SLA 99.9% suffisant
âœ… Pas besoin de Redis Stack

Utilisez AWS MemoryDB si:
âœ… Redis comme primary database
âœ… Zero data loss critique
âœ… 100% AWS infrastructure
âœ… Budget permet (~78% plus cher qu'ElastiCache)
âœ… SLA 99.99% requis

Utilisez Azure Cache Premium si:
âœ… 100% Azure infrastructure
âœ… VNet injection required
âœ… Geo-replication passive suffisante
âœ… Budget moyen (RI 3y Ã©conomique)

Utilisez GCP Memorystore si:
âœ… 100% GCP infrastructure
âœ… SimplicitÃ© > fonctionnalitÃ©s
âœ… Dataset <300GB
âœ… IntÃ©gration GKE prioritaire
âœ… Pas besoin de clustering
```

---

## âœ… Conclusion

### Points clÃ©s Ã  retenir

1. **Redis Enterprise = Solution Premium**
   - CoÃ»t 2-3Ã— supÃ©rieur aux solutions cloud natives
   - JustifiÃ© par Active-Active + Redis Stack + Multi-cloud

2. **Active-Active est unique**
   - Seule solution avec true multi-region read/write
   - CRDTs pour rÃ©solution automatique des conflits
   - Latence locale (<1ms) partout

3. **Redis Stack = Game Changer**
   - RediSearch pour full-text et vector search
   - RedisJSON pour documents natifs
   - RedisTimeSeries pour IoT/monitoring
   - RedisBloom pour probabilistic data structures

4. **Multi-cloud = PortabilitÃ©**
   - DÃ©ploiement identique sur AWS/Azure/GCP
   - Migration simplifiÃ©e
   - Ã‰vite le vendor lock-in

5. **Auto-scaling & Auto-tiering**
   - Scaling automatique selon charge
   - RAM+Flash pour Ã©conomies (jusqu'Ã  80%)
   - Managed fully (zero ops)

### Recommandations finales

**Utilisez Redis Enterprise Cloud pour :**
```
1. E-commerce global avec Active-Active
   â””â”€> Latence <1ms dans chaque rÃ©gion
       3 rÃ©gions Ã— 50GB = ~$27K/mois

2. RAG/AI avec vector search (RediSearch)
   â””â”€> Semantic search sur embeddings
       100GB RAM = ~$8.7K/mois

3. IoT time-series Ã  grande Ã©chelle (RedisTimeSeries)
   â””â”€> Millions de sensors
       500GB avec tiering = ~$7.4K/mois

4. Document store JSON (RedisJSON + RediSearch)
   â””â”€> Alternative MongoDB/Elasticsearch
       50GB = ~$4.7K/mois
```

**N'utilisez PAS Redis Enterprise si :**
```
âŒ Budget trÃ¨s contraint (prÃ©fÃ©rer AWS RI)
âŒ Use case simple (cache standard)
âŒ Pas besoin de Redis Stack modules
âŒ Single-cloud avec solution native performante
âŒ Pas besoin d'Active-Active
```

### ROI simplifiÃ©

```
Si votre downtime coÃ»te >$10K/heure
ET/OU
Si vous avez besoin des modules Redis Stack
ET/OU
Si Active-Active multi-rÃ©gion est requis
ALORS
  â†’ Redis Enterprise est justifiÃ©

SINON
  â†’ Utilisez la solution native de votre cloud
     avec Reserved Instances
```

---

**ğŸ¯ Module 15 terminÃ© !** Nous avons couvert toutes les solutions Redis managÃ©es du marchÃ©. La prochaine Ã©tape serait d'explorer les dÃ©ploiements self-hosted sur Kubernetes avec les sections suivantes (Docker, StatefulSets, Operators, Helm).

â­ï¸ [Gestion des coÃ»ts : Tiering de mÃ©moire (RAM + Flash/SSD)](/15-redis-cloud-conteneurs/06-gestion-couts-tiering-memoire.md)
