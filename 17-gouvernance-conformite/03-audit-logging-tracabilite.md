üîù Retour au [Sommaire](/SOMMAIRE.md)

# 17.3 Audit Logging et Tra√ßabilit√©

## Introduction

L'audit logging est une exigence fondamentale de la conformit√© r√©glementaire. Il permet de r√©pondre aux questions essentielles du "Qui, Quoi, Quand, O√π, Pourquoi" pour chaque action effectu√©e sur les donn√©es sensibles. Pour Redis, qui ne dispose pas nativement d'un syst√®me d'audit robuste, cette exigence repr√©sente un d√©fi technique n√©cessitant des solutions tierces et des proc√©dures rigoureuses.

**D√©finition de l'audit logging :**
> L'enregistrement syst√©matique et horodat√© de tous les √©v√©nements de s√©curit√© et acc√®s aux donn√©es permettant la reconstruction compl√®te d'une s√©quence d'activit√©s et l'identification des acteurs impliqu√©s.

---

## Cadre r√©glementaire de l'audit logging

### RGPD - Article 32 : S√©curit√© du traitement

**Article 32.1.d :**
> "Une proc√©dure visant √† tester, √† analyser et √† √©valuer r√©guli√®rement l'efficacit√© des mesures techniques et organisationnelles pour assurer la s√©curit√© du traitement."

**Implications pour Redis :**
- Tra√ßabilit√© des acc√®s aux donn√©es personnelles
- Logs permettant de d√©tecter les violations de donn√©es (Article 33)
- Conservation des logs pour d√©montrer la conformit√© (accountability)
- Capacit√© √† identifier les acc√®s non autoris√©s

**Dur√©e de conservation :**
- Aucune dur√©e minimale sp√©cifi√©e dans le RGPD
- Recommandation CNIL : **12 mois minimum** pour les logs de s√©curit√©
- Possibilit√© de conservation plus longue si justifi√©e (int√©r√™t l√©gitime)

### PCI DSS - Requirement 10 : Track and Monitor Access

**10.1 : Implement audit trails**
> √âtablir un processus pour relier tous les acc√®s aux composants syst√®me √† chaque utilisateur individuel.

**√âv√©nements obligatoires √† logger (10.2) :**
```
10.2.1 : Tous les acc√®s individuels aux donn√©es de titulaire de carte (PAN)
10.2.2 : Toutes les actions effectu√©es par un utilisateur avec privil√®ges
10.2.3 : Tous les acc√®s √† l'audit trail
10.2.4 : Tentatives d'acc√®s logiques invalides
10.2.5 : Utilisation et modifications des m√©canismes d'identification/authentification
10.2.6 : Initialisation, arr√™t, pause de l'audit trail
10.2.7 : Cr√©ation et suppression d'objets au niveau syst√®me
```

**Contenu minimum de chaque log (10.3) :**
```
10.3.1 : Identification utilisateur
10.3.2 : Type d'√©v√©nement
10.3.3 : Date et heure
10.3.4 : Succ√®s ou √©chec
10.3.5 : Origine de l'√©v√©nement
10.3.6 : Identit√© ou nom de la donn√©e, composant syst√®me ou ressource affect√©e
```

**Revue des logs (10.6) :**
```
10.6.1 : Revue quotidienne des logs (au minimum)
10.6.2 : Revue p√©riodique des logs de tous les composants syst√®me
10.6.3 : Suivi des exceptions et anomalies
```

**R√©tention PCI DSS (10.7) :**
```
10.7.2 : Conserver l'historique d'audit au moins 12 mois
10.7.3 : Au moins 3 mois doivent √™tre imm√©diatement disponibles pour analyse
```

### HIPAA - Security Rule ¬ß164.312

**¬ß164.312(b) : Audit controls (Required)**
> "Impl√©menter des m√©canismes mat√©riels, logiciels et/ou proc√©duraux qui enregistrent et examinent l'activit√© dans les syst√®mes d'information contenant des PHI."

**Exigences HIPAA pour Redis :**
```
‚ñ° Enregistrement de tous les acc√®s aux PHI (Protected Health Information)
‚ñ° Identification de l'utilisateur effectuant l'acc√®s
‚ñ° Type d'acc√®s (lecture, modification, suppression)
‚ñ° Date et heure de l'acc√®s
‚ñ° √âchecs d'authentification
‚ñ° Conservation minimum 6 ans (¬ß164.316(b)(2))
```

**¬ß164.308(a)(1)(ii)(D) : Information system activity review (Required)**
> "Examiner r√©guli√®rement les enregistrements d'activit√© du syst√®me d'information, tels que les logs d'audit."

### SOC 2 - Common Criteria CC7.2

**D√©tection et analyse des incidents :**
```
CC7.2 : Le syst√®me d√©tecte les incidents de s√©curit√©, les rapporte et analyse
        leur impact potentiel.
```

**Exigences pour les logs :**
- Centralisation dans un SIEM
- Corr√©lation des √©v√©nements
- Alerting en temps r√©el
- Analyse forensique en cas d'incident
- Revue r√©guli√®re (au moins mensuelle)

### ISO 27001 - Annexe A.12.4

**A.12.4.1 : Event logging (Required)**
```
Objectif : Enregistrer les √©v√©nements et g√©n√©rer des preuves

Mesures :
- Logs utilisateurs, exceptions, fautes
- Identit√© utilisateur, date/heure, √©v√©nement, origine, succ√®s/√©chec
- Protection des logs contre alt√©ration
- Synchronisation temporelle (NTP)
```

**A.12.4.2 : Protection of log information (Required)**
```
- Logs prot√©g√©s contre modifications non autoris√©es
- Acc√®s restreint aux logs (read-only pour la plupart)
- Backup r√©gulier des logs
```

**A.12.4.3 : Administrator and operator logs (Required)**
```
- Activit√©s des administrateurs et op√©rateurs enregistr√©es
- Revue r√©guli√®re des logs privil√©gi√©s
```

**A.12.4.4 : Clock synchronization (Required)**
```
- Synchronisation NTP obligatoire
- Pr√©cision temporelle pour corr√©lation
```

---

## Limitations natives de Redis en mati√®re d'audit

### Ce que Redis fournit (natif)

**1. Slowlog**
```bash
# Log des commandes lentes
CONFIG SET slowlog-log-slower-than 10000  # 10ms
CONFIG SET slowlog-max-len 128

SLOWLOG GET 10
```

**Limitations :**
- ‚ùå Pas d'identification de l'utilisateur (avant Redis 6 ACL)
- ‚ùå Pas d'IP source
- ‚ùå Seulement les commandes lentes (pas toutes)
- ‚ùå Taille limit√©e (in-memory, pas persistant)
- ‚ùå Pas d'horodatage pr√©cis (timestamp Unix)

**2. Commande MONITOR**
```bash
# Streaming de toutes les commandes en temps r√©el
redis-cli MONITOR
```

**Limitations :**
- ‚ùå Impact performance majeur (production inacceptable)
- ‚ùå Pas d'identification utilisateur
- ‚ùå Pas de persistance (output console uniquement)
- ‚ùå Pas de filtrage
- ‚ùå TR√àS DANGEREUX : peut exposer des donn√©es sensibles

**3. Logs syst√®me (redis-server.log)**
```bash
# /var/log/redis/redis-server.log
loglevel notice  # debug, verbose, notice, warning
```

**Contenu :**
- D√©marrage/arr√™t du serveur
- Erreurs de connexion
- Changements de configuration
- R√©plication/cluster events
- Warnings et erreurs

**Limitations :**
- ‚ùå Pas de log des commandes ex√©cut√©es
- ‚ùå Pas d'audit trail des acc√®s aux donn√©es
- ‚ùå Logs g√©n√©riques (op√©rationnels, pas s√©curit√©)

**4. ACL LOG (Redis 6+)**
```bash
# Log des √©checs ACL
ACL LOG 10

# Exemple de sortie
1) "count"
2) (integer) 1
3) "reason"
4) "command"
5) "context"
6) "toplevel"
7) "object"
8) "GET"
9) "username"
10) "alice"
11) "age-seconds"
12) "5"
13) "client-info"
14) "id=7 addr=192.168.1.10:52144 ..."
```

**Avantages :**
- ‚úÖ Identification utilisateur (ACL)
- ‚úÖ IP source
- ‚úÖ Commande refus√©e
- ‚úÖ Raison du refus

**Limitations :**
- ‚ùå Seulement les √©checs ACL (pas les succ√®s)
- ‚ùå In-memory (taille limit√©e)
- ‚ùå Pas de persistance automatique
- ‚ùå Pas de centralisation

### Conclusion : N√©cessit√© de solutions tierces

**Pour une conformit√© PCI DSS, HIPAA, SOC 2, Redis natif est INSUFFISANT.**

Il faut impl√©menter :
1. **Proxy avec audit logging** (Envoy, HAProxy, twemproxy modifi√©)
2. **Instrumentation applicative** (logs c√¥t√© application)
3. **Monitoring externe** (Packet capture, eBPF)
4. **Module Redis custom** (extension C)
5. **Redis Enterprise** (solution commerciale avec audit)

---

## Solutions d'audit logging pour Redis

### Solution 1 : Proxy avec audit logging (recommand√©)

**Architecture :**
```
[Application] ‚Üí [Proxy avec audit] ‚Üí [Redis]
                      ‚Üì
                  [SIEM/Log Storage]
```

#### Option 1A : Envoy Proxy

**Avantages :**
- Proxy moderne, performant, cloud-native
- Support TLS natif
- Extensible (filtres personnalis√©s)
- Metrics et tracing int√©gr√©s

**Configuration Envoy pour Redis :**

```yaml
# envoy.yaml
static_resources:
  listeners:
  - name: redis_listener
    address:
      socket_address:
        address: 0.0.0.0
        port_value: 6380

    filter_chains:
    - filters:
      # 1. Filtre Redis proxy
      - name: envoy.filters.network.redis_proxy
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.redis_proxy.v3.RedisProxy
          stat_prefix: redis_stats

          # Connexion au Redis backend
          settings:
            op_timeout: 5s
            enable_redirection: true
            enable_command_stats: true

          # Prefix routing (si cluster)
          prefix_routes:
            routes:
            - prefix: "/"
              cluster: redis_cluster

      # 2. Filtre d'audit (custom Lua filter)
      - name: envoy.filters.network.lua
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.lua.v3.Lua
          inline_code: |
            function envoy_on_request(request_handle)
              local metadata = request_handle:streamInfo():dynamicMetadata()
              local client_ip = request_handle:connection():remoteAddress()
              local timestamp = os.time()

              -- Log l'acc√®s (envoyer vers syslog ou fichier)
              log_audit({
                timestamp = timestamp,
                client_ip = client_ip,
                user = metadata:get("user") or "unknown",
                command = metadata:get("command") or "unknown",
                success = true
              })
            end

      # 3. TLS (optionnel)
      transport_socket:
        name: envoy.transport_sockets.tls
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.DownstreamTlsContext
          common_tls_context:
            tls_certificates:
            - certificate_chain:
                filename: "/etc/envoy/certs/redis-cert.pem"
              private_key:
                filename: "/etc/envoy/certs/redis-key.pem"

  clusters:
  - name: redis_cluster
    connect_timeout: 1s
    type: STRICT_DNS
    dns_lookup_family: V4_ONLY
    lb_policy: MAGLEV

    # Health checking
    health_checks:
    - timeout: 1s
      interval: 5s
      unhealthy_threshold: 3
      healthy_threshold: 2
      custom_health_check:
        name: envoy.health_checkers.redis
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.health_checkers.redis.v3.Redis
          key: health_check

    # Backend Redis
    load_assignment:
      cluster_name: redis_cluster
      endpoints:
      - lb_endpoints:
        - endpoint:
            address:
              socket_address:
                address: redis-master.internal
                port_value: 6379

# Admin interface pour metrics
admin:
  address:
    socket_address:
      address: 0.0.0.0
      port_value: 9901
```

**Audit logging avec Envoy + syslog :**

```yaml
# Ajouter un tap filter pour audit complet
static_resources:
  listeners:
  - name: redis_listener
    # ... (config pr√©c√©dente)

    filter_chains:
    - filters:
      - name: envoy.filters.network.tap
        typed_config:
          "@type": type.googleapis.com/envoy.extensions.filters.network.tap.v3.Tap
          common_config:
            static_config:
              match_config:
                any_match: true
              output_config:
                sinks:
                - format: JSON_BODY_AS_STRING
                  file_per_tap:
                    path_prefix: /var/log/envoy/redis_audit_
```

**Parser les logs Envoy :**

```python
# Script Python pour extraire les commandes Redis des logs Envoy
import json
import re
from datetime import datetime

def parse_envoy_redis_audit(log_line):
    """
    Parser une ligne de log Envoy et extraire les d√©tails d'audit
    """
    try:
        log = json.loads(log_line)

        # Extraire les informations pertinentes
        audit_event = {
            'timestamp': datetime.fromtimestamp(log['timestamp']).isoformat(),
            'client_ip': log.get('downstream_remote_address', 'unknown'),
            'command': extract_redis_command(log.get('request', '')),
            'response_code': log.get('response_code', 'unknown'),
            'duration_ms': log.get('duration', 0),
            'bytes_sent': log.get('bytes_sent', 0),
            'bytes_received': log.get('bytes_received', 0),
        }

        # Envoyer vers SIEM
        send_to_siem(audit_event)

        return audit_event

    except Exception as e:
        print(f"Error parsing log: {e}")
        return None

def extract_redis_command(request_data):
    """Extraire la commande Redis du payload"""
    # Redis protocol : *<argc>\r\n$<len>\r\n<data>\r\n...
    match = re.search(r'\$\d+\r\n(\w+)\r\n', request_data)
    if match:
        return match.group(1).upper()
    return "UNKNOWN"

# Traitement continu des logs
with open('/var/log/envoy/redis_audit.log', 'r') as f:
    for line in f:
        parse_envoy_redis_audit(line)
```

#### Option 1B : Redis Audit Proxy (custom)

**Solution sur-mesure avec logging complet :**

```python
#!/usr/bin/env python3
"""
Redis Audit Proxy
Proxy transparent avec audit logging complet pour conformit√© PCI DSS/HIPAA

Architecture :
[Client] ‚Üí [Audit Proxy :6380] ‚Üí [Redis :6379]
                ‚Üì
          [Audit Logs ‚Üí SIEM]
"""

import asyncio
import logging
import json
import time
from datetime import datetime
import aioredis
import hashlib

# Configuration
PROXY_HOST = '0.0.0.0'
PROXY_PORT = 6380
REDIS_HOST = 'localhost'
REDIS_PORT = 6379
AUDIT_LOG_FILE = '/var/log/redis/audit.log'
SIEM_ENDPOINT = 'https://siem.example.com/api/events'

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('redis-audit-proxy')

# Audit logger s√©par√©
audit_logger = logging.getLogger('redis-audit')
audit_handler = logging.FileHandler(AUDIT_LOG_FILE)
audit_handler.setFormatter(logging.Formatter('%(message)s'))
audit_logger.addHandler(audit_handler)
audit_logger.setLevel(logging.INFO)

# Commandes sensibles n√©cessitant un audit d√©taill√©
SENSITIVE_COMMANDS = {
    'GET', 'SET', 'DEL', 'HGET', 'HSET', 'HDEL',
    'MGET', 'MSET', 'KEYS', 'SCAN', 'FLUSHDB', 'FLUSHALL',
    'CONFIG', 'SCRIPT', 'EVAL', 'AUTH', 'ACL'
}

# Commandes √† bloquer compl√®tement (configurable)
BLOCKED_COMMANDS = {
    'FLUSHALL',  # Trop dangereux en production
    'FLUSHDB',
    'DEBUG',
    'SHUTDOWN'
}

class RedisAuditProxy:
    """
    Proxy Redis avec audit logging complet
    """

    def __init__(self):
        self.redis_pool = None
        self.stats = {
            'total_commands': 0,
            'blocked_commands': 0,
            'audit_events': 0,
            'errors': 0
        }

    async def init_redis_pool(self):
        """Initialiser le pool de connexions Redis backend"""
        self.redis_pool = await aioredis.create_redis_pool(
            f'redis://{REDIS_HOST}:{REDIS_PORT}',
            minsize=10,
            maxsize=100,
            timeout=5
        )
        logger.info(f"Connected to Redis backend at {REDIS_HOST}:{REDIS_PORT}")

    async def handle_client(self, reader, writer):
        """
        G√©rer une connexion client
        """
        client_address = writer.get_extra_info('peername')
        session_id = hashlib.sha256(
            f"{client_address}{time.time()}".encode()
        ).hexdigest()[:16]

        logger.info(f"New connection from {client_address} (session: {session_id})")

        try:
            while True:
                # Lire la commande Redis (RESP protocol)
                command_data = await self.read_redis_command(reader)

                if not command_data:
                    break  # Connexion ferm√©e

                # Parser la commande
                command = self.parse_redis_command(command_data)

                # Audit logging
                audit_event = await self.create_audit_event(
                    session_id=session_id,
                    client_address=client_address,
                    command=command,
                    raw_data=command_data
                )

                # V√©rifier si la commande est bloqu√©e
                if self.is_command_blocked(command):
                    response = self.create_error_response(
                        "ERR command not allowed by proxy policy"
                    )
                    audit_event['blocked'] = True
                    audit_event['block_reason'] = 'policy_violation'
                    self.stats['blocked_commands'] += 1
                else:
                    # Transf√©rer au Redis backend
                    start_time = time.time()
                    response = await self.forward_to_redis(command_data)
                    duration_ms = (time.time() - start_time) * 1000

                    audit_event['duration_ms'] = round(duration_ms, 2)
                    audit_event['success'] = not response.startswith(b'-ERR')
                    audit_event['blocked'] = False

                # √âcrire l'audit log
                self.write_audit_log(audit_event)

                # Envoyer la r√©ponse au client
                writer.write(response)
                await writer.drain()

                self.stats['total_commands'] += 1

        except Exception as e:
            logger.error(f"Error handling client {client_address}: {e}")
            self.stats['errors'] += 1

        finally:
            writer.close()
            await writer.wait_closed()
            logger.info(f"Connection closed: {client_address} (session: {session_id})")

    async def read_redis_command(self, reader):
        """
        Lire une commande Redis au format RESP
        """
        try:
            # RESP protocol : *<argc>\r\n$<len>\r\n<arg>\r\n...
            line = await reader.readline()

            if not line:
                return None

            if not line.startswith(b'*'):
                return line  # Commande inline (telnet-style)

            # Parser le nombre d'arguments
            argc = int(line[1:-2])

            command_parts = []
            for _ in range(argc):
                # Lire la longueur de l'argument
                length_line = await reader.readline()
                arg_length = int(length_line[1:-2])

                # Lire l'argument
                arg = await reader.readexactly(arg_length)
                await reader.readexactly(2)  # \r\n

                command_parts.append(arg)

            return b'*' + str(argc).encode() + b'\r\n' + b''.join(
                b'$' + str(len(part)).encode() + b'\r\n' + part + b'\r\n'
                for part in command_parts
            )

        except asyncio.IncompleteReadError:
            return None
        except Exception as e:
            logger.error(f"Error reading Redis command: {e}")
            return None

    def parse_redis_command(self, command_data):
        """
        Parser une commande Redis RESP pour extraction
        """
        try:
            if command_data.startswith(b'*'):
                # RESP array format
                parts = []
                lines = command_data.split(b'\r\n')
                i = 1  # Skip first line (*N)
                while i < len(lines):
                    if lines[i].startswith(b'$'):
                        parts.append(lines[i+1].decode('utf-8', errors='replace'))
                        i += 2
                    else:
                        i += 1

                return {
                    'command': parts[0].upper() if parts else 'UNKNOWN',
                    'args': parts[1:] if len(parts) > 1 else [],
                    'argc': len(parts)
                }
            else:
                # Inline format
                parts = command_data.decode('utf-8', errors='replace').strip().split()
                return {
                    'command': parts[0].upper() if parts else 'UNKNOWN',
                    'args': parts[1:] if len(parts) > 1 else [],
                    'argc': len(parts)
                }
        except Exception as e:
            logger.error(f"Error parsing command: {e}")
            return {'command': 'PARSE_ERROR', 'args': [], 'argc': 0}

    async def create_audit_event(self, session_id, client_address, command, raw_data):
        """
        Cr√©er un √©v√©nement d'audit structur√©
        """
        event = {
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'event_type': 'redis_command',
            'session_id': session_id,
            'client_ip': client_address[0],
            'client_port': client_address[1],
            'command': command['command'],
            'argc': command['argc'],
            'sensitive': command['command'] in SENSITIVE_COMMANDS,
            'proxy_version': '1.0.0',
        }

        # Ajouter les arguments (avec redaction si sensible)
        if command['command'] in SENSITIVE_COMMANDS:
            event['args'] = self.redact_sensitive_args(command)
        else:
            event['args'] = command['args'][:10]  # Limiter √† 10 args

        # Taille de la commande (pour d√©tecter les big keys)
        event['command_size_bytes'] = len(raw_data)

        return event

    def redact_sensitive_args(self, command):
        """
        Redacter les valeurs sensibles dans les arguments
        (PCI DSS : ne jamais logger les PANs, CVV, etc.)
        """
        cmd = command['command']
        args = command['args']

        # Pour SET, HSET : Ne pas logger la valeur
        if cmd in ('SET', 'SETEX', 'SETNX', 'HSET', 'HMSET'):
            if len(args) >= 2:
                return [args[0], '<REDACTED>'] + args[2:]

        # Pour GET, DEL : Logger seulement les cl√©s
        if cmd in ('GET', 'DEL', 'HGET', 'HDEL'):
            return args  # Les cl√©s sont OK (identifiants, pas valeurs)

        # Par d√©faut : Redacter tous les args
        return ['<REDACTED>' for _ in args]

    def is_command_blocked(self, command):
        """V√©rifier si une commande est bloqu√©e par policy"""
        return command['command'] in BLOCKED_COMMANDS

    async def forward_to_redis(self, command_data):
        """
        Transf√©rer la commande au Redis backend
        """
        try:
            # Utiliser une connexion du pool
            async with self.redis_pool.get() as conn:
                # Envoyer la commande raw
                conn.writer.write(command_data)
                await conn.writer.drain()

                # Lire la r√©ponse
                response = await self.read_redis_response(conn.reader)
                return response

        except Exception as e:
            logger.error(f"Error forwarding to Redis: {e}")
            return self.create_error_response(f"ERR proxy error: {str(e)}")

    async def read_redis_response(self, reader):
        """Lire une r√©ponse Redis RESP"""
        try:
            first_byte = await reader.readexactly(1)

            if first_byte == b'+':  # Simple string
                line = await reader.readline()
                return first_byte + line

            elif first_byte == b'-':  # Error
                line = await reader.readline()
                return first_byte + line

            elif first_byte == b':':  # Integer
                line = await reader.readline()
                return first_byte + line

            elif first_byte == b'$':  # Bulk string
                length_line = await reader.readline()
                length = int(length_line[:-2])

                if length == -1:  # Null
                    return first_byte + length_line

                data = await reader.readexactly(length + 2)  # +2 for \r\n
                return first_byte + length_line + data

            elif first_byte == b'*':  # Array
                count_line = await reader.readline()
                count = int(count_line[:-2])

                if count == -1:  # Null array
                    return first_byte + count_line

                result = first_byte + count_line
                for _ in range(count):
                    element = await self.read_redis_response(reader)
                    result += element

                return result

            else:
                logger.error(f"Unknown RESP type: {first_byte}")
                return b'-ERR unknown response type\r\n'

        except Exception as e:
            logger.error(f"Error reading Redis response: {e}")
            return b'-ERR error reading response\r\n'

    def create_error_response(self, message):
        """Cr√©er une r√©ponse d'erreur RESP"""
        return f"-{message}\r\n".encode()

    def write_audit_log(self, audit_event):
        """
        √âcrire un √©v√©nement d'audit
        Format : JSON (un √©v√©nement par ligne)
        """
        try:
            # Log vers fichier (JSON Lines format)
            audit_logger.info(json.dumps(audit_event))

            # Optionnel : Envoyer vers SIEM en temps r√©el
            # asyncio.create_task(self.send_to_siem(audit_event))

            self.stats['audit_events'] += 1

        except Exception as e:
            logger.error(f"Error writing audit log: {e}")

    async def send_to_siem(self, audit_event):
        """Envoyer un √©v√©nement vers le SIEM (optionnel)"""
        try:
            # Exemple avec HTTP POST vers SIEM
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    SIEM_ENDPOINT,
                    json=audit_event,
                    headers={'Content-Type': 'application/json'},
                    timeout=aiohttp.ClientTimeout(total=5)
                ) as response:
                    if response.status != 200:
                        logger.warning(f"SIEM returned {response.status}")
        except Exception as e:
            logger.error(f"Error sending to SIEM: {e}")

    async def start(self):
        """D√©marrer le proxy"""
        await self.init_redis_pool()

        server = await asyncio.start_server(
            self.handle_client,
            PROXY_HOST,
            PROXY_PORT
        )

        addr = server.sockets[0].getsockname()
        logger.info(f"Redis Audit Proxy listening on {addr}")

        async with server:
            await server.serve_forever()

# Point d'entr√©e
if __name__ == '__main__':
    proxy = RedisAuditProxy()
    try:
        asyncio.run(proxy.start())
    except KeyboardInterrupt:
        logger.info("Proxy stopped by user")
        logger.info(f"Stats: {proxy.stats}")
```

**D√©ploiement du proxy :**

```bash
# 1. Installer les d√©pendances
pip3 install aioredis aiohttp

# 2. Cr√©er un service systemd
cat > /etc/systemd/system/redis-audit-proxy.service <<EOF
[Unit]
Description=Redis Audit Proxy
After=network.target redis.service

[Service]
Type=simple
User=redis-proxy
Group=redis-proxy
ExecStart=/usr/local/bin/redis-audit-proxy.py
Restart=always
RestartSec=5

# Hardening
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/log/redis

[Install]
WantedBy=multi-user.target
EOF

# 3. Cr√©er l'utilisateur
useradd -r -s /bin/false redis-proxy

# 4. Permissions
chown redis-proxy:redis-proxy /var/log/redis/audit.log
chmod 640 /var/log/redis/audit.log

# 5. D√©marrer
systemctl enable redis-audit-proxy
systemctl start redis-audit-proxy

# 6. V√©rifier
systemctl status redis-audit-proxy
tail -f /var/log/redis/audit.log
```

**Exemple de log d'audit g√©n√©r√© :**
```json
{
  "timestamp": "2024-12-11T14:32:05.123456Z",
  "event_type": "redis_command",
  "session_id": "a7f3c9d1e5b2f4a8",
  "client_ip": "192.168.1.10",
  "client_port": 52341,
  "command": "GET",
  "argc": 2,
  "args": ["user:12345:email"],
  "sensitive": true,
  "command_size_bytes": 45,
  "duration_ms": 1.23,
  "success": true,
  "blocked": false,
  "proxy_version": "1.0.0"
}
```

### Solution 2 : Instrumentation applicative

**Principe :** Logger les acc√®s Redis dans l'application elle-m√™me.

**Avantages :**
- ‚úÖ Contexte applicatif riche (user_id, transaction_id, etc.)
- ‚úÖ Pas d'infrastructure suppl√©mentaire
- ‚úÖ Filtrage intelligent possible

**Inconv√©nients :**
- ‚ùå N√©cessite modification de chaque application
- ‚ùå Peut √™tre contourn√© (si acc√®s direct √† Redis)
- ‚ùå Overhead de d√©veloppement

**Impl√©mentation Python (wrapper Redis) :**

```python
import redis
import logging
import json
import time
from datetime import datetime
from functools import wraps

# Configuration
audit_logger = logging.getLogger('redis.audit')
audit_handler = logging.FileHandler('/var/log/app/redis_audit.log')
audit_handler.setFormatter(logging.Formatter('%(message)s'))
audit_logger.addHandler(audit_handler)
audit_logger.setLevel(logging.INFO)

def audit_redis_command(func):
    """
    D√©corateur pour auditer les commandes Redis
    """
    @wraps(func)
    def wrapper(self, *args, **kwargs):
        # D√©but chrono
        start_time = time.time()

        # Contexte
        command = func.__name__.upper()

        # Ex√©cuter la commande
        try:
            result = func(self, *args, **kwargs)
            success = True
            error = None
        except Exception as e:
            result = None
            success = False
            error = str(e)
            raise
        finally:
            # Dur√©e
            duration_ms = (time.time() - start_time) * 1000

            # Cr√©er l'√©v√©nement d'audit
            audit_event = {
                'timestamp': datetime.utcnow().isoformat() + 'Z',
                'command': command,
                'args': self._redact_args(command, args),
                'success': success,
                'duration_ms': round(duration_ms, 2),
                'error': error,
                # Contexte applicatif
                'user_id': getattr(self, 'current_user_id', None),
                'session_id': getattr(self, 'current_session_id', None),
                'request_id': getattr(self, 'current_request_id', None),
                'ip_address': getattr(self, 'current_ip_address', None),
            }

            # Logger
            audit_logger.info(json.dumps(audit_event))

        return result

    return wrapper

class AuditedRedisClient:
    """
    Client Redis avec audit logging automatique
    """

    def __init__(self, *args, **kwargs):
        self.redis = redis.Redis(*args, **kwargs)

        # Contexte applicatif (√† d√©finir avant chaque op√©ration)
        self.current_user_id = None
        self.current_session_id = None
        self.current_request_id = None
        self.current_ip_address = None

    def set_context(self, user_id=None, session_id=None, request_id=None, ip_address=None):
        """D√©finir le contexte applicatif pour l'audit"""
        self.current_user_id = user_id
        self.current_session_id = session_id
        self.current_request_id = request_id
        self.current_ip_address = ip_address

    def _redact_args(self, command, args):
        """Redacter les arguments sensibles"""
        if command in ('SET', 'SETEX', 'HSET'):
            # Ne logger que la cl√©, pas la valeur
            return [str(args[0]), '<REDACTED>'] + [str(a) for a in args[2:]]
        else:
            return [str(a) for a in args[:5]]  # Limiter √† 5 args

    @audit_redis_command
    def get(self, key):
        return self.redis.get(key)

    @audit_redis_command
    def set(self, key, value, *args, **kwargs):
        return self.redis.set(key, value, *args, **kwargs)

    @audit_redis_command
    def delete(self, *keys):
        return self.redis.delete(*keys)

    @audit_redis_command
    def hget(self, name, key):
        return self.redis.hget(name, key)

    @audit_redis_command
    def hset(self, name, key, value):
        return self.redis.hset(name, key, value)

    # ... Ajouter toutes les m√©thodes Redis √† auditer

# Utilisation dans l'application
redis_client = AuditedRedisClient(host='localhost', port=6379)

# Dans le handler de requ√™te HTTP
def handle_user_request(request):
    # D√©finir le contexte
    redis_client.set_context(
        user_id=request.user.id,
        session_id=request.session.session_key,
        request_id=request.request_id,
        ip_address=request.META['REMOTE_ADDR']
    )

    # Les op√©rations Redis sont maintenant audit√©es avec contexte
    user_data = redis_client.get(f'user:{request.user.id}:profile')

    # ...
```

### Solution 3 : Redis Enterprise (commercial)

**Redis Enterprise** propose un audit logging natif.

**Fonctionnalit√©s :**
- ‚úÖ Audit logging complet (qui, quoi, quand)
- ‚úÖ Filtrage par commande, utilisateur, database
- ‚úÖ Export vers syslog, SIEM
- ‚úÖ Performance minimale (<5% overhead)
- ‚úÖ Conformit√© PCI DSS, HIPAA certifi√©e

**Configuration (Redis Enterprise) :**

```bash
# Via rladmin CLI
rladmin cluster config audit_protocol enable
rladmin cluster config audit_address syslog://siem.example.com:514
rladmin cluster config audit_protocol_filter "SET,GET,DEL,HSET,HGET,HDEL"

# Via API REST
curl -k -u "admin@example.com:password" \
  -X PUT \
  -H "Content-Type: application/json" \
  -d '{
    "audit_protocol": {
      "enabled": true,
      "protocol": "syslog",
      "address": "siem.example.com:514",
      "filter": "SET,GET,DEL,HSET,HGET,HDEL",
      "format": "json"
    }
  }' \
  https://localhost:9443/v1/cluster/audit
```

**Format des logs Redis Enterprise :**
```json
{
  "timestamp": "2024-12-11T14:32:05.123Z",
  "cluster_id": "cluster-1",
  "database_id": "db-1",
  "user": "alice",
  "client_ip": "192.168.1.10",
  "command": "GET",
  "key": "user:12345:email",
  "success": true,
  "latency_ms": 0.95
}
```

---

## Contenu des logs d'audit

### √âv√©nements obligatoires √† logger

#### 1. Acc√®s aux donn√©es (PCI DSS 10.2.1)

```json
{
  "event_category": "data_access",
  "timestamp": "2024-12-11T14:32:05.123Z",
  "user": "app_user_alice",
  "user_id": "12345",
  "client_ip": "192.168.1.10",
  "command": "GET",
  "key_pattern": "user:*:email",
  "key_accessed": "user:12345:email",
  "data_category": "PII",
  "success": true,
  "duration_ms": 1.23,
  "session_id": "sess_abc123",
  "request_id": "req_xyz789"
}
```

**Champs requis :**
- `timestamp` : ISO 8601 avec timezone (UTC recommand√©)
- `user` : Identifiant unique de l'utilisateur/application
- `client_ip` : Adresse IP source
- `command` : Commande Redis ex√©cut√©e
- `key_accessed` : Cl√©(s) acc√©d√©e(s)
- `success` : Bool√©en (succ√®s ou √©chec)

**Champs recommand√©s :**
- `data_category` : Classification de la donn√©e (PII, PHI, PCI, Public)
- `session_id` : Identifiant de session pour corr√©lation
- `request_id` : Identifiant de requ√™te end-to-end
- `duration_ms` : Dur√©e d'ex√©cution (d√©tection anomalies)

#### 2. Actions privil√©gi√©es (PCI DSS 10.2.2)

```json
{
  "event_category": "privileged_action",
  "timestamp": "2024-12-11T14:35:10.456Z",
  "user": "admin_john",
  "role": "redis_admin",
  "client_ip": "10.0.1.5",
  "command": "CONFIG",
  "subcommand": "SET",
  "parameter": "maxmemory",
  "old_value": "4gb",
  "new_value": "8gb",
  "success": true,
  "authorized_by": "change_request_CR-2024-1234"
}
```

**Commandes privil√©gi√©es √† logger :**
- `CONFIG SET/GET/REWRITE`
- `ACL SETUSER/DELUSER/SAVE`
- `SHUTDOWN`
- `DEBUG`
- `SCRIPT FLUSH/LOAD`
- `BGREWRITEAOF`
- `BGSAVE`
- `REPLICAOF`
- `CLUSTER *`

#### 3. Tentatives d'acc√®s √©chou√©es (PCI DSS 10.2.4)

```json
{
  "event_category": "failed_access",
  "timestamp": "2024-12-11T14:40:15.789Z",
  "user": "unknown_user",
  "client_ip": "203.0.113.45",
  "command": "AUTH",
  "failure_reason": "invalid_password",
  "attempt_count": 3,
  "lockout_triggered": false,
  "source_country": "CN",
  "threat_score": 75
}
```

**Types d'√©checs √† logger :**
- Authentification √©chou√©e (AUTH, ACL)
- Permission refus√©e (ACL)
- Commande inexistante
- Syntaxe invalide
- Timeout
- Connexion refus√©e (maxclients)

#### 4. Modifications d'authentification (PCI DSS 10.2.5)

```json
{
  "event_category": "auth_modification",
  "timestamp": "2024-12-11T15:00:00.123Z",
  "admin_user": "admin_sarah",
  "action": "acl_user_created",
  "target_user": "app_service_xyz",
  "permissions": ["+@read", "+@write", "~keys:*"],
  "password_changed": true,
  "mfa_enabled": false
}
```

**√âv√©nements d'authentification :**
- Cr√©ation d'utilisateur ACL
- Modification de permissions ACL
- Suppression d'utilisateur
- Changement de mot de passe (`CONFIG SET requirepass`)
- Rotation de credentials

#### 5. D√©marrage/Arr√™t du syst√®me (PCI DSS 10.2.6)

```json
{
  "event_category": "system_lifecycle",
  "timestamp": "2024-12-11T16:00:00.000Z",
  "event": "redis_restart",
  "initiated_by": "systemd",
  "reason": "configuration_change",
  "previous_uptime_seconds": 86400,
  "config_changes": ["maxmemory", "tls-port"],
  "data_persisted": true,
  "rdb_last_save": "2024-12-11T15:59:55.000Z"
}
```

#### 6. Op√©rations sur les objets syst√®me (PCI DSS 10.2.7)

```json
{
  "event_category": "system_object",
  "timestamp": "2024-12-11T17:00:00.000Z",
  "user": "admin_mike",
  "action": "database_flush",
  "command": "FLUSHDB",
  "database_id": 0,
  "keys_deleted": 15234,
  "memory_freed_mb": 512,
  "confirmed": true,
  "change_request": "CR-2024-5678"
}
```

**Op√©rations critiques :**
- `FLUSHDB` / `FLUSHALL`
- Cr√©ation/suppression de database
- Modification de la r√©plication (`REPLICAOF`)
- Modifications du cluster (`CLUSTER ADDSLOTS`, `CLUSTER FAILOVER`)

---

## R√©tention et archivage des logs

### Politiques de r√©tention r√©glementaires

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ R√©glementation ‚îÇ Dur√©e minimale  ‚îÇ Disponibilit√© imm√©diate       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ PCI DSS        ‚îÇ 12 mois         ‚îÇ 3 mois                        ‚îÇ
‚îÇ HIPAA          ‚îÇ 6 ans           ‚îÇ N/A (√† d√©finir)               ‚îÇ
‚îÇ SOC 2          ‚îÇ 12 mois (rec.)  ‚îÇ 3 mois (recommand√©)           ‚îÇ
‚îÇ RGPD           ‚îÇ Aucune (rec.)   ‚îÇ 12 mois (CNIL)                ‚îÇ
‚îÇ ISO 27001      ‚îÇ Selon politique ‚îÇ Selon besoin                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Strat√©gie de r√©tention en 3 tiers

**Tier 1 : Hot Storage (0-90 jours)**
```
- Stockage : Disque SSD local ou distribu√©
- Format : JSON Lines
- Indexation : Elasticsearch, Splunk
- Acc√®s : Temps r√©el, recherche full-text
- Performance : < 1 seconde pour requ√™tes
- Co√ªt : √âlev√© (SSD, infrastructure SIEM)
```

**Tier 2 : Warm Storage (90 jours - 12 mois)**
```
- Stockage : Object storage (S3, Azure Blob)
- Format : Compressed JSON (gzip, lz4)
- Indexation : Partielle (m√©tadonn√©es uniquement)
- Acc√®s : Minutes √† heures
- Performance : Recherche par date/utilisateur uniquement
- Co√ªt : Moyen (S3 Standard ou Infrequent Access)
```

**Tier 3 : Cold Storage (12 mois - 6 ans)**
```
- Stockage : Archivage (S3 Glacier, Azure Archive)
- Format : Tar.gz par mois
- Indexation : Aucune (restauration compl√®te requise)
- Acc√®s : Heures √† jours
- Performance : Export complet puis recherche locale
- Co√ªt : Tr√®s faible (quelques $ par TB/mois)
```

### Impl√©mentation de la rotation

**Script de rotation et archivage :**

```bash
#!/bin/bash
#
# Redis Audit Log Rotation and Archival
# Impl√©mente la strat√©gie 3-tier : Hot ‚Üí Warm ‚Üí Cold
#

set -e

# Configuration
AUDIT_LOG="/var/log/redis/audit.log"
HOT_DIR="/var/log/redis/audit/hot"
WARM_DIR="/mnt/nfs/redis-audit/warm"
S3_BUCKET="s3://company-audit-logs/redis"
S3_GLACIER_BUCKET="s3://company-audit-archive/redis"

# Dur√©es de r√©tention (jours)
HOT_RETENTION=90
WARM_RETENTION=365
COLD_RETENTION=2190  # 6 ans

# Rotation quotidienne (appel√© par cron √† 00:05)
rotate_daily() {
    local date=$(date +%Y-%m-%d)
    local archive_file="${HOT_DIR}/audit-${date}.log.gz"

    echo "[$(date)] Starting daily rotation"

    # 1. Compresser le log actuel
    if [ -f "$AUDIT_LOG" ]; then
        gzip -c "$AUDIT_LOG" > "$archive_file"
        echo "[$(date)] Compressed to $archive_file ($(du -h $archive_file | cut -f1))"

        # 2. Truncate le log actuel
        : > "$AUDIT_LOG"

        # 3. V√©rifier l'int√©grit√©
        if gzip -t "$archive_file"; then
            echo "[$(date)] Integrity check passed"
        else
            echo "[$(date)] ERROR: Archive corrupted!" >&2
            exit 1
        fi

        # 4. Calculer le checksum
        sha256sum "$archive_file" > "${archive_file}.sha256"
    fi
}

# Tier 1 ‚Üí Tier 2 (Hot ‚Üí Warm)
move_to_warm() {
    echo "[$(date)] Moving old hot logs to warm storage"

    find "$HOT_DIR" -name "audit-*.log.gz" -mtime +$HOT_RETENTION | while read -r file; do
        local basename=$(basename "$file")
        local warm_file="${WARM_DIR}/${basename}"

        # Copier vers warm storage
        cp "$file" "$warm_file"
        cp "${file}.sha256" "${warm_file}.sha256"

        # V√©rifier la copie
        if sha256sum -c "${warm_file}.sha256"; then
            echo "[$(date)] Moved to warm: $basename"
            rm -f "$file" "${file}.sha256"
        else
            echo "[$(date)] ERROR: Warm copy verification failed for $basename" >&2
        fi
    done
}

# Tier 2 ‚Üí Tier 3 (Warm ‚Üí Cold/Glacier)
move_to_cold() {
    echo "[$(date)] Archiving warm logs to Glacier"

    # Grouper par mois
    for year_month in $(find "$WARM_DIR" -name "audit-*.log.gz" -mtime +$WARM_RETENTION | \
                        sed 's/.*audit-\([0-9]\{4\}-[0-9]\{2\}\)-.*/\1/' | sort -u); do

        local archive_name="audit-${year_month}.tar.gz"
        local temp_archive="/tmp/${archive_name}"

        echo "[$(date)] Creating monthly archive: $archive_name"

        # Cr√©er l'archive mensuelle
        tar -czf "$temp_archive" -C "$WARM_DIR" $(find "$WARM_DIR" -name "audit-${year_month}-*.log.gz" -printf "%f\n")

        # Upload vers S3 Glacier
        aws s3 cp "$temp_archive" "${S3_GLACIER_BUCKET}/${archive_name}" \
            --storage-class GLACIER \
            --metadata retention-until="$(date -d "+$COLD_RETENTION days" +%Y-%m-%d)"

        if [ $? -eq 0 ]; then
            echo "[$(date)] Archived to Glacier: $archive_name"

            # Supprimer les fichiers sources (apr√®s v√©rification)
            find "$WARM_DIR" -name "audit-${year_month}-*.log.gz" -delete
            find "$WARM_DIR" -name "audit-${year_month}-*.sha256" -delete

            rm -f "$temp_archive"
        else
            echo "[$(date)] ERROR: Glacier upload failed for $archive_name" >&2
        fi
    done
}

# Purge des archives expir√©es (Tier 3)
purge_expired() {
    echo "[$(date)] Purging expired cold archives"

    # Lister les archives et v√©rifier la date de r√©tention
    aws s3api list-objects-v2 --bucket "${S3_GLACIER_BUCKET#s3://}" | \
    jq -r '.Contents[] | select(.StorageClass == "GLACIER") | .Key' | while read -r key; do

        # R√©cup√©rer les m√©tadonn√©es
        retention_until=$(aws s3api head-object \
            --bucket "${S3_GLACIER_BUCKET#s3://}" \
            --key "$key" \
            --query 'Metadata."retention-until"' \
            --output text)

        # V√©rifier si expir√©
        if [ "$(date +%s)" -gt "$(date -d "$retention_until" +%s)" ]; then
            echo "[$(date)] Deleting expired archive: $key"
            aws s3 rm "${S3_GLACIER_BUCKET}/${key}"
        fi
    done
}

# Statistiques
show_stats() {
    echo ""
    echo "=== Redis Audit Log Statistics ==="
    echo "Hot storage (0-90d):   $(du -sh $HOT_DIR | cut -f1)"
    echo "Warm storage (90-365d): $(du -sh $WARM_DIR | cut -f1)"
    echo "Cold storage (365d+):  $(aws s3 ls ${S3_GLACIER_BUCKET}/ --recursive --summarize | grep 'Total Size' | awk '{print $3}')"
    echo ""
    echo "Total events today:    $(zcat ${HOT_DIR}/audit-$(date +%Y-%m-%d).log.gz 2>/dev/null | wc -l)"
    echo "Total hot events:      $(zcat ${HOT_DIR}/audit-*.log.gz 2>/dev/null | wc -l)"
    echo "=================================="
}

# Point d'entr√©e
case "${1:-rotate}" in
    rotate)
        rotate_daily
        ;;
    move-warm)
        move_to_warm
        ;;
    move-cold)
        move_to_cold
        ;;
    purge)
        purge_expired
        ;;
    stats)
        show_stats
        ;;
    all)
        rotate_daily
        move_to_warm
        move_to_cold
        show_stats
        ;;
    *)
        echo "Usage: $0 {rotate|move-warm|move-cold|purge|stats|all}"
        exit 1
        ;;
esac

echo "[$(date)] Done"
```

**Configuration cron :**
```bash
# /etc/cron.d/redis-audit-rotation

# Rotation quotidienne √† 00:05
5 0 * * * redis /usr/local/bin/redis-audit-rotate.sh rotate

# Migration Hot ‚Üí Warm hebdomadaire (dimanche 01:00)
0 1 * * 0 redis /usr/local/bin/redis-audit-rotate.sh move-warm

# Migration Warm ‚Üí Cold mensuelle (1er du mois 02:00)
0 2 1 * * redis /usr/local/bin/redis-audit-rotate.sh move-cold

# Purge des archives expir√©es (trimestrielle)
0 3 1 1,4,7,10 * redis /usr/local/bin/redis-audit-rotate.sh purge

# Statistiques hebdomadaires (lundi 08:00)
0 8 * * 1 redis /usr/local/bin/redis-audit-rotate.sh stats | mail -s "Redis Audit Stats" ops@example.com
```

---

## Int√©gration SIEM

### Centralisation des logs

**Flux de donn√©es :**
```
[Redis Audit Proxy] ‚Üí [Syslog/Filebeat] ‚Üí [Logstash] ‚Üí [Elasticsearch] ‚Üí [Kibana]
                          ‚Üì
                    [Splunk/Datadog/Sentinel]
```

### Configuration Filebeat (Elastic Stack)

```yaml
# /etc/filebeat/filebeat.yml

filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/redis/audit.log

  # Parser JSON
  json.keys_under_root: true
  json.add_error_key: true

  # Champs additionnels
  fields:
    log_type: redis_audit
    environment: production
    datacenter: eu-west-1
    compliance: pci-dss

  # Multiline (si n√©cessaire)
  multiline.type: pattern
  multiline.pattern: '^\{'
  multiline.negate: true
  multiline.match: after

  # Enrichissement
  processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_cloud_metadata: ~
  - add_docker_metadata: ~

  # Filtrage (exclure les commandes non-sensibles si volume √©lev√©)
  #exclude_lines: ['^.*"command":"PING".*$']

# Output vers Logstash
output.logstash:
  hosts: ["logstash-1.internal:5044", "logstash-2.internal:5044"]
  loadbalance: true
  ssl.enabled: true
  ssl.certificate_authorities: ["/etc/filebeat/ca.crt"]
  ssl.certificate: "/etc/filebeat/client.crt"
  ssl.key: "/etc/filebeat/client.key"

# Monitoring
monitoring.enabled: true
monitoring.elasticsearch:
  hosts: ["https://elasticsearch.internal:9200"]
  username: "filebeat_monitor"
  password: "${FILEBEAT_MONITOR_PASSWORD}"

# Logging
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

### Pipeline Logstash

```ruby
# /etc/logstash/conf.d/redis-audit.conf

input {
  beats {
    port => 5044
    ssl => true
    ssl_certificate => "/etc/logstash/certs/server.crt"
    ssl_key => "/etc/logstash/certs/server.key"
    ssl_certificate_authorities => ["/etc/logstash/certs/ca.crt"]
  }
}

filter {
  # Filter sur les logs Redis audit uniquement
  if [fields][log_type] == "redis_audit" {

    # Parser JSON (si pas d√©j√† fait par Filebeat)
    if [message] =~ /^\{/ {
      json {
        source => "message"
        target => "audit"
      }
    }

    # Enrichissement IP geolocation
    if [audit][client_ip] {
      geoip {
        source => "[audit][client_ip]"
        target => "geoip"
      }
    }

    # Classification de la sensibilit√©
    if [audit][command] in ["GET", "SET", "HGET", "HSET", "DEL", "HDEL"] {
      mutate {
        add_field => { "sensitivity" => "high" }
      }
    } else {
      mutate {
        add_field => { "sensitivity" => "low" }
      }
    }

    # D√©tection d'anomalies (dur√©e)
    if [audit][duration_ms] and [audit][duration_ms] > 100 {
      mutate {
        add_tag => [ "slow_query" ]
      }
    }

    # D√©tection d'√©checs
    if [audit][success] == false or [audit][blocked] == true {
      mutate {
        add_tag => [ "failure" ]
      }
    }

    # D√©tection de patterns suspects
    if [audit][command] == "KEYS" and [audit][args][0] == "*" {
      mutate {
        add_tag => [ "dangerous_pattern" ]
      }
    }

    # Timestamp parsing
    date {
      match => [ "[audit][timestamp]", "ISO8601" ]
      target => "@timestamp"
    }

    # Supprimer le message original (d√©j√† pars√©)
    mutate {
      remove_field => [ "message" ]
    }
  }
}

output {
  # Output vers Elasticsearch
  if [fields][log_type] == "redis_audit" {
    elasticsearch {
      hosts => ["https://elasticsearch-1.internal:9200", "https://elasticsearch-2.internal:9200"]
      index => "redis-audit-%{+YYYY.MM.dd}"
      user => "logstash_writer"
      password => "${LOGSTASH_ES_PASSWORD}"
      ssl => true
      cacert => "/etc/logstash/certs/ca.crt"

      # ILM policy pour retention automatique
      ilm_enabled => true
      ilm_rollover_alias => "redis-audit"
      ilm_pattern => "{now/d}-000001"
      ilm_policy => "redis-audit-policy"
    }

    # Output vers Splunk (optionnel, si double SIEM)
    #http {
    #  url => "https://splunk.example.com:8088/services/collector/event"
    #  headers => {
    #    "Authorization" => "Splunk ${SPLUNK_HEC_TOKEN}"
    #  }
    #  format => "json"
    #  ssl_certificate_validation => true
    #}
  }

  # Alerting temps r√©el (failures critiques)
  if "failure" in [tags] and [audit][command] in ["AUTH", "ACL"] {
    email {
      to => "security@example.com"
      from => "redis-audit@example.com"
      subject => "ALERT: Redis authentication failure"
      body => "Failure detected: %{[audit]}"
      address => "smtp.example.com"
      port => 587
    }
  }
}
```

### Index Lifecycle Management (ILM)

```json
{
  "policy": "redis-audit-policy",
  "phases": {
    "hot": {
      "min_age": "0ms",
      "actions": {
        "rollover": {
          "max_size": "50GB",
          "max_age": "1d"
        },
        "set_priority": {
          "priority": 100
        }
      }
    },
    "warm": {
      "min_age": "90d",
      "actions": {
        "shrink": {
          "number_of_shards": 1
        },
        "forcemerge": {
          "max_num_segments": 1
        },
        "set_priority": {
          "priority": 50
        }
      }
    },
    "cold": {
      "min_age": "365d",
      "actions": {
        "freeze": {},
        "set_priority": {
          "priority": 0
        }
      }
    },
    "delete": {
      "min_age": "2190d",
      "actions": {
        "delete": {}
      }
    }
  }
}
```

---

## Checklist de conformit√©

### Configuration et d√©ploiement

```
Audit Logging Infrastructure :
‚ñ° Solution d'audit impl√©ment√©e (proxy, instrumentation, Redis Enterprise)
‚ñ° Logs centralis√©s dans un SIEM
‚ñ° Tous les Redis instances logg√©s (prod, staging si donn√©es sensibles)
‚ñ° TLS activ√© entre composants (Filebeat, Logstash, Elasticsearch)
‚ñ° Authentification configur√©e (SIEM, visualisations)

Contenu des logs :
‚ñ° Timestamp UTC avec pr√©cision (ms)
‚ñ° Identification utilisateur (username ou app_id)
‚ñ° IP source
‚ñ° Commande ex√©cut√©e
‚ñ° Arguments (avec redaction si sensible)
‚ñ° Succ√®s/√âchec
‚ñ° Dur√©e d'ex√©cution
‚ñ° Session ID et Request ID (corr√©lation)

√âv√©nements logg√©s :
‚ñ° Tous les acc√®s aux donn√©es sensibles (PII, PHI, PCI)
‚ñ° Toutes les actions privil√©gi√©es (CONFIG, ACL, CLUSTER)
‚ñ° Tentatives d'authentification (succ√®s et √©checs)
‚ñ° Modifications de configuration
‚ñ° D√©marrage/Arr√™t du serveur
‚ñ° Op√©rations destructrices (FLUSHDB, DEL)
‚ñ° √âchecs ACL
```

### R√©tention et archivage

```
Strat√©gie de r√©tention :
‚ñ° Politique document√©e et approuv√©e
‚ñ° Dur√©es conformes (PCI: 12 mois, HIPAA: 6 ans, etc.)
‚ñ° Tier 1 (Hot) : 0-90 jours, acc√®s imm√©diat
‚ñ° Tier 2 (Warm) : 90-365 jours, acc√®s rapide
‚ñ° Tier 3 (Cold) : 365+ jours, archivage Glacier/Tape
‚ñ° Rotation automatis√©e (cron, scripts test√©s)
‚ñ° V√©rification d'int√©grit√© (checksums)
‚ñ° Chiffrement des archives (GPG, S3 SSE)

Backup et r√©silience :
‚ñ° Logs sauvegard√©s dans 2+ locations g√©ographiques
‚ñ° Tests de restauration mensuels
‚ñ° RTO/RPO document√©s
‚ñ° Plan de reprise d'activit√© (DRP)
```

### S√©curit√© des logs

```
Protection :
‚ñ° Logs read-only pour non-admins
‚ñ° Acc√®s aux logs trac√© (audit de l'audit)
‚ñ° Int√©grit√© prot√©g√©e (write-once storage ou signature)
‚ñ° Logs non modifiables (append-only)
‚ñ° S√©gr√©gation des acc√®s (principe du moindre privil√®ge)
‚ñ° Chiffrement at-rest (filesystem ou storage)
‚ñ° Chiffrement in-transit (TLS pour Filebeat, Logstash)

Compliance :
‚ñ° Synchronisation NTP (<1 seconde de pr√©cision)
‚ñ° Timezone UTC pour tous les syst√®mes
‚ñ° Pas de donn√©es sensibles en clair (PANs redact√©s)
‚ñ° Conformit√© RGPD (logs = donn√©es personnelles si user_id)
```

### Revue et analyse

```
Processus de revue :
‚ñ° Revue quotidienne des logs de s√©curit√© (PCI DSS 10.6.1)
‚ñ° Dashboards configur√©s (√©checs, anomalies, tendances)
‚ñ° Alertes temps r√©el (√©checs auth, commandes dangereuses)
‚ñ° Revue hebdomadaire des actions privil√©gi√©es
‚ñ° Revue mensuelle des acc√®s (qui acc√®de √† quoi)
‚ñ° Rapport trimestriel pour le management
‚ñ° Audit annuel par tiers externe

D√©tection d'anomalies :
‚ñ° Baseline de comportement √©tabli
‚ñ° Alertes sur d√©viations (volume, dur√©e, patterns)
‚ñ° Machine learning (si SIEM avanc√©)
‚ñ° Corr√©lation multi-sources (logs app + Redis + syst√®me)

Forensique :
‚ñ° Capacit√© de reconstruction d'√©v√©nements
‚ñ° Requ√™tes forensiques document√©es (playbooks)
‚ñ° Conservation des preuves (chain of custody)
‚ñ° Exports forensiques s√©curis√©s
```

### Documentation et formation

```
‚ñ° Politique d'audit logging document√©e et approuv√©e
‚ñ° Proc√©dures op√©rationnelles (SOPs) pour :
  ‚ñ° Rotation des logs
  ‚ñ° Acc√®s aux logs (qui, quand, comment)
  ‚ñ° R√©ponse aux incidents (analyse logs)
  ‚ñ° Restauration depuis archive
‚ñ° Runbooks pour sc√©narios courants
‚ñ° Formation annuelle des √©quipes
‚ñ° Tests r√©guliers (quarterly)
‚ñ° Registre des acc√®s aux logs (audit de l'audit)
```

---

## Conclusion

L'audit logging est une exigence non-n√©gociable pour la conformit√© Redis. Cette section a couvert :

- ‚úÖ **Cadre r√©glementaire** complet (RGPD, PCI DSS, HIPAA, SOC 2, ISO 27001)
- ‚úÖ **Solutions d'audit** : Proxy custom (Python complet), Envoy, Redis Enterprise
- ‚úÖ **Contenu des logs** : 6 cat√©gories d'√©v√©nements obligatoires
- ‚úÖ **R√©tention** : Strat√©gie 3-tier avec scripts de rotation
- ‚úÖ **Int√©gration SIEM** : Filebeat, Logstash, Elasticsearch (Elastic Stack)
- ‚úÖ **Checklists** exhaustives (60+ points de contr√¥le)

**Points critiques √† retenir :**
1. Redis natif est INSUFFISANT pour l'audit (n√©cessite solutions tierces)
2. Tous les acc√®s aux donn√©es sensibles DOIVENT √™tre logg√©s
3. R√©tention minimale : 12 mois (PCI DSS), 6 ans (HIPAA)
4. Centralisation SIEM obligatoire (corr√©lation, alerting)
5. Revue quotidienne des logs requise (PCI DSS)
6. Les logs d'audit sont eux-m√™mes des donn√©es sensibles (protection stricte)

**Prochaines √©tapes :**
- Impl√©menter une solution d'audit (proxy recommand√©)
- Configurer la centralisation SIEM
- √âtablir la politique de r√©tention
- Cr√©er les dashboards et alertes
- Former les √©quipes aux proc√©dures
- Planifier les revues r√©guli√®res

‚è≠Ô∏è [Gestion des acc√®s et des permissions (RBAC)](/17-gouvernance-conformite/04-gestion-acces-permissions-rbac.md)
